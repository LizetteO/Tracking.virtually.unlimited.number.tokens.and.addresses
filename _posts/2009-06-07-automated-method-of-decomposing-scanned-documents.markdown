---

title: Automated method of decomposing scanned documents
abstract: Some embodiments produce an image capture application that implements a novel auto scan feature. The auto scan feature directs a scanner to perform an initial scan and then decomposes the scanned document into component regions. Some embodiments then identify a set of attributes of each region from the initial scan, select a set of optimal scanning parameters for each region based on the identified set of attributes, and then direct the scanner to perform a detailed secondary scan of each region with the identified set of scanning parameters. Following the secondary scan, some embodiments perform post-scan operations on the image of the scanned region.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08913285&OS=08913285&RS=08913285
owner: Apple Inc.
number: 08913285
owner_city: Cupertino
owner_country: US
publication_date: 20090607
---
This Application is related to the following applications U.S. patent application Ser. No. 12 479 853 filed Jun. 7 2009 and U.S. patent application Ser. No. 12 479 854 filed Jun. 7 2009.

Many devices are available to capture images for a computer. Computer applications that control individual image capture devices are often provided by the manufactures of those devices. For example makers of document scanners provide software to enable a user of a computer to scan documents into the computer.

Some image capture devices allow a user to lay an item such as a photograph flat upon a glass scanning bed through which a scanning head of the image capture device shines a light and through which the scanning head takes an image of the item. The image data is converted into binary form and the scanner sends the data to a computer. Some scanners are capable of scanning a subsection of the glass. Such scanners receive identifications of subsections to be scanned from the computer. By scanning small areas of the glass instead of the entire glass the scanners save and produce less image data. At higher resolutions the amount of image data required to represent a small subsection of the glass is much smaller than the amount of image data required to represent the entire glass.

Some image capture applications are available that control more than one image capture device. However such image capture applications do not easily switch between image capture devices.

Some embodiments of the invention provide an image capture application that detects available image capture devices and controls them. The image capture application of some embodiments implements the following novel features 1 a novel user interface UI feature 2 a novel auto scan feature and 3 a novel manual scan feature. Each of these features will be sequentially described below.

Some embodiments of the image capture application implement a novel UI feature. In some embodiments the UI feature provides a GUI that displays a window with multiple window areas including 1 a first window area that includes a menu of the available image capture devices automatically detected by the image capture application and 2 a second window for displaying controls for individual scanners. The menu allows a user to select a particular device from among the multiple devices in the first window area. In some embodiments when a user selects a particular image capture device in the first window area the GUI manifests controls for that particular device in the second window area. The controls allow the user to set various parameters for the image capture device.

Some embodiments display different controls for different scanners. In some embodiments the specific set of controls displayed for a particular scanner is chosen by a driver associated with that scanner. Some embodiments provide a set of generic controls that are usable by device driver manufacturers to allow a particular scanner to interface with the image capture application. These controls include controls that are common to most if not all scanners such as a control for setting the resolution of a scan a control for setting the color depth the number of colors per pixel of a scan and controls for setting the orientation of a scan. Some embodiments also allow scanner drivers to define the features of controls which are 1 not previously defined by the image capture application and 2 specific to the scanner associated with the driver. In some embodiments the image capture application provides a control that allows a user to select a separate application to receive scanned images.

Some embodiments of the image capture application implement a novel auto scan feature. Some embodiments of the auto scan feature 1 automatically decompose a scanned document into one or more component regions and 2 perform scans of the component regions. In some embodiments the image capture application directs the scanner to first produce an initial scan. The image capture application then identifies a set of attributes of the document from the initial scan selects a set of optimal scanning parameters based on the identified set of attributes and then directs the scanner to perform a detailed secondary scan with the identified set of scanning parameters. Following the secondary scan some embodiments of the image capture application with an auto scan feature perform post scan operations.

The initial scan produces a scanned document. The scanned document sometimes referred to as a scanned electronic document is an electronic image of the contents of the scanner glass of a flatbed scanner or a page that is fed through a document feeder on a scanner. In some embodiments the scanned document is a relatively low resolution image. Some embodiments perform a series of image processing operations on the scanned document to ascertain the borders of component regions and to distinguish the component regions from the scanner background and noise artifacts. In some embodiments these operations include thresholding seed filling group seed filling edge detection and boundary identification e.g. by a Hough transform .

The auto scan feature analyzes each component region to identify a set of attributes for each component region. Examples of such attributes include the type of content e.g. text image etc. the color of the content e.g. black and white grey scale color etc. and the orientation of the component region. The auto scan feature derives a set of scan parameters for each component region according to the component region s identified attributes. Some embodiments then perform a secondary scan on each component region using the scan parameters derived from the component region s attributes.

In some embodiments the image capture application performs post scan operations on a component region after the secondary scan. Specifically as needed the auto scan feature performs alignment optical character recognition OCR storage or other operations on the component region. In some embodiments the auto scan feature also delivers data or images to applications other than the image capture application.

Some embodiments of the image capture application also implement a novel manual scan feature. In some embodiments an image capture application with a manual scan feature automatically identifies regions in a similar manner to the auto scan but rather than automatically performing the secondary scans the image capture application provides a manual scanning tool that enables the user to manually adjust the regions. Some embodiments further provide tools such as visual indicators of the size location and orientation of identified regions. In some embodiments a set of guidelines are provided to show the user the original location and orientation of the automatically identified region. The guidelines provide a set of reference lines that allow a user to identify directions relative to a selected automatically identified region. In some embodiments since the image capture application automatically selects a set of scan parameters for automatically identified regions the manual scan feature provides scanner controls that enable the user to manually override the automatically selected scan parameters.

Some embodiments implement all of the above described features. Other embodiments implement a subset of the above described features For example an image capture application may implement some of the above described features without implementing all of them. Moreover some embodiments do not implement these features as one image capture application but instead provide the features as frameworks sometimes called libraries for other applications to build image capture interfaces upon. For instance some embodiments provide some or all these features as APIs in a framework provided by the operating system of a device such as a computer. Some embodiments provide these features to third party application developers to integrate into third party applications. The frameworks of some embodiments are designed to interact with modules of the operating system. Under such an approach a developer of an application that runs on the operating system can access the above described features through the APIs. By accessing the frameworks through the APIs the developers can add functionalities such as the novel UI feature the novel auto scan feature or the novel manual scan feature to their applications.

In the following detailed description of the invention numerous details examples and embodiments of the invention are set forth and described. However it will be clear and apparent to one skilled in the art that the invention is not limited to the embodiments set forth and that the invention may be practiced without some of the specific details and examples discussed.

Some embodiments of the invention provide an image capture application that manages multiple image capture devices from multiple manufacturers. The image capture application of some embodiments detects image capture devices connected to the computer on which the image capture application is running. In some embodiments the image capture application also detects image capture devices that are shared on a network that is connected to the computer on which the image capture application is running. The image capture application of some embodiments detects multiple types of devices include scanners cameras and memory devices that store images. Some embodiments manage multiple types of devices e.g. cameras and scanners . Some embodiments manage a single type of device e.g. scanners only .

In some embodiments the image capture application includes a graphical user interface GUI . The GUIs of some embodiments display a window with a first window area that includes a menu of the available image capture devices. The menu allows a user to select a particular device from among the multiple devices in the first window area. In some embodiments when a user selects a particular image capture device in the first window area the GUI manifests controls for that particular device in a second area of the window that includes the menu of available image capture devices. That is the GUI simultaneously displays in a single window the multiple image capture devices from different manufacturers and the particular controls for the selected image capture device. The controls allow the user to set various parameters for the image capture device. An example of such an image capture application is illustrated in .

As shown in the GUI includes device display area which includes icons and scan display area in stages control area and thumbnail display area in stage . The device display area displays a menu of image capture devices that are available to the image capture application. The scan display area visually presents images captured by scanners. The control area displays controls that manage particular scanners and functions of the image capture application that relate to particular scanners. Thumbnail display area shows miniature representations of images stored in a digital camera or other image recording device.

The operation of the GUI will now be described by reference to the state of the GUI during the four stages . Stage shows the GUI after the image capture application has detected available image capture devices and populated the menu in device display area with the detected devices. The image capture application allows users to select image capture devices from the menu. The device display area shows icons and which represent detected scanners and icon which represents a detected camera. None of the icons have been selected in stage . Accordingly the scan display area is empty. As shown in stage in some embodiments when no image capture device is selected the GUI displays a default set of scanner controls in control area . In some embodiments the default controls are not shown when no scanner has been selected. In other embodiments default controls are shown even when no scanner has been selected though the controls remain inactive.

Stage shows the GUI when scanner icon is selected as indicated by its inverted colors . As a result of the selection the image capture application has commanded the scanner represented by scanner icon to perform a preview scan of the glass of the scanner. The preview scan is a low resolution scan performed to get general data about the item s on the glass. As used herein the glass of the scanner refers to the area of the scanner on which items are placed to have their images captured. The scanner glass is sometimes referred to as a scanner bed . In the illustrated embodiment the scanner has performed the scan and is displaying preview in scan display area . Preview shows the images of photographs on the scanner. As used herein preview data is the raw data received from the scanner during a preview scan. A preview refers to the display of that preview data as an image. In some embodiments a preview may include various overlays and indicators as well as the image itself.

As another result of the selection of icon the GUI in stage displays a set of controls which are controls that apply to the selected scanner. Some embodiments display multiple sets of controls. For example separate sets of controls provided by the image capture application programmers and controls provided by the scanner manufacturers. Additional details about sets of scanner controls are found in section I.B. below.

Stage shows the GUI when scanner icon is selected. As a result of the selection the image capture application has commanded the scanner represented by scanner icon to perform a preview scan of the glass of the scanner to generate a replacement of preview . In the illustrated embodiment the scanner has performed the scan and is displaying preview in scan display area . Preview shows the image of a tax form on the newly selected scanner. Preview is different from preview because different items are on the different scanners.

Also in stage the GUI displays a set of controls which are controls that apply to the newly selected scanner. The GUI provides each particular scanner with a set of controls that apply to that particular scanner. The scanner represented by icon is different from the scanner represented by icon therefore the GUI provides a different set of controls for each of the selected scanners. That is set of controls are different from set of controls because they are controls for different models of scanner.

Stage shows that GUI manages cameras as well as scanners. Stage shows the GUI when camera icon is selected. As a result of the selection the image capture application has retrieved or generated thumbnails of images on the camera and has displayed the thumbnails in thumbnail display area . The GUI displays a set of camera controls in control area . The camera controls allow a user to perform various operations with the camera e.g. downloading the photographs .

Though the GUI and other GUIs described herein are drawn with particular areas associated with particular features of an image capture application one of ordinary skill in the art will realize that in some embodiments the areas or controls will be provided in different configurations. For example in some embodiments a device display area is on the right side of a GUI rather than the left. Similarly in some embodiments the location of the control area depends on which device is selected. For example when a scanner is selected the scanner controls appear on the right but when a camera is selected the camera controls appear along the bottom of the window in a similar fashion to the simplified GUI illustrated in below . In some such embodiments the display area extends to the right edge of the window in order to provide more room for thumbnails or other image data.

In some embodiments an image capture application automatically detects scanners from multiple manufacturers that are accessible to the computer on which the image capture application is running. The image capture application provides a GUI with a single window that includes 1 a first area for displaying a set of icons that represent the detected scanners from multiple manufacturers and 2 a second area for displaying controls of a scanner when that scanner is selected from the set of icons. In some embodiments the set of icons represents both scanners that are directly connected to the computer on which the image capture application is running the local computer and scanners that are shared on a computer network to which the local computer is connected. A local computer that can access a device either through the network or directly can be described as communicatively coupled to the device. The GUI of some embodiments continues to display the set of icons in the first area of the window while simultaneously displaying the controls in the second area of the window. The GUI of some embodiments provides different controls for scanners with different features.

Computer is able to access devices that are connected to it directly as well as shared devices that are connected to it via the network. A device is shared when the computer to which it is connected makes the device accessible to other computers on a computer network. In some cases devices connected directly to a network may be set to be shared devices by default. For the purposes of describing GUIs herein the flatbed scanner and the multi function device will be assumed to be shared devices. The scanners as shown in the figures have arbitrary names e.g. scanner six . One of ordinary skill in the art will recognize that the use of arbitrary individual names for devices on a network is a common practice.

As mentioned above illustrates a GUI of an image capture application of some embodiments. The GUI of includes 1 a device display area which includes a local device display area and a shared device display area 2 a scan display area and 3 a scanner control area . Local device display area shows icons that represent scanners that are connected directly to the local computer. The shared device display area shows scanners that are available to the local computer through a network. The scanner control area is where the GUI displays the particular set of controls that apply to a particular scanner once the scanner has been selected.

The image capture application detects scanners by different manufacturers locally and through the network. This detection can be performed by various modules of the image capture application. As described in relation to below in some embodiments the image capture application is provided as a set of modules including a client module and an extension module. In some embodiments the client module detects the devices. In other embodiments the extension module detects the devices. In still other embodiments the image capture application is provided as a single module and that single module detects the devices. Similarly many other operations described herein as being performed by an image capture application are performed by an image capture extension module or an image capture client module. Examples of image capture extension modules are described in U.S. patent application Ser. No. 10 873 822 titled Image Sharing filed on Jun. 22 2004 which is incorporated herein by reference.

As shown in the image capture application has detected the scanners of the example computer system illustrated in . The application has detected 1 scanner manufactured by Canon which is connected to the USB port of computer 2 duplex scanner manufactured by HP which is connected to network and 3 scanner manufactured by Epson which is connected to computer . The GUI displays these scanners from different manufacturers in device display area which shows graphical representations icons of the various available scanners.

After detecting the scanners the GUI displays icons representing these scanners from different manufacturers in the device display area . Icon represents scanner which is connected directly to the local computer on which GUI is displayed. Therefore the GUI displays icon in local device display area . Icon represents scanner which is accessible to computer through the connection of computer to network . Therefore GUI displays icon in the shared device menu . Icon represents multi function device which is accessible to computer through the connection of computer to network . Therefore GUI displays icon in the shared device menu . In the embodiment shown in the local devices are separated from the shared devices however the GUIs of some embodiments do not separate scanners into local and shared areas.

As shown in each of the illustrated scanners is made by a different hardware manufacturing company. However all the available scanners are displayed together in device display area . One of ordinary skill in the art will realize that in computer systems that have scanners from only one manufacturer the GUI will display scanners from only that manufacturer in the device display area. Some embodiments allow available scanners to be excluded from the device display area e.g. scanners that the user chooses to exclude scanners which are in use by another computer etc. .

The icons and have text that indicates the name of the scanner the manufacturer of the scanner and the location of the scanner. For example scanner is an Epson brand scanner connected to computer which has the name Comp2 . Accordingly the text for icon which represents scanner shows that it is an Epson scanner connected to Comp2. One of ordinary skill in the art will realize that some embodiments do not provide the same type of information for the icons as illustrated in . For example some embodiments do not display the brand names of the scanners in the device display area. Some embodiments display the brand names of some scanners but not other scanners. For example older model scanners might not provide a brand name to the image capture application. Similarly some embodiments omit the location of the scanner or show the location of only some of the scanners. For example some embodiments omit the locations of some network scanners such as scanners directly connected to the local network that do not employ the protocols that the image capture application uses to identify the locations of scanners.

In some embodiments the GUI receives elections of particular scanners through GUI operations e.g. a click operation on the icons in device display area . When a particular scanner has been selected the GUI displays controls that apply to that particular scanner in the scanner control area while continuing to display the scanners from different manufacturers in the device display area . The GUI is then able to receive commands from users to control the selected scanner through the controls displayed in the scanner control area . When a scanner has been selected and a scan of the image capture area glass of the scanner has been performed scan display area graphically displays the results of that scan.

In some embodiments when the GUI receives a selection of a particular scanner the image capture application directs the scanner to perform a low resolution preview scan of the glass of the scanner. Details of the preview scan will be further described below in reference to . Other embodiments direct the scanner to perform the preview scan at the regular full resolution. GUI displays the results of such preview scans in scan display area . However scan display area is shown in as empty because the figure illustrates a state of the GUI in which no scanner has been selected and no preview scan has been performed.

As an additional consequence of a scanner being selected the scanner control area displays GUI controls for the scanner. In the scanner control area includes blank GUI controls and . Blank controls are provided in the figure for the purpose of showing the typical location of generic scanner controls. Blank controls are provided in the figure for the purpose of showing the typical location of scanner specific controls.

Generic scanner controls are provided by the makers of the image capture application. Scanner specific controls manage features that are built into a specific model of scanner but are not provided by the makers of the image control application. More details about generic and scanner specific controls are provided in section I.A. below.

When no scanner has been selected some embodiments display all the available generic scanner controls. Some embodiments display a subset of the available generic scanner controls. Still other embodiments do not display any scanner controls until a particular scanner has been selected. In some embodiments a scanner is automatically selected by default and the controls generic and scanner specific that apply to that scanner are displayed in scanner control area until a different device has been selected.

To illustrate different generic and scanner specific controls for different scanners. Two more detailed examples of the GUI of some embodiments will be described below in relation to .

Different scanners have different features. Accordingly some embodiments display different controls for different scanners. In some embodiments the specific set of controls displayed for a particular scanner is chosen by a driver associated with that scanner. As mentioned above some embodiments provide a regular set of controls referred to herein as generic controls that are usable by device driver manufacturers to allow a particular scanner to interface with the image capture application. These controls include controls that are common to most if not all scanners such as a control for setting the resolution of a scan a control for setting the color depth the number of colors per pixel of a scan and controls for setting the orientation of a scan. Different scanners may require different sets of generic controls. Accordingly the scanner manufacturers program a device driver associated with a particular scanner to select a specific subset of the available generic controls that apply to that particular scanner. In some embodiments the individual scanner drivers provide codes that identify the generic controls for a scanner and their associated menu items but do not provide the names of the controls or the names of menu options for the controls.

A scanner driver that provides an interface between a scanner and the image capture application of some embodiments would not have to provide the names of the generic controls or the names of individual menu items of the generic controls. The drivers would merely indicate which of the available generic controls and menu items were valid options for the particular scanner. That is the scanner drivers used with some embodiments provide specific codes from a list of codes supplied by the image capture application producer that the image capture application uses to determine which of multiple available generic controls and menu options provided by the image capture applications are applicable to a particular scanner. In some embodiments because the codes refer to specific controls supplied by the makers of the image capture application generic controls for the same function on two different scanners will always have the same name. For example drivers of a scanner could select a code to include the control that sets the scan resolution in the generic controls for that scanner. The image capture application would display the name resolution for that control for all scanners rather than resolution for some scanners and res. scan resolution or dpi for other scanners. This serves to eliminate the confusion that would result from different manufacturers giving different names to the same standard control.

The options for individual generic controls of some embodiments are also supplied by the makers of the image capture application. For example in some embodiments a generic control for color number might have four acceptable values 1 two 2 256 3 thousands and 4 millions. A driver for use with such embodiments could provide a code e.g. from a list of codes supplied to the maker of the drivers by the makers of the image capture application. The code would 1 identify the color number control as control for the scanner and 2 append a four bit word to identify which of the preset menu options the particular scanner supports. The four bit word would be a binary digit indicating yes or no for each of the four menu items.

In some embodiments when a driver indicates that an option is not viable for controlling a scanner the GUI grays out that option on the control menu. In other embodiments the GUI omits any non viable options from the control menu and displays only the viable options. For example a scanner could be made that is able to scan with two colors 256 colors or millions of colors but not thousands of colors. The driver for the scanner would identify as a control of the scanner a color number control with options 1 2 and 4 as viable options for the corresponding scanner and option 3 as non viable. The GUI would take this identification and display a color number control with options 1 two 2 256 and 3 millions.

In addition to the generic controls some embodiments provide interfaces for controls to set scan parameters that are specific to individual scanners and not provided as part of the generic controls. In contrast to the generic controls these controls can be anything that the device manufacturer wants them to be. These controls are referred to herein as scanner specific controls . In some embodiments the device drivers supply the elements of each scanner specific control. Such elements may include 1 the type of control such as toggle or menu 2 the name of the control 3 the names of the menu options of the control if applicable and 4 which of the named options is the default option.

In such embodiments the image capture application merely displays the scanner specific controls to the user in the manner that the device driver indicates and acts as a pass through to the scanner of the selected menu items or values. The availability of scanner specific controls allows the image capture application to control scanner functions that were not originally contemplated by the programmers of the image capture application. For example if a scanner manufacturer adds a dust removal feature that is not supported by the regular controls of the image capture application the scanner manufacturer can program the device driver for the scanner to command the image capture application to show a dust removal scanner specific control to the user. The driver could also specify that the control should have menu options light dust medium dust or heavy dust . The image capture application would then display a control for the user with exactly the specified control name dust removal and menu options light dust medium dust and heavy dust .

The scanner specific controls are entirely at the discretion of the individual scanner manufacturer. As an example of a feature that is unusual or unknown in existing scanners a scanner manufacturer could create a scanner with an attached paper shredder. The manufacturer could program the device driver for the scanner to provide the image capture application with a scanner specific shred document after scanning control. Some examples of generic and scanner specific controls are illustrated in . In giving these examples additional details are provided regarding the scan display area generic scanner controls and scanner specific controls.

As previously mentioned when a scanner icon in local device display area or shared device display area is selected the image capture application provides controls for that scanner. The generic scanner controls and the scanner specific controls receive settings from a user that determine various parameters that will be used when scanning the items on the scanner and processing the scanned images. Preview shows a low resolution image of the items that are on the glass of selected scanner . Preview scans are described in additional detail in section II below.

In icon has been selected. As mentioned in relation to icon represents scanner of . In the GUI indicates that scanner has been selected by inverting the colors of the corresponding icon . However other embodiments use other visual cues to indicate that a scanner has been selected. For example some embodiments provide a border box around the icon altered icon colors bold lettering for the icon or other cues.

In because scanner has been selected the GUI displays the controls that apply to scanner in scanner control area . Generic controls are displayed in the upper section of scanner control area while scanner specific controls are displayed in the lower section of scanner control area .

As mentioned above different scanners can require different sets of generic controls. In such embodiments the generic controls provided by the GUI for the selected scanner depend on the generic features of the selected scanner. One generic control included in generic controls is an orientation control . Orientation controls determine which side of a scanned image is saved as the top of the image. Orientation controls are provided because items may be placed on a scanner in any orientation. Some items are placed on the scanner sideways or upside down. Orientation control determines the orientation of an image generated by scanner .

Scanner is a simplex scanner a scanner that can only scan on one side of a page without a user turning the page over . Therefore generic controls in are generic controls appropriate for a simplex scanner though other simplex scanners may have other sets of generic controls . Because a simplex scanner can only scan one side of a page and a stack of pages fed into a sheet feeder of the simplex scanner is generally fed in with a common orientation there is no need for more than one orientation control for simplex scanner. Therefore generic controls only include one orientation control. Orientation control is a generic control because orientation control is provided by the makers of the image capture application rather than the scanner manufacturer.

In some embodiments the section of the scanner control area that displays the generic controls also displays controls that determine the actions of the image capture application beyond controlling the scanner itself. For example the scan to control described in section I.C. below determines to which application from a provided list of applications the scanned image will be sent once it has been scanned and processed by the image capture application.

As mentioned above scanner specific controls manage features that are built in to the specific model of scanner but are not pre programmed in the image control application. shows that the selected scanner has features that the scanner manufacturer calls unsharp mask and descreening . In the driver for scanner the manufacturer or third party driver programmer has identified the names and menu options of controls that the manufacturer or programmer wants the image capture application to display. The image capture application receives the names of the controls and the menu items and generates the scanner specific controls . Scanner specific controls include controls and . Control is labeled unsharp mask because the driver for scanner provided the name unsharp mask for a scanner specific control. Control is labeled descreening because the driver provided the name descreening for a scanner specific control. If the image capture application receives selections of the options of scanner specific control or then the image capture application passes the received selection to the scanner.

In some embodiments such as the embodiment illustrated in scanner specific controls are in a separate section from generic controls. In some embodiments the separate section is a dedicated section set aside for scanner specific controls. In other embodiments the section for the scanner specific controls is inserted just after the last generic control. In still other embodiments scanner specific controls are positioned among the generic controls.

Because the names and menu options are set by the driver in some embodiments the GUI could provide controls for the same feature on two different scanners with two different names. That is if a driver for a scanner from a different manufacturer or even a different driver for the same scanner called the unsharp mask feature by a different name e.g. blur the name of control would be different for the different scanner or driver . The names would be different even if the result of using the differently named controls would be the same for each scanner. Similarly in some embodiments the scanner specific controls for the same features may have different names for the options. For example one driver could specify that the options for control should be named heavy medium or light while another driver could specify that the options be named high middle or low even though selection of the corresponding options e.g. selection of heavy or high would cause the same result.

The amount of time it takes to perform a scan increases for higher resolution scans. Many scanners are capable of performing high resolution scans of specified portions of the glass while ignoring other portions of the glass. Accordingly scanning time can be reduced by performing an initial scan at a low resolution and then selecting manually or automatically portions of the glass on which to perform higher resolution scans. In the embodiment illustrated in the image capture application automatically commands scanner to perform a low resolution preview scan when the scanner icon is selected. The preview scan generates a preview that shows the items and on scanner . Additional details about preview scans are described in section II below.

Some features of described above are associated with the particular scanner selected. illustrates GUI when another particular scanner has been selected. Like shows different controls that are provided by the GUI to control the selected scanner and a preview scan of the items on the scanner. However a different scanner has been selected in than . includes generic scanner controls scanner specific controls and preview .

Like the controls in the generic scanner controls and the scanner specific controls receive settings from a user that determine various parameters that will be used when scanning the items on the scanner and processing the scanned images. Preview shows a low resolution image of the item that is on the glass of selected scanner .

In icon has been selected. Icon represents scanner of which is a duplex scanner. In because scanner has been selected the GUI displays the controls that apply to scanner in scanner control area . The controls shown in are different from the controls shown in demonstrating that the image capture application provides different sets of controls for different scanners. Specifically show that the GUI provides both different generic controls and different scanner specific controls for scanner than for scanner .

Although the particular controls are different in the generic controls are displayed in the upper section of scanner control area like the generic controls in . Similarly scanner specific controls are displayed in the lower section of scanner control area like the scanner specific controls in .

As mentioned above in some embodiments different sets of generic controls apply to different scanners. In such embodiments the generic controls provided by the GUI for the selected scanner depend on the generic features of the selected scanner. In the example shown in the selected scanner was a simplex scanner. In the selected scanner is a duplex scanner scanner . Therefore the generic controls of are generic controls that are appropriate for a duplex scanner though other duplex scanners may have other sets of generic controls . In contrast to the generic controls of which included a single orientation control generic controls include dual orientation controls and for setting the orientation of each side of a two sided page.

The provided orientation controls and are useful for duplex scanners but not to one sided scanners. They are useful to duplex scanners because duplex scanners can flip pages over. The duplex scanners scan one side of the paper and then flip the paper over to scan the other side. Two sided pages are sometimes printed so that the text of the even numbered pages will be in the same orientation as the odd numbered pages when the pages are flipped up rotated through an axis parallel to the top and bottom of the page . However two sided pagers are also sometimes printed so the text of the even numbered pages will be in the same orientation as the odd numbered pages when the pages are flipped over rotated through an axis parallel to the left and right sides of the page . Flipping a page in the wrong direction results in the even numbered pages being oriented in the opposite direction from the odd numbered pages. Duplex scanner can only flip the page in one direction. Accordingly if the pages are printed so as to require flipping in the other direction then a single orientation control for duplex scanner would leave every other scanned page upside down. The dual orientation controls and solve this problem. This is shown by control being set to save images of the odd pages upside down and control being set to save images of the even pages right side up.

Duplex scanners are common enough that in some embodiments like the one shown in the image capture application producer provides generic controls to handle the two sided page orientation issue. That is in some embodiments the different orientation controls and are all generic because all of them are pre programmed in the image capture application rather than provided by the scanner manufacturer. However in some embodiments dual orientation controls are not provided by the makers of the image capture application. In some of such embodiments the makers of the drivers can provide dual orientation controls as scanner specific controls.

Because the generic controls and their options are pre programmed in the image capture application the image capture application of some embodiments is programmed to provide secondary uses of the selected options of generic controls. That is secondary to passing the control setting to a scanner. For example the image capture application of some embodiments provides a scanner resolution control. The programmers of the image capture application knowing how scan resolution affects file size could program the image capture application to calculate an estimated file size for the scan that varies depending on the resolution setting.

In contrast scanner specific controls manage features that are built in to the specific model of scanner but are not pre programmed in the image control application. Because scanner specific controls perform operations that were not anticipated by the programmers of the image capture application the image capture application of some embodiments has no secondary use for a selected option of a scanner specific control e.g. the image capture application can only pass it through to the scanner .

As mentioned above in some embodiments the image capture application automatically commands a scanner to perform a low resolution preview scan of a scanner when the scanner is selected. Therefore when scanner is selected e.g. by the selection of icon shown in the preview scan generates a preview that shows the item on scanner . The preview of is different from the preview of because they are preview scans of different items on different scanners.

Some embodiments provide a control for the user to command the scanner to redo the preview scan e.g. when items on the glass have been moved or replaced . Some embodiments provide a control to command a preview scan in addition to or instead of automatically commanding a preview scan when the scanner is first selected.

As mentioned in relation to in some embodiments an automatic preview scan of the glass of a selected scanner is performed upon selection of the scanner. The preview scan provides the GUI with a low resolution image of the entire glass including the items on the glass and the surrounding space to display as a preview. In some embodiments the image capture application evaluates the data collected in the preview scan to determine the positions and types of items on the glass.

In embodiments that automatically determine scanning parameters based on preview scans and in embodiments in which the user selects parameters based on the preview image parameters of subsequent detailed scans of the items on the glass such as which areas of the glass will be scanned in the detailed scans depend on the information gathered in the preview scan. Therefore it is important that the information gathered in the preview scan remains accurate. If the positions of the items on the glass change after a preview scan but before a detailed scan then the existing preview scan data will no longer accurately represent the state of the items on the glass. Such inaccuracies could lead to worthless detailed scans and wasted time so the preview scan should be redone when items on the glass are moved or replaced. However many scanners do not have a sensor that identifies when the lid of the scanner has been opened and the items on the glass have been moved or replaced. Therefore the images on the glass can change without the image capture application being notified. Accordingly some embodiments provide a control to receive a user command to redo the preview scan. Such a control can be activated by a user. For example a user can activate the control after the user has moved or replaced items that were previously on the scanner. Activating the control ensures that the image capture application has up to date preview scan data to evaluate. An example of the preview scan of some embodiments is illustrated in .

Overview button is a control that commands the scanner to redo the preview scan. Cancel button is a control that aborts the preview scan before it is finished. Incomplete preview is an image of the scanner s progress so far at generating the data for the low resolution preview of the items on the scanner glass. Incomplete preview shows a partial scan of item . Item is an image of a photograph that has replaced the male portrait represented by scanned image shown in . The scan status indicator indicates what type of scan operation is being performed.

In the item has replaced item on the scanner glass. In a preview was generated by the automatic preview scan performed when the scanner icon was selected. Because of the replacement of item with item on the scanner glass preview does not accurately represent the contents of the glass of scanner at the time of the preview scan shown in . Accordingly the user has activated overview button e.g. by clicking on the button and the image capture application has commanded the scanner to perform another preview scan. The GUI displays the preview scan in progress showing partially scanned item and status indicator . In this figure status indicator shows that a quickscan i.e. a preview scan is being performed. While the preview scan is in progress a user can select the cancel button to command that the preview scan be stopped immediately or as soon as the software and hardware are able to stop the scan . Some embodiments lock out some or all controls other than the cancel control while the preview scan is being performed.

Preview is a low resolution image of the glass of a scanner. The preview shows the items and which are images of the items on the glass during the new preview scan. In some embodiments the GUI provides a bounding box that surrounds the scanned items in the preview . The bounding box indicates the outer limits of the scanned group of items. Scan button activates a detailed scan of the scanner glass.

Preview image in shows an image of the entire glass of the selected scanner after the new preview scan is complete. The items placed on the glass of a scanner here items and are generally of interest to the user while the areas outside of the items are generally not of interest to the user. Accordingly it is desirable that the image capture application should default to not scanning areas outside of the items. That is unless the image capture application receives overriding commands e.g. from a user a detailed scan of items and should exclude the areas outside of those images. Therefore the image capture application uses the preview scan data to determine the outermost locations of the items on the glass. That is the highest lowest rightmost and leftmost locations of any items placed on the glass to be scanned. GUI shows the determined limits to the user as bounding box which is a box with edges parallel to the sides of the preview that surrounds all the images items and in the preview . In bounding box is the smallest possible box with edges parallel to the sides of the preview that surrounds all the images in the preview . Bounding box indicates the automatically determined limits of the area that it would be useful to capture in a detailed scan. When the detailed scan button is activated e.g. by a click of a mouse button the image capture application will perform a detailed scan of the area represented by bounding box .

In some cases a user might want to scan a different area of the glass than the automatically determined area e.g. more of the surrounding blank space . Therefore some embodiments provide controls to change the location size or orientation of the identified bounding box. Some examples of such embodiments are described in section III below. In some embodiments the image capture application commands the scanner to perform a detailed scan of the area in the bounding box. In some embodiments the image or images captured by the detailed scan are sent to an application selected by a user. An example of the controls for selecting an application as a recipient of the scanned image is shown in .

The image capture applications of some embodiments provide a control that allows a user to select an application to receive scanned images. illustrates a GUI with an application selection menu of some embodiments. The figure shows various menu items that a user can select to determine the application to which a scanned image will be sent. The menu includes grayed out non selectable items representing applications to which images cannot be sent. includes scan to application selector which is displayed as a menu of applications. The menu includes selectable menu items 1 mail 2 ImageViewer and 3 Firefox and non selectable menu items 1 calculator and 2 chess .

The scan to application selector allows a user to choose a computer application to which a scanned image should be sent. Individual selectable menu items and represent applications that are capable of displaying or otherwise handling supplied images. Non selectable menu items and represent applications that are not capable of displaying or otherwise handling supplied images.

Some computer applications are capable of displaying image files that are sent to the application. For example the Firefox web browser displays images in a browser window when an image is supplied to the browser. In applications that are capable of displaying supplied image files mail ImageViewer and Firefox are represented in the scan to application selector in black lettering indicating that they are selectable. When a selectable menu item is selected a subsequent detailed scan will be sent to the application that corresponds to the selected menu item.

In contrast some computer applications are not capable of displaying supplied images. For example a calculator program may not be capable of displaying a supplied image file. In applications calculator and chess which are incapable of displaying supplied image files are represented in the scan to application selector in grayed out text preventing the user from accidentally sending a scanned image file to an application that is incapable of handling an image file. Alternate embodiments may provide representations of applications that are not capable of displaying supplied images that are deprecated in other ways than being grayed out. Scan to application selector demonstrates the concept of grayed out application options. However in some embodiments the scan to application selector omits non viable menu options but includes an option to browse additional applications some of which may be non viable. In some such embodiments the display of the additional applications includes grayed out non viable applications.

Some applications such as mail are not programmed to display received images but are capable of using received images in some manner if the applications are provided with instructions for how to use the received images. In some embodiments the image capture application or some other application or operating system component provides scripts to instruct such applications how to handle scanned images. For example a script for sending a scan to a mail application could include instructions to the mail application to create a new e mail and attach the scanned image as a file attachment to the new e mail.

Some embodiments provide local drive network drive SD card and or other storage medium as an alternative destination for the scanned images. In these instances the user may select a storage medium to receive the scanned image produced by the image capture application.

As described above some embodiments perform preview scans of the glass of selected scanners. Some embodiments use the previews to automatically detect separate items on the scanner glass. The GUI controls for setting the image capture application to automatically detect separate items are described in relation to . The GUI controls activate the processes of identifying separate items. Additional details about the process of identifying separate items are described in section II below.

In the detect separate item toggle is checked commanding the image capture application to identify items individually. When toggle is set to identify items individually the image capture application uses the preview scan data to identify the locations occupied by the separate items. The image capture application then displays the separately identified images to the user. Accordingly preview shows each item enclosed in a separate individual bounding box bounding boxes and .

Some embodiments switch back and forth between the large bounding box of and the individual bounding boxes of when toggle is checked and unchecked. In some embodiments the image capture application can switch from either of the two modes to the other without performing a new preview scan. In some embodiments even when toggle is unchecked the separate items are detected when the original preview scan is performed and the detection data is stored for potential later use. In some embodiments when the detect separate items toggle is first checked after a preview scan the detection of the separate items is performed and the results are stored for later retrieval in the event that the detect separate items toggle is unchecked and then checked again. In other embodiments the detection of the separate items is performed on the preview image each time toggle is checked and rechecked.

Most scanners are only able to scan areas that are aligned with the edges of the glass. The scanners contain a scanner head that captures thin slices of an image at right angles to the sides of the scanner glass. The scanner head is then moved parallel to the sides of the glass scanning a rectangular area aligned with the edges of the glass. Therefore in some embodiments when the image capture application determines the bounding box of an image that is rotated in relation to the glass the image capture application also determines a larger bounding box for the image that has sides that are aligned with the glass and encompass the first bounding box. The image capture application provides the scanner with the larger bounding box. The scanner then scans the area within the larger bounding box and sends the scan data to the image capture application which extracts the image within the smaller bounding box from the larger image provided by the scanner.

In the bounding box identifies the leftmost rightmost top and bottom corner of item . Therefore when the scanner scans the area of the glass corresponding to bounding box the entirety of item along with some surrounding blank areas will be provided to the image capture application which will then extract the data within the boundaries of item . Similarly when the scanner scans the area of the glass corresponding to bounding box the entirety of item along with some surrounding blank areas will be provided to the image capture application which will then extract the image data within the boundaries of item .

Some embodiments automatically set parameters for each identified item. For example some embodiments would identify bounding box as containing a color picture and set the parameters to scan the color picture at 150 dots per inch dpi with millions of colors. Some embodiments would identify item as text and scan it at 300 dpi in black and white followed by applying an optical character recognition algorithm to the scanned image of item .

In some embodiments once individual items have been identified the image capture application allows a user to select a particular image and manually adjust the automatically set scanning parameters before commanding the scanner to scan that particular item. Examples of such embodiments are described in section III. below.

As mentioned above some embodiments allow a user to manually adjust the automatically identified scan parameters. However under some circumstances a user may want to sacrifice the ability to manually control the parameters in exchange for the increased speed resulting from not making the image capture application wait for the user to select items and scan each item. Accordingly some embodiments provide an optional simplified interface for performing multiple steps involved in scanning in rapid succession. One of ordinary skill in the art will understand that in some embodiments the simplified interface and the standard interface are both aspects of the same user interface rather than separate and distinct interfaces. Some embodiments provide GUI controls for switching between a simplified interface and a standard interface.

The automated process activated by scan button performs a preview scan but does not stop for user input after the preview scan. Accordingly the simplified interface provides only controls that are relevant before a preview scan is performed. The simplified interface also does not provide a separate overview button includes a preview scan. A user of GUI can hit the scan button to scan multiple items then replace the items on the scanner and hit the scan button again to scan the new items. Without having to set the parameters the user can scan large numbers of items very quickly.

Some embodiments provide a GUI that allows the control of both scanners and image capture devices that are not scanners. illustrates device display area with multiple types of devices from multiple vendors. Device display area displays SD card scanner a Canon brand scanner duplex scanner an HP brand scanner scanner an Epson brand scanner camera a Nikon brand camera and camera a Kodak brand camera .

The image capture application of some embodiments controls SD cards and similar external memory devices because such cards are often used as storage devices for images taken by digital cameras. For example many digital cameras have an input output slot for inserting an SD card to store digital photographs on the card as soon as the digital photographs are taken. Therefore some embodiments provide GUI controls for SD cards that are similar to the GUI controls that the embodiments provide for cameras. Some embodiments provide novel features for the camera interface of the GUI. When a scanner is the active device and a camera is selected the GUI of some embodiments changes from a state in which the scanner controls are displayed to another state in which the camera controls are displayed. The GUI of some embodiments goes through many states.

When the image capture application is activated it enters state in which it displays the GUI. The initial GUI includes a device area to be populated with icons representing image capture devices. The image capture application automatically detects image capture devices e.g. scanners cameras and memory devices to transition to state in which the GUI populates the device area with icons representing the detected image capture devices. In some embodiments the image capture application detects the devices before displaying the initial GUI and state is the first state shown to the user. In some embodiments the device area continues to be displayed during all the other states shown in . An example of a GUI in state is provided above in .

The user of the image capture application can select an image capture device from the device area. When the image capture application receives a selection of a scanner it transitions to state . In state the GUI displays the scanner controls for the selected scanner. An example of a GUI in state is provided in . A user can then direct the image capture device to perform a manual scan or an automatic scan. When the image capture application in state receives a command to start a manual scan the GUI transitions to state in which it displays the manual scan GUI operations. When the manual scan ends the GUI transitions back to state . When the image capture application in state receives a command to start an automatic scan the GUI transitions to state in which it displays the automatic scan GUI operations. Examples of GUI operations during an automatic scan are provided in section II.D. When the automatic scan ends the GUI transitions back to state .

When the image capture application is in state the user can select a new scanner or select a camera or memory device. When a new scanner is selected the GUI transitions to a new iteration of state in which the GUI displays the controls for the newly selected scanner instead of the pervious scanner. An examples of a GUI displaying scanner controls in state before such a transition is provided above in . An example of a GUI displaying new scanner controls in state after such a transition is provided above in .

When the image capture application receives a selection of a camera or memory device when the GUI is in state or state the GUI transitions to state . In state the GUI displays camera memory device controls. In some embodiments the image capture application treats memory devices with images in a similar manner to digital cameras with memory in them. Accordingly some applications provide similar interfaces for cameras and memory devices with slightly different controls depending on whether the device is a camera or a memory device. Other embodiments provide separate states for controlling cameras and memory devices. An example of the GUI in state is provided as the last stage in described above. The user can direct the image capture application to perform various camera operations such as downloading pictures. When the image capture application receives a command to perform a camera operation the GUI transitions to state . When the camera operation is complete the GUI transitions back to state . As was the case in state the user can select a new camera memory device or scanner. When the user selects a new camera the GUI transitions from state to a new iteration of state with the controls for the new camera displayed. When the user selects a scanner the GUI transitions to state .

One of ordinary skill in the art will understand that the state diagram is a conceptual representation of the states of the image capture applications of some embodiments and does not include every possible state or every possible transition between states. For example in some embodiments a user can select a new image capture device during a manual scan in state .

Some embodiments of the invention provide an auto scan feature that automatically decomposes a scanned document into one or more component regions. In some embodiments the auto scan feature directs the scanner to produce the scanned document by performing an initial scan. The scanned document sometimes referred to as a scanned electronic document can be an electronic image of one or more items placed on the scanner glass i.e. a single image of one or more items placed on the scanner glass of a flatbed scanner or a page passed through a document feeder on a scanner. The auto scan feature then identifies a set of attributes of the scanned document selects a set of optimal scanning parameters based on the identified set of attributes and then directs the scanner to perform a detailed secondary scan with the identified set of scanning parameters. Following the secondary scan some embodiments of the invention perform post scan operations.

The first stage shows two pieces of content being scanned by the scanner . One piece of content is a text document while the other piece of content is an image document . These two pieces of content could be two sections of a single document placed on the scanner bed of a flatbed scanner or of a single document fed through a document feeder of a scanner. These two pieces of content could further be two separate items placed on the scanner bed of a flatbed scanner. As shown in the stage the two pieces of content are not aligned with the edge of the scan area. In the first stage the dashed arrows conceptually illustrates an initial scan being performed by the scanner. As shown in the second stage this initial scan produces a scanned document which includes a relatively low resolution copy of the photo and a relatively low resolution copy of the text .

At the third stage the auto scan operation identifies two component regions and in the scanned document . The two component regions and are the two regions that included the photo and the text . To ascertain the borders of component regions and to distinguish the component regions from background and noise artifacts some embodiments of the invention perform a series of image processing operations on the scanned document and intermediate binary image document . In some embodiments these operations include thresholding seed filling group seed filling edge detection and Hough transform. These operations will be further described below by reference to .

At the fourth stage the auto scan operation analyzes each component region to identify a set of attributes for each component region. Examples of such attributes include the type of content e.g. text image etc. the color of the content e.g. black and white grey scale color etc. and the orientation of the component region. In the example illustrated in the operation identifies two sets of attributes and for the two component regions and . Specifically it determines that the component region is a color image with a tilt of plus 15 degrees while it determines that the component region is a black and white text with a tilt of minus 15 degrees.

In the fifth stage the auto scan feature derives a set of scan parameters for each component region according to the component region s identified attributes. Having identified component region as a color image the operation specifies a set of scan parameters for example which calls for a secondary scan performed at 150 dpi using 24 bit color. Likewise for black and white text component region the operation specifies a set of scan parameters for example which calls for a secondary scan performed at 300 dpi using 1 bit black and white coding. The operation derives the scan parameters to optimize the secondary more detailed scans based on the attributes of each component. Also at stage the operation in some embodiments identifies one or more post scan parameters and for component regions and . One example of such a post scan parameter includes the amount that each component region has to be rotated after the secondary scan.

In the sixth stage the auto scan feature performs two secondary scans each for a different component region or . The operation performs each secondary scan by using the scan parameters or derived from the component region s attributes during the fifth stage . Unlike the second stage where the entire scan area is scanned the operation performs each secondary scan in some embodiments by scanning only the component region or that it is scanning in that iteration or a region that bounds that component region. The dashed arrows and conceptually illustrate that the secondary scans of component regions and take place separately and that these scans are about each region being scanned.

At the seventh stage the auto scan operation performs post processing after the secondary scan. The scanned images and are post processed separately. The image is the result of the secondary scan of component region whose post scan parameter calls for a rotational adjustment of minus 15 degrees. Likewise the image is the scan of component region whose post scan parameter calls for its rotation by 15 degrees and performance of OCR to produce a text file.

The process starts when the image capture application receives an auto scan command. In some cases the image capture application receives the auto scan command after the user places one or more documents on a scan bed or in a document feeder. The image capture application then receives in some embodiments the auto scan command when the user presses a button on the device e.g. on the scanner or multi function device or the user selects an auto scan option in the application s UI. The auto scan command can be generated differently in other embodiments.

Next the process determines at whether it needs to try to parse the document into its individual component parts. As mentioned above the image capture application in some embodiment makes this determination based on whether the user has made the selection e.g. checked the box to detect multiple images in the scanned document. If so then the process performs at an initial scan. Otherwise the process proceeds to operation which is described further below.

The process directs at a scanner to perform an initial scan. The initial scan is performed at a relatively low resolution setting in some embodiments in order to save time and to reduce complexity. Many scanners are capable of scanning at multiple resolutions and color depths. However the amount of data generated by a high resolution scan of the entire glass of a scanner can be relatively large. For example an uncompressed image of a scan at 9600 dpi and 24 bit color is over 275 megabytes per square inch. The area of the glass of a scanner can be greater than 100 square inches. A high resolution scan of such a glass could result in an image file tens of gigabytes in size. Therefore in some embodiments an initial scan sometimes called a preview scan or an overview scan at a relatively low resolution is performed to allow the application and or the user to select particular areas or interest for more detailed scans.

The initial scan produces at a scanned document. In the case of a flatbed scanner the scanned document is a low resolution image of the scanner bed on which the user may simultaneously place multiple items such as a photo and a page of text. Alternatively in case of a scan that is performed through a document feeder the scanned document is a low resolution copy of the page passing through the feeder. The scanned document includes both regions with content and regions without. Regions without content are background regions which correspond to the image inside of the scanner s cover or blank spaces in the page being scanned. Background regions may contain noise due to debris shadow light leakage or other unwanted artifacts. Regions with content in a scanned document may simultaneously include black and white content color content text photos and or other types of contents. Further different regions in the scanned document may be tilted and thereby not aligned with each other or with the boundaries of the scan bed area or document.

After producing the initial scan the process identifies at one or more component regions in the scanned document i.e. the document generated at . A component region is a contiguous section in a document 1 that is distinct and separate from other possible sections and 2 that is identified by the process as having content rather than being mere empty background. The identification of component regions also gives the component regions definite sets of borders which in some embodiments serve as the component regions scan boundary during the secondary scans. The region identification operation will be further described below by reference to .

As mentioned above a scanned document may be a copy of the scanner bed or a copy of the document currently passing through the document feeder. A component region identified from a scanned document can come from an item on the scanner bed. A component region may also come from a section of a document sitting on the scanner bed that are distinct and separate from background and other sections. conceptually illustrates and compares the identification of component regions from separate items on the scanner bed with identification of component region from a single document. In sitting on top of a scanner bed is a single document . Within the single document are a photograph section and a text section . After an initial scan produces a scanned document the process identifies component regions and which are sections of the scanned document that are distinct and separate from background and other sections. On the other hand sitting on top of a scanner bed are two separate items and . After an initial scan produces a scanned document the process identifies component regions and which correspond to the separate items and on the scanner bed.

Once the component regions from the scanned document are identified the process selects at one of the identified component regions. The process then identifies at a set of attributes for the component region selected at . Examples of such attributes include the type of content e.g. text image etc. the color of the content e.g. black and white grey scale color etc.

Some embodiments identify the attributes of the component region by analyzing the pixels within the component region. For example color is one identified attribute when the process determines that the pixels have an amount of chrominance more than a predetermined threshold. Conversely when the process determines that the component region pixels have an amount of chrominance less than a predetermined threshold the process identifies black and white as the attribute of the component region. The process also identifies an attribute of a component region as text where a sufficient number of English words are recognizable. Otherwise it identifies the attribute as either photo or graphics. Some scanners are capable of providing a set of attributes from its own analysis of the scanned document. In those instances some or all scanner identified attributes may be incorporated into the component region s set of attributes.

When a region includes different types of content some embodiments assign the region a default set of attributes in some embodiments. Other embodiments assign the region the set of attributes belonging to the most dominant content in other embodiments. Some other embodiments identify the different sub regions within the component region. One of ordinary skill would recognize that other methods of handling a component region that includes different types of content are available. For example the image capture application may prompt the user for further instructions.

After identifying at the set of attributes for the component region selected at the process directs at the scanner to perform a detailed secondary scan of the selected region. In some embodiments the process uses at the attributes identified at to identify an optimal set of scan parameters for the selected component region. The process then uses at these detailed parameters to perform the secondary scan of the selected region. For example when the region has been identified as having a color image the process uses in some embodiments the scan parameters of 150 dpi dots per inch and 24 bit color encoding. Alternatively when the region has been identified as containing only black and white text the process uses in some embodiments default scan parameters of 300 dpi 1 bit black and white encoding.

To ensure the quality of the scanned image some embodiments use 24 bit color encoding to preserve color fidelity of a color image and 300 dpi to preserve textual readability of a text. Where such image quality is not needed some embodiments use lower resolution settings such as 1 bit black and white encoding or 150 dpi scan resolution to conserve computing resources. One of ordinary skill would recognize that these scan settings are merely illustrative examples and that other considerations may lead to different optimal scan settings.

In some embodiments the process directs at the scanner to only scan the boundary of the selected component region i.e. to forego the scanning of other identified component regions . This allows the scanner and the image capture application to process each scanned region faster. Many scanners are capable of performing high resolution scans of specified portions of the glass while ignoring other portions of the glass. Accordingly time can be saved by automatically selecting portions of the glass on which to perform higher resolution scans.

After obtaining the secondary scan of the component region the process performs at post scan operations on the scanned component region. Examples of such post scan operations will be described further below by reference to . After performing at post scan operations the process determines at whether it still needs to perform a secondary scan of other component regions identified at . When the process determines at that it still needs to generate the secondary scan of one or more other component regions it transitions back to operation to select another component region. It then repeats operations . When the process determines at that it has generated the secondary scan for all component regions identified at the process ends.

As mentioned above the process transitions from to when the process determines at that it should scan the whole scanner glass or fed through page rather than individual component parts. At the process directs the scanner to generate a scan of the document i.e. of the scanner bed or of the document placed in the document feeder of the scanning device.

In some embodiments the process directs at the scanner to generate the scanned document as a detailed scan of the scanner glass or of a page fed through the scanner. However in other embodiments the process directs at the scanner to perform two stage scanning operations that are similar to operations and . In other words at operation the process in some embodiments directs the scanner to first produce an initial scan. It then identifies a set of attributes for the document from the initial scan selects a set of scanning parameters based on the identified set of attributes and then directs the scanner to perform a secondary scan with the selected set of scanning parameters. Following the secondary scan the process performs post scan operations in some embodiments. After operation the process ends.

One of ordinary skill will recognize that process is an example of one possible process performed by some embodiments in order to perform the auto scan process. Process is not necessarily the only example of how to identify component regions. Operations in the process can be performed in a different order. For example the process can perform operation after namely performing post scan operations on scanned images after the process has completed the detailed secondary scans of all component regions. The process may also perform operation before namely identifying a set of attributes for each component region before selecting a component region for detailed secondary scan.

As shown in the process starts at when it receives a scanned document from an initial scan. The scanned document includes images of content as well as background and noise. is an example screenshot of a scanned document . As shown in this figure the scanned document includes two sections with content namely regions and . This figure further shows that the scanned document includes noisy artifacts such as shadow and light leakage .

Next the process performs at thresholding on the scanned document to produce a binary document. A binary document has only two colors unlike a color or gray scale document which may have hundreds or even millions of colors. Thresholding is the operation that converts color or gray scale pixels into black and white pixels. In some embodiments thresholding marks a pixel as black if its luminance value compares in a predetermined manner to a certain threshold value e.g. less than and as white if otherwise. illustrates the result of a thresholding operation on the scanned document of . In binary document the region is a binary image version of the region after thresholding while the region is the binary image version of region after thresholding. Both regions and still contain unfilled white regions. Noisy artifacts are also present in this binary document. The artifact is the binary image of the shadow while the artifact is the binary image of the light leakage.

After performing the thresholding operation the process performs at a seed filling operation to fill all bounded regions in the binary document. In some embodiments seed filling floods all regions in the binary document that are bounded by black pixels with black pixels. In other words seed filling leaves only white regions not bounded by black pixels. These white regions are the background regions.

Next the process eliminates at noisy artifacts from the binary document and indexes the remaining black regions. As illustrated in noisy artifacts continue to be present in the binary document after the seed filling operation. Artifact is the binary image of the shadow while artifact is the binary image of the light leakage .

In some embodiments the process cleans up at these artifacts with a group seed filling operation. Group seed fill is a variant of the seed fill operation. In applying the group seed filling operation at the process steps through each black region in the binary document to determine whether the black region is too small in size or too odd in shape to have content. If the black region is too small in size or too odd in shape to have content the process fills the region with white pixels and eliminates it from the binary document. Otherwise the process leaves the region intact and gives it an index.

After applying group seed fill the process selects at a component region. In some embodiments the process selects a component region based on the index assigned to it during group seed filling. illustrates the selection of a component region from the binary document . As mentioned above binary document at the end of group seed filling includes two component regions and with indices and . The process uses index to select component region and masks the unselected component region . The result of this operation is the binary document which has only one component region . The marker identifies the location of the masked component region .

After selecting at a component region the process performs at edge detection on the selected component region in order to detect its borders. In some embodiments the edge detection is accomplished by using a Sobel operator which calculates the gradient of the image intensity at each point of an image. Because the binary document after thresholding and seed filling operations contain only regions of uniform image intensity applying the Sobel operator results in the borders of these regions. illustrates the result of applying the Sobel operator to the binary document that remains after the selection of the component region . As shown in this figure the application of the Sobel operator results in the document a region . The region specifies the borders of the component region .

Next the process performs at a Hough transform on the borders of the component region. The Hough transform identifies a set of lines that best represent the borders of the regions identified by the Sobel transform. The Hough transform mathematically generates a series of curves based on a series of test lines through the points on the border. For each point on the border the Hough transform generates a curve in a parameterized space the Hough space that relates the angle of the test line to the distance of the test line from the origin. A point in the Hough space at which large numbers of curves intersect represents the angle and distances of lines that lie along a particular edge of the border. The Hough transform algorithm uses these points to identify lines that lie along the edges of the regions identified by the Sobel transform.

After performing the Hough transform the process determines at whether there are more component regions to be selected. In some embodiments the process makes this determination by checking whether the number of component regions already scanned is equal to or more than the total number of component regions in the scanned document. If so process proceeds to to eliminate falsely identified component regions. Otherwise the process transitions back to operation to repeat this operation and operations for each component region.

At operation the process eliminates falsely identified component regions. False identification of component regions may occur in some embodiments due to peculiarities within the scanned document. For example the layout of the content within a component region may cause some embodiments to falsely identify a component region within the boundary of another correctly identified component region. conceptually illustrates how the process eliminates a falsely identified component region for the above mentioned example.

In an image includes two sections and separated by a gap . The gap can be a boundary defined by the document. The gap can also be an artifact in the image created by lighting or other conditions. Thresholding and seed filling of the image produces binary document which separates the image into a large L shaped component region and a smaller rectangular shaped component region . The smaller rectangular shaped component region is not a real component region but merely a sub region of the image . The process applies Sobel edge detect to component regions and to yield regions and . The process then applies Hough transform to region and correctly identifies rectangular component region which corresponds to the image . However the process also applies Hough transform on region and falsely identifies a smaller component region .

The process then eliminates the smaller falsely identified region . Some embodiments identify and eliminate all regions that lie within another region thereby eliminating falsely identified regions such as the region . One of ordinary skill will recognize that other methods of eliminating falsely identified regions are available. For example the process may eliminate all regions that are too small and too oddly shaped to be a component region. After eliminating at falsely identified component regions the process ends.

The operations will now be explained again in order to finish describing the example illustrated in . When the process returns to it selects the component region as illustrated in . As mentioned above the binary document includes both component regions and with indices and . Having already performed edge detect and Hough transform on component region the process uses index to select the component region and masks . This results in the binary document which has only one component region . illustrate subsequent operations on the component region . The region in is the result of Sobel edge detect on the component region . illustrates the result of Hough transform on the region . The four intersect points and are used to create a bounding box to graphically identify the component region . Since the component region is the last component region the process proceeds to operation and ends.

One of ordinary skill will recognize that process is an example of one possible process performed by some embodiments in order to identify component regions. Process is not necessarily the only example of how to identify component regions.

The process starts when it receives a secondary scan of a component region. The process initially identifies at a set of post scan parameters. Post scan parameters control a post scan operation that the process performs on the component region. These parameters specify whether the process should perform an OCR operation rotate the scanned region send the scan result to a particular application store the scan result etc. The process may identify one or more post scan parameters by analyzing the secondary scan of the component region. The process may also derive these post scan parameters from various data e.g. the set of attributes of the component region generated by the process or the process .

After identifying a set of post scan parameters the process rotates at the component region if necessary i.e. if specified by the post scan parameters. The process rotates the component region by a rotational adjustment angle. In some embodiment this rotational adjustment angle is identified when process performs the Hough transform. Since the coordinate of an intersect point on the Hough plane correspond to the angular separation between a component region s border and the horizontal the process of some embodiments uses the angle to arrive at the necessary rotational adjustment. In some embodiments the process performs an image transform by using the rotational angle in order to realize the adjustment.

Next the process performs at an OCR on the component region if necessary. The OCR operation if performed produces text. Some embodiments perform this operation only if the component region has been determined to include text as result of the initial or secondary scan.

After performing the OCR operation the process performs at a document recognition operation to identify structural elements in the text. The OCR in some embodiments results in an unstructured document containing a collection of glyphs or characters without any structures such as lines paragraphs or columns. The document recognition process identifies these structural elements and these elements are used in some embodiments to construct a structured document from the unstructured document. Structural elements of some embodiments include associated primitive elements e.g. words paragraphs joined graphs etc. guides gutters text flow tables etc. These structural elements are related in a hierarchical manner in some embodiments e.g. a paragraph includes text lines a text line includes words and a word includes primitive glyphs . Several document recognition processes are described in a non provisional U.S. patent application Ser. No. 12 455 866 filed concurrently with this application with the title Identification of Layout and Content Flow of an Unstructured Document which is incorporated herein by reference.

The process then converts at the result of the above mentioned operations into another data format if necessary. For example in some embodiments the process converts OCR recognized text or the resulting structured document into ASCII Word WordPerfect PDF HTML or any other format capable of supporting a text document. Some embodiments use the structural elements identified at to assist in the format conversion. The process may also convert an image aligned at into Bitmap TGA TIFF GIF JPEG or any other format capable of supporting graphical images. The conversion of an image however is performed in some embodiments as part of the image transform operation that some embodiments perform at .

Next the process stores at a post processed scan data into a storage medium if necessary. A post processed scan data may be an OCR recognized text a structured document an aligned secondary scan converted scanned result or other data derived from detailed second scan. The process may save any of these post processed data into a hard disc random access memory or other types of storage medium accessible by computer.

Finally the process forwards at the post processed scan data to a destination application if necessary. Applications other than the image capture application may serve as the destinations for any type of post processed scan data. For example the process can forward the scanned result to image editing application word processor program print server mail program any application capable of view or editing text or other types of applications that are capable of handling the post processed scan data.

Some embodiments also communicate a message to the destination application on how to handle the post processed scan data from the image capture application. In some embodiments this message is a command or a script understood by the destination application. For example some embodiment sends an open image command in order to notify the destination application that the image capture application is about to deliver an image. In another example the process may execute a script to instruct a mail application on how to compose a message using an OCR recognized text as the body of the message and a scanned image as the attachment.

One of ordinary skill will recognize that process is an example of one possible process performed by some embodiments in order to perform post scan operations on a component region. Process is not necessarily the only example of how post scan operations are performed. For instance operations and need not necessarily be performed in the order shown in .

Moreover even though the description above describes the document recognition processes as being applied to OCR text other embodiments apply document recognition processes to scanned documents that contain other types of primitives. For instance when the scanned document contains region containing text and a region containing an image some embodiments OCR the text to produce glyphs and then define the image s bitmap as a primitive element along with the glyphs. Some embodiments then use the glyphs and bitmap to perform additional document recognition processes to try to define additional structural elements for the scanned document.

During the auto scan operations described above some embodiments display the image data as it is received. The displays provide visual feedback to the user to demonstrate the progress of the auto scan process. In some embodiments the visual feedback is provided in a scan display area of a GUI such as GUI shown in . Examples of the displays of some embodiments at various stages of an auto scan process are provided in .

As mentioned above while a preview scan is being performed the GUI of some embodiments displays an image of the portion of the glass scanned so far. In this figure the image capture application has received image data from the top of the scanner to a line in the middle of item . Accordingly the scan display area shows an image of part of item . While the preview scan is in progress the GUI does not display indicators e.g. bounding boxes of the locations and rotations of the partially scanned item . The lack of displayed bounding boxes is because the location and rotation angles of the separate items on the glass have not yet been determined from the data produced by the preview scan. Before the regions are identified the GUI does not produce bounding boxes.

The lack of bounding boxes is not the only indication in the GUI that the scan currently in progress is a preview scan. Some embodiments such as the one in this figure provide a status indicator to inform the user that a preview scan is in progress rather than a detailed scan e.g. by displaying quickscan . Additionally to indicate that a scan preview or detailed is in progress some embodiments gray out render non selectable all of the scanner controls except the cancel button . The cancel button remains selectable so that the user can abort the auto scan before it is complete. For example if the preview scan reveals that the wrong items were placed on the scanner the user can abort the auto scan before images of the wrong items are saved by clicking the cancel button .

In this figure the detect separate items toggle is checked. Accordingly the image capture application has identified the regions and the GUI has provided bounding boxes and to surround the identified regions. The bounding boxes provide a visual indicator of the identified regions. By providing a visual indicator of the identified regions the image capture application allows the user to determine whether the identified regions contain the particular parts of the glass that the user is trying to scan. If the identified regions are not what the user wants the user can abort the scan. The user can then change to the more complicated GUI described in section I e.g. by clicking the show details button shown in . The user can then initiate a scan with manual override options as described in section III below. Some embodiments pause briefly at this point to allow the user time to abort before the detailed scans begin. Other embodiments do not provide the display shown in but instead proceed directly from the preview scan to the detailed scans without showing the identified regions before starting the detailed scans.

In some embodiments while the image capture application receives the detailed scan data for a particular item the scan display area shows a faded preview and then progressively replaces the faded preview with non faded images of the detailed scan as the detailed scan data is received from the scanner. In some embodiments the data is adjusted before it is displayed.

In the detailed scan of image is progressively revealed at right angles to the image . That is during the detailed scan of image the image capture application progressively reveals the received data as a series of angled slices of pixels of image . This demonstrates to the user how much of the final scanned image has been received. The slices of pixels are angled relative to the glass but are at right angles to the edges of the image . The image capture application reveals each angled slice of pixels only after it has the image data for every pixel in the entire angled slice of pixels.

Most scanners do not capture images in angled slices of pixels. As explained in section I in relation to scanners capture images in thin horizontal lines of pixels. The image capture application receives the data in the same manner as horizontal slices of pixels from the top of the bounding rectangle to the bottom of the bounding rectangle. However the image capture application of some embodiments receives the scanned image as horizontal slices of pixels and reveals the scanned image as angled slices of pixels.

In order to display the scanned data as angled slices of pixels the image capture application of some embodiments refrains from revealing all received detailed scan data. In the image processing application has received data in the area between demarcation and the bottom of bounding box . However the image capture application does not reveal the received scan data from below demarcation because the image capture application has not received all the pixels of any angled slide of pixels from below demarcation .

One of ordinary skill in the art will realize that bounding box is shown in to conceptually show the area scanned so far. Some embodiments display such a bounding box aligned with the glass during a detailed scan. Some embodiments do not display a bounding box aligned with the glass during a detailed scan of an identified region but do display a bounding box aligned with the region such as bounding box in . In contrast to the embodiment illustrated in some embodiments reveal the detailed scan as in slices of pixels that are horizontal relative to the scanner glass.

Once the detailed scan of item is complete the image capture application begins a detailed scan of the next identified region. In this case the region containing item . In some embodiments the image capture application directs the scanner to perform the detailed scan of each identified region separately from the detailed scans of the other identified regions. Therefore the scanner does not scan the areas between the bottom of an identified region and the top of another identified region.

The previously described illustrate the GUI during an auto scan when the detect separate items function is on. Some embodiments also perform auto scans without detecting separate items. Such an auto scan will sequentially 1 display the images garnered from the preview scan while the preview scan is in progress in the same way as previously shown in and 2 identify a single region encompassing all the items on the glass as shown in and 3 display the images garnered from a single detailed scans of that single identified region while the detailed scan is performed as shown in which are described below.

As mentioned above until the preview scan is complete an auto scan that does not detect separate items is the same as an auto scan that does detect separate items. Accordingly the description of the GUI in relation to applies to auto scans that do not detect separate items. In an auto scan that does not detect separate items the image capture applications automatically detects a single region that encloses all the items on the glass. illustrates the GUI with a single bounding box around an automatically identified region. The region encloses all the items on the glass because the image capture application has been set to not detect items separately. includes bounding box . Bounding box identifies the region that will be scanned in a detailed scan.

As was the case for bounding boxes in auto scans that identify separate regions the bounding box provides a visual indicator of the items to be scanned. If the identified region does not enclose the images the user wants to scan the user can abort the scan. The user can then change to a GUI that performs manual scans. As with auto scans that detect separate items some embodiments pause briefly at this point to allow the user time to abort before the detailed scan begins. Other embodiments do not provide the display shown in but instead proceed directly from the preview scan to the detailed scans without showing the identified regions before starting the detailed scans.

Just as in auto scans that detect separate items in some embodiments while the image capture application receives the detailed scan data for the single region the scan display area shows a faded preview and then progressively replaces the faded preview with non faded images of the detailed scan as the detailed scan data is received from the scanner. illustrates a GUI as it progressively displays the results of a detailed scan. The detailed scan is a scan of the single automatically identified region. includes demarcations . Demarcation conceptually separates the display of the detailed scan of the region in bounding box from the faded display of the preview scan of the region.

During the detailed scan of region the image capture application progressively replaces the faded preview with the detailed scan. Unlike the replacement of the preview in the replacement here is not performed at right angles to the individual items and . The replacement is performed at right angles to the bounding box . However as bounding box is already aligned with the glass each slice of pixel data from the scanner provides a full slice of data at right angles to the bounding box . Therefore the image capture application reveals all scan data as it comes in.

Unlike the detailed scan of separate items shown in the detailed scan in is being performed for the entire region rather than for the individual items and . Accordingly when the scanner has finished scanning the part of the glass containing item the scanner continues to scan the area between items and instead of skipping that area as it did when performing the scans in . illustrates the detailed scan of region when the scan is between two items. The scanner head has passed the bottom of item but has not yet reached the top of item . Accordingly demarcation line is between the items and .

Eventually the scanner head reaches the top of item and continues to scan it as part of the single region in bounding box . illustrates the detailed scan of region when the scan is in the middle of item . Here the scanner head has reached the middle of item . Accordingly demarcation line is across item indicating that scan data for the upper portion of item has been received by the image capture application.

As mentioned above the image capture application of some embodiments provides an automatic scan operation that 1 identifies different regions in an initial scanned documents 2 re scans these different regions separately based on parameters that are optimized for each region and 3 post processes the individually scanned regions e.g. post processes different regions differently . In addition or in lieu of this auto scan feature the image capture application of some embodiments also includes a set of manual scanning tools that allow the user to 1 manually adjust the regions to be scanned i.e. the location size and orientation of the scanned regions 2 manually adjust the scan parameters e.g. the scan resolution the scan color etc. for each region and 3 activate a detailed scan.

With the exception of the manual selection tool the GUI of includes many of the same basic elements as the GUIs described in section I with a layout that closely resembles that of GUI in . As mentioned above a user can invoke the manual selection tool to bound a particular region that is initially identified through a pre scan operation by selecting e.g. clicking or double clicking on the region. As shown in this tool can be a rectangle with a circle inside of it. The rectangle is moveable e.g. by a drag operation to move the location of the selection tool. Also the sides of the rectangle are independently moveable i.e. each side can be moved independently of the other sides of the rectangle to adjust the size of the rectangle. The circle has a handle that a user can select and drag to rotate the bounding rectangle of the manual selection tool.

The operations of GUI will now be described in relation to the four stages . The first stage shows the GUI after a preview scan has been performed. The image capture application has identified two regions and of the scanner glass as containing separate items e.g. two separate photographs . The image capture application has automatically selected the identified regions and to be the default areas for a future detailed scan. The rectangles around regions and provide the user with a visual representation of the current boundaries of the regions. The user can select the regions and to activate a manual selection tool to modify the areas of the future detailed scan. The preview scan automatically identified separate regions and because the detect separate items toggle is checked. The preview scan could have been performed automatically upon the selection of scanner icon or commanded by the overview button .

In addition to identifying the regions and some embodiments automatically identify the type of content in each region e.g. color or black and white photograph . As described in section II the image capture application of some embodiments automatically determines scanning parameters for a subsequent detailed scan of each region. In the first stage some embodiments leave the controls blank because the user has not yet selected a region for editing. Once a particular region or is selected the automatically determined scanning parameters for that region will be displayed as settings of the generic scanner controls and scanner specific controls . As mentioned above the user can select e.g. by clicking or double clicking one of the identified regions or to activate the manual selection tool to operate on that region. Other embodiments display as a list the automatically determined scanning parameters of each region even before the user selects a region.

The second stage shows the manifestation of the manual selection tool . The manual selection tool is displayed by GUI in response to the user s selection of region . Manual selection tool has manifested over the selected region . Some embodiments display the manual selection tool as a rectangular border with a circle inside it. The circle has a handle . A user can 1 adjust the size of the manual selection tool by dragging an edge or a corner of the border 2 rotate the manual selection tool by dragging the handle and 3 move the manual selection tool by dragging any place in the manual selection tool that does not command a rotation or resizing. By adjusting the manual selection tool the user can select a sub region of the identified region image include some of the background of the scanner or even scan parts or all of multiple images.

The selection of the region also causes the GUI to display the automatically determined scanning parameters as settings of the generic controls and the scanner specific controls . In stage the generic controls are all set to auto to conceptually illustrate that they are set to the automatically determined parameters. In some embodiments the scanner specific controls are also set to automatically determined scanning parameters.

In other embodiments the image capture application do not automatically set scanning parameters for the scanner specific controls but rather sets the scanner specific controls to default options specified in the scanner driver. Therefore in stage the scanner specific controls and are set to default . The parameter names auto and default are conceptual identifications only and are not intended to indicate the names of actual parameters. The manual editing process allows the user to change the automatically selected settings of the generic controls and the default settings of the scanner specific controls and . Changes to the controls are shown later in relation to the fourth stage .

Returning to the manual selection tool stage shows the manual selection tool surrounding the entire region indicating that a detailed scan at this stage would capture the entire picture in region . However the user may want to capture a smaller portion of region . For example the user may want to focus on the section of region that includes an airplane. The third stage shows that the user has adjusted the manual selection tool to closely surround the section of region that includes the airplane.

A user may employ many sequences of movement rotation and resizing of the manual selection tool to select an area within the region selection tool . illustrates one such possible sequence of adjustments of the manual selection tool . The sequence includes five substages that change the selected region from the area shown in second stage to the area shown in third stage of . The first substage shows a movement of the manual selection tool the second substage shows a rotation of the manual selection tool the third and fourth substages show alterations of the size of the manual selection tool . The figure includes original state substages and cursor . Original state shows the manual selection tool just after it has been selected. The substages show how the manual selection tool is manipulated e.g. by the user to perform each adjustment to the region for scanning. The cursor shows which part of the manual selection tool the user dragged to perform the operation of each substage.

The first substage shows the end of a movement operation of the manual selection tool . In the movement operation the user has clicked and dragged the manual selection tool with cursor . As shown by the position of cursor in the manual selection tool the user clicked on a part of the manual selection tool that does not activate a rotation or resizing operation i.e. anywhere other than the handle or border . As mentioned above clicking and dragging a part of the manual selection tool that does not activate a rotation or resizing operation moves the manual selection tool . The user dragged cursor to the upper right which moved the manual selection tool to the upper right. Then the user released cursor at the position shown in the first stage .

The second substage shows the end of rotation operation of the manual selection tool . The rotation operation started with the manual selection tool in the same location as shown in substage . All the completed operations shown in this figure start with the manual selection tool in the position size and orientation shown in the previous stage. The user moved the cursor to the handle . The user then clicked and dragged the handle with the cursor . Specifically the user moved the cursor down which moved the handle down. By dragging the handle down the user rotated the manual selection tool into the position shown in the second substage . In some embodiments dragging on the circle would also rotate the manual selection tool .

The third through fourth substages show various resizing operations. The third substage shows the end of a first resizing operation of the manual selection tool . In the resizing operation of the third substage the user clicked and dragged the right border of the manual selection tool and to the left. This reduced the size of the region .

The fourth substage shows the end of a second resizing operation of the manual selection tool . In this resizing operation the user has clicked and dragged the upper left corner of the manual selection tool down and to the right. In the embodiment shown in this figure dragging a corner of the manual selection tool changes the size of the manual selection tool while keeping the aspect ratio the ratio of height to width constant. In other embodiments dragging a corner of the manual selection tool allows the user to freely change the length of both sides of the manual selection tool that are connected to the dragged corner. As shown in this figure moving rotating and changing the size of the manual selection tool has not affected the image in region . The movement and rotation of manual selection tool has not affected the image in region because the manual selection tool is for selecting an area of the glass to scan it is not a tool for editing the images in the preview scan.

The sequence of operations shown in this figure has produced the change in the size orientation and location of the manual selection tool seen when going from the second stage to the third stage in . However this sequence of operations is not the only sequence that would produce such a change. One of ordinary skill in the art will realize that the operations shown could be performed in any order to produce the same change. Additionally equivalent sequences can make the same changes without exactly duplicating the individual operations shown. For example the movement operation could be replaced with multiple border shifting operations.

Returning to in the third stage the options in the controls and options are the same as in the previous stage indicating that the user has not yet changed the scanner control options set by the image capture application. Between the third stage and the fourth stage the user does change those settings.

The fourth stage shows user modified settings. The user has changed the settings of some of the generic controls and scanner specific controls . Specifically the user set control to option D control to option C and control to option B. The user has not changed the settings of controls and so those controls remain at the automatically selected or default values. Specific types of controls with parameters that the user can adjust are described in more detail below.

One of ordinary skill in the art will understand that although the stages are shown in in a particular order other embodiments may receive adjustments to the location size and orientation of a region after receiving adjustments to the scanning parameters in the scanner control area or receive multiple adjustments of the controls and the manual selection tool in any order.

The manual selection tool includes multiple features to indicate the angle of the tool including handle and the alignment of the border . However other embodiments may provide different or additional indications of the rotation of the manual selection tool. illustrates two examples of manual selection tools with additional angle indicators. The angle indicators shown can be used along with the previously described indicators or can function independently. The figure includes manual selection tool which includes angle indicator and manual selection tool which includes angle indicator . Angle indicator is a stylized human figure. Angle indicator is a numerical readout of the angle of the manual selection tool . When manual selection tool rotates angle indicator rotates with the tool. The head of the stylized human figure points in the direction that the GUI will treat as up during a detailed scan of a region selected by manual selection tool . In contrast when manual selection tool rotates the numerical readout of angle indicator updates to display the new angle of the manual selection tool .

In some embodiments a manual selection tool might be invoked or implemented differently than as described above. In some embodiments such as the embodiments described above this tool is invoked by a user selecting a region that is identified as a separable region in the scanned document. This invocation causes the tool to appear to bound the selected region. Instead or in lieu of this manner of invoking the tool some embodiments allow a user simply to select the tool from the GUI and to use the tool to bound any identified region in the scanned document.

The sections that follow describe various aspects of the manual override features of some embodiments. Section III.A. describes the way that the GUIs of some embodiments display automatically identified regions to the user before the user selects a region for editing. Section III.B. describes the results of detailed scans performed after various adjustments to a manual selection tool. Section III.C. describes guidelines that show the frame of reference of the identified regions during adjustments to the manual selection tool. Section III.D. describes manual overrides of various automatically identified parameters for performing a detailed scan on an automatically selected region.

One parameter that a user can control is whether the image capture application will present the results of the preview scan as separate items or as a group of items. A basic user interface for detecting separate regions is described in section I in reference to . However some embodiments provide additional indicators of the separate regions when the regions are presented to the user for manual editing. illustrates a GUI that provides visual indicators of the size location and orientation of identified regions when a detect separate items option is selected. The visual indicators help to distinguish between states of the GUI in which separate regions are selectable and states in which a single region is selectable. includes angle indicators and . Angle indicators and are visual indicators of the presence and orientations of the two identified regions in bounding boxes and .

The image capture application indicates the selectable regions by displaying the bounding boxes and with angle indicators and superimposed on the regions. The bounding boxes and show the user the separate regions of the glass that will be captured by a detailed scan if the user activates the scan button without adjusting the regions e.g. with a manual selection tool . Angle indicator is superimposed on the picture in bounding box and shows the angular displacement of the bounding box from the horizontal axis of the GUI. One end of the angle indicator is positioned on the center of the identified region to show the user where the center of the region is. The angle between angle indicator and an edge of the preview display area visually presents the identified orientation of bounding box . Angle indicator provides the same visual indications for bounding box as angle indicator provides for bounding box .

In addition to allowing manual editing of separately detected individual regions some embodiments allow manual editing of regions containing groups of items when the detect separate items option is turned off. Such embodiments identify a single region on the glass that encompasses all the items on the glass. The embodiments then provide visual indicators of the size location and orientation of the single identified region. illustrates a GUI that provides visual indicators of the size location and orientation of an identified region containing a group of items when the detect separate items option is not selected. The visual indicators show the angle when the region is a group of items rather than a single item. includes angle indicator . Angle indicator is superimposed on the middle of bounding box and shows the angular displacement of the bounding box from the horizontal axis of the scanner. As mentioned above in some embodiments the bounding box of a group of items is defined by horizontal and vertical lines through the outermost corners of the group of items. In such embodiments the bounding box is aligned with the scanner by default therefore the default angle of the angle indicator is zero. However if a user 1 selected the region in bounding box for manual adjustment 2 rotated the manual selection tool that appeared on the region and 3 unselected the region then the angle indicator would change to show the new angle of the bounding box.

As mentioned above the manual selection tool of some embodiments can move rotate or resize scanning regions. The manual selection tool affects the scanning area not the underlying images. That is shrinking the manual selection tool reduces the portion of the image that will be captured not the size of the image presently shown in the boundaries of the manual selection tool.

Image is a captured image of the entire photograph . Image includes the entire content of the photograph and is the same size as the photograph . Because the user has made no changes with the manual selection tool image is the same image that the image capture application would produce in the automatic scans described in section II. The corresponding operation represents the default selection of an identified region. The manual selection tool completely surrounds the photograph and the borders of the manual selection tool are co extensive with the borders of the photograph. The region was automatically identified after a preview scan and has not been adjusted. A detailed scan after operation produces image .

Image is a rotated image of the photograph . More accurately image is rotated by a different angle than the angle necessary to counter the actual rotation of the photograph relative to the scanner glass. Image includes a counterclockwise rotated view of those portions of photograph that remain in the manual selection tool after the rotation operation . The user rotated the manual selection tool clockwise relative to the default region. Operation shows that the user rotated the manual selection tool by clicking and dragging the handle with cursor . A detailed scan after operation produces image .

Image is a shorter version of an image of the photograph . Image includes a view of the top of the photograph but does not contain a view of the bottom of the photograph . The user shrank the region and cut off the bottom of the photograph with manual selection tool . Operation shows that the user shrank the manual selection tool by clicking and dragging the boundary with cursor . A detailed scan after operation produces image .

Image is an offset image of the photograph . The image shows the lower right portion of photograph . The user moved the manual selection tool down and to the right which moved the region of the detailed scan . Operation shows that the user moved the manual selection tool by clicking and dragging the manual selection tool with cursor . A detailed scan after operation produces image .

Image is an image of photograph and some of the surrounding area of photograph . The user manipulated manual selection tool to expand the region for the detailed scan into the area surrounding the photograph so the image is larger than image and unlike image includes some of the background of the scanner glass. Operation shows that the user increased the size of manual selection tool by clicking and dragging the corner of the boundary with cursor and by other unshown operations e.g. dragging the top and left sides of the boundary outward . A detailed scan after operation produces image .

Some embodiments provide an option to preview the image in the manual selection tool. In such embodiments clicking the control or selecting a set of keyboard keys temporarily shows a view of the images that is similar to the images in . That is the GUI displays a preview of the adjusted region aligned with the edges of the GUI rather than showing the preview with a bounding box of manual selection tool rotated relative to the edges of the GUI. In some embodiments once the control or set of keyboard keys that activates the preview of the image is released the manual selection tool returns to the position and orientation that it had before the preview of the image was activated.

In some embodiments when a user selects a region for editing with a manual selection tool the GUI provides guidelines to show the user the original location and orientation of the automatically identified region. Some embodiments display the guidelines only when the manual selection tool is moved resized or rotated. illustrates a manual selection tool with guidelines of some embodiments. The guidelines provide the user with location and orientation references relative to the originally identified region. includes guidelines . The guidelines outline the originally detected region.

The guidelines provide a set of reference lines that allow a user to identify directions relative to the original region . The guidelines serve two main purposes. First when a user moves rotates or resizes the manual selection tool the guidelines show the user the original position and orientation of the automatically identified region . Second when a user moves rotates or resizes the manual selection tool the extension of the guidelines past the boundaries of the region allow a user to identify places that are offset from the region by right angles to the region. The guidelines show where the manual selection tool is relative to the region . For example if the user moves manual selection tool up along the guidelines then the sides of the manual selection tool will remain aligned with the sides of region . A user can for example align the manual select tool with guidelines to select the entire top half of region .

In some embodiments the manual selection tool snaps to the guidelines when it gets close to them. The snapping feature allows a user to easily move the manual selection tool to a position at right angles to the original position. The snapping feature also helps to restore parameters of the manual selection tool to their original values after they have been changed. For example in some embodiments the snapping feature helps a user to resize a manual selection tool to its original length or width. In some embodiments the snapping tool helps the user return the manual selection tool to its original position or orientation.

The operation of the snapping features will now be described in relation to the stages . As mentioned above stages show the snapping feature during a movement operation. The movement related snapping feature is triggered by the proximity of the manual selection tool to the guidelines. In stages the user drags the manual selection tool with the cursor . The manual selection tool moves progressively closer to the guidelines until it reaches a proximity that triggers the snapping feature. The proximity at which the snapping feature activates is shown in stages by proximity lines . In stage the edges of the manual selection tool nearest to each of the guidelines are still farther away from the guidelines than the proximity lines are therefore the snapping function is not triggered. In stage the manual selection tool reaches the proximity lines and the snapping feature is triggered. Without further dragging of the manual selection tool by the user the manual selection tool snaps to the guidelines as shown in stage .

Stages show the snapping feature during a resizing operation. The resizing related snapping feature is triggered by the proximity between a guideline and the edge or corner being dragged. In stages the user drags the right edge of border with the cursor . The edge of border moves progressively closer to the right side guideline until it reaches a proximity that triggers the snapping feature. The proximity at which the snapping feature activates is shown in stages by proximity line . In stage the moving edge of the border is still farther away from the nearest guideline than the proximity line is therefore the snapping function is not triggered. In stage the border reaches the proximity line and the snapping feature is triggered. Without further dragging of the border by the user the border snaps to the guidelines as shown in stage .

Stages show the snapping feature during a rotation operation. The resizing related snapping feature is triggered by the proximity and angular proximity between a guideline and an edge of a rotating manual selection tool . In stages the user drags the handle with the cursor . The edge the manual selection tool moves progressively closer to alignment with the right side guideline until it reaches a proximity that triggers the snapping feature. The proximity at which the snapping feature activates is shown in stages by proximity line . In stage the moving edge of the rotating manual selection tool is still farther away from the nearest guideline than the proximity line is therefore the snapping function is not triggered. In stage the edge of the rotating manual selection tool reaches the proximity line and the snapping feature is triggered. Without further dragging on the handle by the user the manual selection tool snaps into alignment with the guidelines as shown in stage .

Though the snapping features in this figure were illustrated with proximity lines some embodiments do not visibly display proximity lines. In some embodiments the snap features activate after the cursor is released. That is the user moves resizes rotates the manual selection tool into the proper proximity and then releases the cursor to activate the relevant snap feature. In some embodiments the snap features can be activated by a GUI item a keyboard key or a combination of keyboard keys. In some embodiments the snap features can be temporarily turned on or off. For example some embodiments deactivate the snap features while a user holds down a particular set of keyboard keys and reactivates the snap features when the set of keys are released. In some embodiments the snapping tool only affects the parameter being modified. For example when the user is rotating the manual selection tool the snap feature can rotate the manual selection tool but cannot move the manual selection tool laterally.

This section describes manual adjustments to the automatically selected scan parameters. As mentioned above when the user selects an automatically detected region for editing the automatically selected scan parameters for that region are displayed as settings on the controls in control area .

As described in section II some embodiments automatically select scan parameters for automatically identified regions. The automatically selected scan parameters act as default parameters for subsequent detailed scans of the identified regions. Some automatically selected scan parameters affect the performance of the detailed scan itself. For example the scan resolution parameter determines how many dots per inch the scanner will produce. Other scan parameters affect the processing of the images after a scan is performed. For example scan output format parameters determine the image format in which the image capture application will save the detailed scan. Some embodiments provide the user with various types of scanner controls to manually override the automatically selected scan parameters. Some examples of controls for performing manual overrides for various types of parameters are described below in reference to .

As mentioned above the scanner controls of are set to the automatically selected parameters. The way in which the parameters are displayed depends on the type of control that the GUI provides for that parameter. In this figure controls are menu controls. Menu controls present a set of options to a user in the form of a list or menu . In some embodiments the options are only displayed when the menu control is selected. When the options are displayed the top listed option of a particular menu can represent the current setting of that particular menu control while the lower items on the menu represent other available settings of the menu control. As mentioned the controls in this figure are set to the automatically selected parameters therefore the top menu options of menus are the automatically selected parameters for the selected region. A user could change the selected parameters using menu controls e.g. by clicking on a menu option other than the top listed option . The specific settings and functions of the individual menus are described below.

The image capture application has identified item as a color photo. Therefore the image type menu is set to color photo . The image type menu affects how raw data is gathered by the scanner. For example when the color photo menu option is selected the scanner gathers both chrominance and luminance data about the image and encodes them using the color number set in color number menu . In contrast when the grayscale photo menu option is selected the scanner gathers luminance information about the image but not chrominance information and encodes the luminance information using the color number set in color number menu . If the user wants to scan the photograph in grayscale the user can select the grayscale option of menu control to override the image capture application s selection of the color photo option.

The image capture application has chosen 256 colors as the default color number for a future scan of region . Therefore the color number menu is set to 8 bits. Color number menu determines how many bits to use to encode the color data of each pixel the scanner generates. The color number menu affects the detailed scan itself. The image capture application commands the scanner to use a particular color number which affects what data the scanner will capture. If the user wants more color number the user can select the thousands millions or billions options of menu control to override the image capture application s selection of 256 colors.

The image capture application has chosen to save the image to a .jpg file. Therefore the format menu is set to JPEG . In some embodiments the image capture application receives raw data from the scanner and saves the data in format specified by the format menu . In some embodiments the image capture application commands a scanner to provide the data in the format specified by the format menu rather than as raw data.

The output format menu controls the format in which the image capture application will output the image. Some scanners convert images to a selected format themselves however for some models of scanner the conversion of raw image data to a particular format is performed entirely by the image capture application. That is the image capture application receives raw image data from the scanner and saves the data in the selected format after or while the raw image data has been received from the scanner. Only the post scan processing of the data is affected by the output format menu not the data from the scanner itself. If the user prefers not to use the .jpg format the user can select the GIF TIFF or other format option of format menu to override the image capture application s selection of the .jpg format.

In some embodiments some menu controls are sliders. A slider control includes a line and a knob on that line. The line represents the available range of values for that parameter and the position of the knob selects from among those values. The user slides the knob back and forth to change the values. In some embodiments some menu controls are check boxes. A check box is control that toggles between to state usually the on state and the off state for a particular option.

Some embodiments provide controls that cause other controls to manifest. In this figure image correction mode control provides options to set the image correction to none manual or automatic . When as here image correction mode control is set to manual the GUI provides image correction sliders .

As mentioned above the scan parameters of the selected region are displayed as settings of the controls in control area . In this figure image correction sliders are set to the parameters automatically selected for the region containing item . The illustrated image correction sliders change the chrominance and luminance values of the pixels in the scanned images. The user may adjust these sliders by dragging the knobs on the sliders to override the image capture application s automatically selected values for these image correction parameters.

To help the user decide what values to set on the image correction sliders some embodiments provide a preview of the effects of changes to these values. In some such embodiments the image correction parameters are applied to the selected region in the scan display area to provide the user with a preview of the effects that various adjustments will have on the detailed scan of that particular region.

As mentioned above some automatically determined parameters are displayed on controls that are toggles in the form of checkboxes. In the OCR checkbox determines whether to apply an optical character recognition algorithm to the scanned image. The OCR checkbox is not checked for item because the image capture application has chosen not to perform a post scan OCR on an item that has no text in it. In the case of textual item the OCR check box would be automatically checked. The user can click on the checkbox to check or uncheck and thus override the automatically determined post scan OCR parameter.

The above described manual override operations of the image capture applications of some embodiments can be performed by various processes. One such process is described below. conceptually illustrates the process of some embodiments for receiving manual adjustments to automatically identified regions and scanning parameters. The process receives commands from a user and commands a scanner to perform various scans. Several figures described before provide examples of the states of GUIs of some embodiments during the operations of process . The description of will note the figures associated with the various operations.

Some embodiments provide a user with manual scan options after directing a scanner to perform a preview scan receiving a preview image from the scanner and performing an automatic region decomposition operation that provides an initial identification of one or more separate regions in the scan document. The process begins after the preview scan when the process displays at automatically identified regions that a user can select to activate manual editing tools. described above provides an example of a grouped region displayed for selection. described above provides an example of multiple separate regions displayed for selection.

The process then determines at whether the user has selected one of the automatically identified regions. When the user has not selected an automatically identified region the process waits until the user does select such a region. When the user does select such a region the process provides at editing tools that allow the user to adjust the identified regions by specifying the location size orientation and scanner settings for one or more subsequent manual scan operations. described above provides an example of a GUI providing such editing tools.

The process then determines at whether the user has accepted the automatic selections. In some embodiments the process determines that the user has accepted the automatic selections when the user activates a manual control for performing a detailed scan without first editing the automatically selected parameters. When the process determines at that the user has not accepted the automatic selections e.g. by receiving a user command to edit the automatically selected parameters the process receives at user edits to the location size and orientation of the automatically identified scanning region. The edited region determines the location size and orientation of a pending detailed scan. described above provides an example of a series of user edits to the location orientation and size of a region.

The process then receives at edits to the scanner control settings. The scanner control settings determine the scan parameters e.g. resolution for the pending detailed scan. They are automatically selected for each region by the image capture application after the preview scan. described above provide examples of editable scanner control settings.

The process then receives at a command to perform a detailed scan. The image capture application directs the scanner to scan the edited region using the edited scan parameters. The detailed scan is similar to the detailed scan described in section II. The process then receives at a scanned image from the scanner. The process then performs at any post scan processing that is required by the settings of the scan parameters e.g. OCR changing file formats etc. . In some embodiments the post scan processing includes extracting a selected region from a larger set of image data provided by the scanner as described in relation to in section I. The process then saves at the processed image. In some embodiments saving the image includes forwarding the image to a selected application after it has been scanned as described in relation to . The process then determines at whether another region has been selected. When another region has been selected then the process returns to operation and displays the manual selection tool on the new region. When another region has not been selected the process ends.

While the above described process includes operations in a particular order one of ordinary skill in the art will realize that in some embodiments these operations are performed in other orders or in some cases skipped. For example a user could choose to edit the scanner control settings and choose not to edit the location orientation or size of the scanning region. Similarly in some embodiments after a detailed scan is performed the process will wait for another region to be selected or for some other action to end the process rather than simply ending if another region is not selected. As mentioned above the following figures provide examples of the manual override features of some embodiments.

In some embodiments the image capture application runs as multiple separate modules on a single computer. Some embodiments run three separate types of modules 1 a device module in some embodiments this is a driver that launches when an image capture device associated with that module is connected to the computer 2 a high level image capture client and 3 an image capture extension that runs in the background and provides connections between the device modules and the high level applications.

In some embodiments the image capture client could be an application provided by the same entity e.g. a computer company that produces the image capture extension . Alternatively the image capture client could be a third party application that uses application programming interfaces APIs provided by the entity that produces the image capture extension . The third party application that uses the APIs can be a word processor an image viewer an image editor a spread sheet a web browser or any other types of application. The APIs enable applications produced by third parties to work with the attached devices through image capture extension . A third party application using APIs of some embodiments is illustrated in described below.

In the device module is programmed by the makers of the image capture devices or a third party programmer . In some embodiments the makers of the image capture extension provide APIs to the makers of image capture devices. The makers of the image capture devices use the APIs to program device modules. The APIs enable the device modules to interface with the image capture extension . Device module is the device module associated with scanner . Accordingly in some embodiments the device module launches automatically when scanner is connected to computer .

The image capture extension runs in the background without an interface visible to the end user of the image capture clients . The image capture extension provides connections between device module and the image capture client . In the image capture architecture image capture extension acts as an intermediary between device modules and image capture clients. This relieves the programmers of image capture client from having to program their applications to work with individual devices such as scanner .

In some embodiments the image capture clients extensions and device modules are all executed as separate processes. Running the modules as separate processes makes it possible to dynamically add device modules to the architecture e.g. when new image capture devices are connected. The separation of the processes also allows multiple image capture clients and multiple device modules to use the same image capture extension and access device modules on separate computers. Some examples of such connections are illustrated in .

Scanner and camera are image capture devices connected to computer . Image viewing application is an application that accesses image capture devices through the image capture extension . Image capture client is a copy of image capture client . Image capture extension is a copy of image capture extension . Device module controls scanner . Device module controls scanner .

The architecture allows multiple applications to access devices attached to the computer the applications are executing on. Image capture client and image viewing application are both connected to image capture extension at the same time. That is both applications and interface with the image capture extension with copies of APIs provided by the makers of the image capture extension . The image capture extension allows both applications to connect to device module . In some embodiments both applications can use the scanner at the same time. In other embodiments the scanner is provided as a selectable device to both applications at the same time but when one application actually begins to use the scanner the other application is unable to use the scanner .

The architecture allows one application to access multiple devices. In this figure image capture client has simultaneous access to scanner and camera through 1 the interface between image capture client and image capture extension and 2 the interfaces between the image capture extension and the device modules and .

The architecture allows multiple applications to access multiple devices attached to a computer connected to the computer the applications are executing on. As shown in the figure applications and can access scanner and camera over the network connection . Specifically image capture extension on computer interfaces with image capture extension on computer . Through that interface and the interfaces between image capture extension and device modules and the image capture client and image viewing application can access the device modules and which control scanner and camera . Similarly image capture client can access scanner through 1 image capture extension 2 image capture extension and 3 device module .

Some embodiments implement some of the above described modules as sets of more specialized modules. conceptually illustrates the software architecture of some embodiments with multiple specialized modules. The specialized modules perform particular operations that collectively implement the features of some embodiments of the image capture application described herein.

Client module group represents one possible arrangement of modules that perform the operations of image capture client in . Image capture user interface provides the GUI of some embodiments and receives commands from users though the UI. Scan coordinator manages the preview scans and detailed scans. Item identifier determines which regions of a scanner glass contain items and identify the type of content in each region. Post scan processing module performs operations that modify scanned images after they are received by the image capture application. Image router sends images to the external applications selected to receive them. Manual override coordinator receives adjustments to parameters for detailed scans automatically selected by the image capture application. One of ordinary skill in the art will realize that module group is a conceptual group and that it does not necessarily reflect any actual item in the software. Group is merely one possible example of a set of modules that implement the image capture client .

Module group represents one possible arrangement of modules that perform the operations of image capture extension in . External interface detects image capture extensions running on other computers of local network and detects scanners connected to the network. Driver download interface retrieves device modules sometimes called drivers for newly detected image capture devices. Application coordinator provides data to the image capture user interface. Device interface provides an interface between the image capture application and the device module . One of ordinary skill in the art will realize that the particular set of modules in is merely one example of a set of modules that implement the image capture extension .

The image capture user interface provides a GUI to allow interaction between the image capture application and a user. In some embodiments the GUI is one of the GUIs described in section I. The GUI can receive a selection of a scanner and commands to perform a scan with that scanner. When the GUI receives a command to perform a scan the image capture user interface activates the scan coordinator . The scan coordinator then performs the required scan by commanding device interface to perform the scan. Device interface commands the device module to have the scanner perform the scan. The data from the scan is then passed back along the same route to the scan coordinator .

If the commanded scan is a preview scan the scan coordinator will send the preview scan data to item identifier . Item identifier will then determine what regions of the glass contain images in some cases separate images in other cases groups the nature of those images is e.g. color or black and white and the optimum scan parameters to apply to those images in a subsequent detailed scan.

The scan coordinator then provides the scan data and optimized scan parameters to the image capture user interface which in some embodiments displays the data to the user. In a manual scan mode the image capture user interface accepts manual adjustments to the scan parameters through the manual override coordinator .

If a detailed scan is commanded the image capture user interface commands the scan coordinator to perform the detailed scan using the set parameters location resolution etc . The command passes along through the device interface and device module to the scanner and the scan data returns will return back along the same route. The scan coordinator will then send the detailed scan data to the post scan processing module for any necessary processing image formatting color adjustment OCR etc. after which the processed image passes to the image router to be sent on to whatever application the user has specified. In some embodiments the image router supplies scripts to the applications to command them to perform specific actions with the images e.g. a script to a mail application could say to open a new e mail with the image as an attachment . In some embodiments the image capture user interface sends the destination data directly to the image routing module .

When an image capture device is initially connected to a port of the computer the driver download interface determines whether there is a driver device module for that image capture device in the driver database. In some embodiments if there is no locally available driver the driver download interface downloads a driver device module from the Internet or from a driver disk or other source for the new image capture device. The new driver device module is then stored in driver database . The driver device module executes e.g. like device module whenever the scanner is plugged into the computer. Some embodiments do not provide a driver download interface and instead rely on a driver download interface that is part of a separate application or part of the operating system.

One of ordinary skill in the art will realize that the modules in are only one example of modules for implementing some embodiments. Other embodiments may provide individual modules that perform multiple operations attributed to multiple modules in . Similarly some embodiments may provide multiple modules to perform operations depicted as being performed by a single module in . Also some embodiments may provide different connection schemes for the modules of those embodiments. The application architecture shown in includes a single image capture client that performs many image capture operations using modules that are part of the image capture client. However some embodiments provide modules outside of the image capture client to perform such functions. These modules are grouped together in frameworks sometimes called libraries that perform various image capture operations. In such embodiments the image capture client interfaces with the frameworks using APIs and the frameworks handle the image capture operations. An image capture application with the same modules shown in could be implemented as a client connected to external frameworks. An example of an embodiment that displays external frameworks is provided below.

As mentioned above in some embodiments an image capture client uses APIs to interface with frameworks that perform image capture operations e.g. preview scans manual scans etc. . In such embodiments the frameworks are accessible to clients from a variety of parties and that perform a variety of functions. For example the image capture client of such embodiments could be programmed either by the same programmers as the frameworks or by a third party with access to the APIs of the frameworks. In such embodiments a client application could be another image capture application an image viewing application an image editing application an e mail application a word processing application or any other type of application whose programmers choose to access the functionality of the frameworks.

The APIs enable a form of black box programming. The third party application acts as a front end and provides a user interface and a certain amount of functionality. An image capture engine that controls the scanners is provided in some embodiments. The third party application passes commands to the APIs of the image capture engine to cause the image capture engine to perform operations that control the scanners. The APIs enable applications produced by third parties as well as additional applications from the entity that produced the APIs to work with the attached devices without worrying about the internal mechanics of the image capture engine.

Image capture core framework provides information about and from scanners to the image viewing application . The APIs provide an interface between the image capture connection module and the image capture core framework . As shown in the image capture core framework in some embodiments is the framework that communicates with the image capture extension . Accordingly in some embodiments the framework provides a communication path that allows framework to communicate with image capture extension . Image storage stores image data received from scanners. Image kit framework provides various predefined GUI areas to the image viewing application . The APIs provide an interface between the image capture connection module and the image kit framework . Image capture connection module sends and receives data to and from the frameworks and in a protocol understood by the frameworks. Viewer coordinator handles the general processes of the image viewing application . Image editor receives directives from a user to modify images. Image converter changes images from one format to another. GUI control module displays the GUI of the image viewing application .

The frameworks and take commands that are formatted as calls to APIs and from the image viewing application and perform the operations dictated by those commands. In some embodiments a call to an API of framework or can result in further calls from framework or to APIs in framework or image capture extension . In some embodiments the image capture core framework handles commands that involve communication with the scanners and other image capture devices . The image kit framework handles commands that supply prearranged layouts for placement in the GUI of the image viewing application and direct auto scan and manual scan operations. The prearranged layouts in some embodiments include graphical elements and predefined interfaces to allow the placement of data from the image capture core framework in the prearranged layout. For example a prearranged layout could include a GUI section for displaying identified image capture devices and interfaces that place icons in the section. That is icons that represent scanners identified through the image capture core framework . Some examples of prearranged layouts are provided in the figures described below.

The operations of a preview scan API will now be described by reference to the modules shown in . Some embodiments provide an API for a preview scan similar to the preview scans described in sections II and III. When a user directs the image viewing application to perform a preview scan e.g. by clicking on a control in the GUI provided by GUI control module a chain of commands passes from one of the illustrated modules to another. Specifically a command potentially using a command format unique to the image viewing application passes from 1 the GUI control module to 2 the viewer coordinator to 3 the image capture connection module . The image capture connection module then uses a scan preview API to command the image kit framework to perform the preview scan.

The image kit framework using a command format of the image capture engine passes the command to perform a preview scan along another chain. The command is passed to 1 the image capture core framework to 2 extension to 3 the device module to 4 the scanner. The scanner then performs the requested preview scan and passes the scan data 1 to the device module to 2 the image capture extension to 3 the image capture core framework to 4 the image kit to 5 the image storage . The image kit framework then sends data about the captured image possibly including the captured image itself to the image capture connection module using a scan report API. The image capture connection module passes the data to the viewer coordinator which passes the scan on to the appropriate module of the image viewing application . For example the scan data can be passed to the image converter to be saved in a specified format. Alternatively the data can be passed to an image editor so that the user can edit the scanned image before saving it with the image converter . In some embodiments the image kit does not save the image to an image storage . In such embodiments the image is stored elsewhere or stored by other modules.

The preview scan API allows the image viewing application to command a preview scan without having any information about any of the modules further down the chain. Similarly some embodiments supply other APIs that the image viewing application can use to command the image capture engine to perform various operations. Some examples of these APIs will be described below. For example if an API in the image kit framework starts a chain of commands through multiple modules that ultimately causes a scanner to perform a scan the API would be described as commanding a scanner to perform a scan . Only the final destination of the command chains will be identified but one of ordinary skill in the art will understand that the commands are passed through several modules and may be retranslated by APIs of other modules to reach their target.

As described above some embodiments provide an API that commands the scanner to perform a preview scan. Some embodiments provide an API that commands the image capture core framework to find image capture devices an example of such an API ICDeviceBrowser.h is listed in Appendix B. in section VIII.C. Some embodiments provide an API that commands the image kit framework to decompose a preview image into separate regions. Some embodiments provide an API that commands the scanner to perform a detailed scan of a particular region. Some embodiments provide an API that commands the image capture core framework or image kit framework to send an image captured from a detailed scan to a selected external application not shown . Some embodiments provide an API that commands the image kit framework to supply a GUI control to the GUI control module that allows a user to select the destination application for a scanned image.

Some embodiments provide an API that commands the image capture engine to perform an auto scan. The auto scan API 1 commands the scanner to perform a preview scan with the scanner 2 commands the image kit framework to decompose the preview image into separate regions 3 commands the image capture core framework to select scanning parameters for each region 4 commands the scanner to perform a detailed scan of each region and 5 commands the image kit framework to send the detailed scan data to a preselected application e.g. an application selected by a GUI control supplied by image kit framework . Some embodiments provide a set of preview scan APIs that each commands one or more of the above described auto scan operations. Some embodiments provide a single API that activates multiple separate APIs that collectively perform an auto scan operation.

Some embodiments provide APIs that commands the image capture engine to perform a manual scan. The manual scan APIs 1 command the scanner e.g. through image capture extension and device module to perform a preview scan 2 command the image kit framework to decompose the preview image into separate regions 3 command the image kit to select scanning parameters for each region 4 command the image kit framework to provide GUI tools for editing the regions and scan parameters 5 command the scanner to perform a detailed scan of each region and 6 commands the image kit framework to send the detailed scan data to a preselected application e.g. an application selected by a GUI control supplied by image kit framework . Some embodiments provide a set of manual scan APIs that each directs one or more of the above described operations. Other embodiments provide a single API that directs all the manual scan operations. Some embodiments provide a single API that activates multiple separate APIs that collectively perform a manual scan operation.

As mentioned above in some embodiments the image kit framework supplies GUI areas to the GUI control module . Some embodiments provide an API or a set of APIs that commands the image kit framework to supply the GUI control module with a device selection area an example of such an API IKDeviceBrowserView.h is listed in Appendix A in section VII.A. Some embodiments provide an API or a set of APIs that commands the image kit framework to supply the GUI control module with a scanner control area an example of such an API IKScannerView.h is listed in Appendix A in section VII.B. Some embodiments provide an API that commands the image kit framework to supply the GUI control module with a single window that simultaneously displays a device selection area and a scanner control area. Some embodiments provide an API that commands the image kit framework to supply the GUI control module with a single window that simultaneously displays a device selection area a scanner control area and a scan display area.

Within the device view the presence of scanner icons and indicates that the image viewing application now has access to these three scanners. The image viewing application learns of the availability of these scanners from the APIs of the image capture core framework . As soon as the user selects the scanner icon the APIs of the image capture core framework populate the scanner view with scan options that corresponds to the selected scanner.

The user can change the scan options in scanner view by selecting buttons within the scan view. For example if the user wants to send the scanned image directly to a file the user can change the Scan To option to File to indicate that the user has chosen a file as the destination of the scanned image. The user may further want to change the name of the destination file in this instance to Foo by changing the File Name option .

The scan view also includes checkboxes to let the user of the image viewing application decide how to perform the scan. For example by checking Detect Separate Items checkbox the user has decided to decompose a scanned document into separate images. For a scanned document generated from the two pieces of contents and in the image viewing application will receive two separate scanned images from the APIs of image capture core framework after the framework has decomposes the scanned document and performed scan.

The image capture window also includes Auto scan button and the Manual Scan button . In some embodiments when the user click on the Auto scan button the image viewing application invokes the auto scan routines in the image capture core framework and uses graphical elements from the image kit framework to perform auto scan operation as described above in Section II. Likewise when the user click on the Manual Scan button the image viewing application invokes the manual scan routines in the image capture core framework and uses graphical elements from the image kit framework to perform manual scan operation as described above in Section III. The image capture core framework directs the scanner to perform the scan operation and deliver the scanned image back to the image viewing application via the APIs.

When the user clicks on the FILE icon the image viewing application pops an image file window . The image file window displays two icons and to represent the image files Foo1 and Foo2 which are delivered to the image viewing application by the image capture core framework . When the user clicks on the icon to select image file Foo1 the image viewing application displays an image which is the scanned image of the photo in . Although the photo was not properly aligned to the edge of the scanner the image capture core framework has automatically aligned the scanned image as part of the auto scan operation it performs. Thus as shown in the image is now aligned to the edges of the GUI.

The process defines at rules and processes for populating the first window area with representations of detected image capture devices. For example scanners and cameras connected directly or through a network to a computer on which the image capture application runs. In some embodiments defining rules and procedures comprises defining modules and or APIs to retrieve a list of image capture devices from a scanner detecting module of an operating system such as image capture extension .

The process defines at an auto scan process for 1 commanding an initial scan that generates a scanned document 2 identifies separate regions of the scanned document 3 automatically generating scan parameters for each identified area and 4 commanding secondary scans of each identified region according to the automatically generated scan parameters. The auto scan process described in section II is an example of such an auto scan process. In some embodiments defining the auto scan process includes defining modules and or APIs for command the individual operations of the auto scan.

The process defines at a manual selection tool for adjusting the automatically identified regions. Manual selection tool is an example of such a manual selection tool. In some embodiments defining the manual override tool comprises defining modules and or APIs for displaying the manual selection tool and receiving commands from a user through the manual selection tool.

The process then defines at controls for receiving user adjustments of the automatically generated scan parameters. illustrate several examples of such controls. In some embodiments defining the controls comprises defining modules and or APIs for displaying the controls and receiving commands from a user through the controls.

The process then defines at other image capture items and functionalities. Examples of such functionalities may include additional angle indicators for the manual selection tool post processing procedures etc. The process defines these additional tools in order to create an image capture application that has many additional features to the features described above. In some embodiments defining such functionalities comprises defining modules and or APIs for such functionalities.

Process then stores at the defined image capture application i.e. the defined modules and or APIs modules GUI items etc. on a computer readable storage medium. The computer readable storage medium may be a disk e.g. CD DVD hard disk etc. or a solid state storage device e.g. flash memory in some embodiments. One of ordinary skill in the art will recognize that the various elements defined by process are not exhaustive of the modules rules processes and GUI items that could be defined and stored on a computer readable storage medium for an image capture application incorporating some embodiments of the invention. In addition the process is a conceptual process and the actual implementations may vary. For example different embodiments may define the various elements in a different order may define several elements in one operation may decompose the definition of a single element into multiple operations etc. In addition the process may be implemented as several sub processes or combined with other operations within a macro process.

Many of the above described processes and modules are implemented as software processes that are specified as a set of instructions recorded on a computer readable storage medium also referred to as a computer readable medium or a machine readable medium . When these instructions are executed by one or more computational element s such as processors or other computational elements like ASICs and FPGAs they cause the computational element s to perform the actions indicated in the instructions. Computer is meant in its broadest sense within the field of computing devices and can include any electronic device with a processor. Examples of computer readable media include but are not limited to CD ROMs flash drives RAM chips hard drives EPROMs etc.

As used in this specification and any claims of this application the terms computer server processor and memory all refer to electronic or other technological devices. These terms exclude people groups of people or aspects of people e.g. the term memory as used herein does not include human memory . For the purposes of the specification the terms display as a verb or displaying means displaying by an electronic device. The term displaying excludes handwriting on paper painting and other forms of creating an image that do not involve electronic devices. As used in this specification and any claims of this application the terms computer readable medium and computer readable media are entirely restricted to tangible physical objects that store information in a form that is readable by a computer and or other electronic devices. These terms exclude any carrier waves wireless signals wired download signals electronic signals and any other ephemeral signals.

In this specification the term software is meant to include firmware residing in physical devices such as read only memory or applications stored in magnetic storage which can be read into memory for processing by a processor. Also in some embodiments multiple software inventions can be implemented as sub parts of a larger program while remaining distinct software inventions. In some embodiments multiple software inventions can also be implemented as separate programs. Finally any combination of separate programs that together implement a software invention described here is within the scope of the invention. In some embodiments the software programs when installed to operate on one or more computer systems define one or more specific machine implementations that execute and perform the operations of the software programs.

The bus collectively represents all system peripheral and chipset buses that support communication among internal devices of the computer system . For instance the bus communicatively connects one or more processors with the system memory the read only memory and the permanent storage device .

From these various memory units the processor retrieves instructions to execute and data to process in order to execute the processes of the invention. In some embodiments the processor comprises a Field Programmable Gate Array FPGA an ASIC or various other electronic components for executing instructions. The read only memory ROM stores static data and instructions that are needed by the processor and other modules of the computer system. The permanent storage device on the other hand is a read and write memory device. This device is a non volatile memory unit that stores instructions and data even when the computer system is off. Some embodiments of the invention use a mass storage device such as a magnetic or optical disk and its corresponding disk drive as the permanent storage device . Some embodiments use one or more removable storage devices flash memory card or memory stick as the permanent storage device . Some embodiments use a removable storage device such as a floppy disk flash drive or CD ROM as the permanent storage device.

Like the permanent storage device the system memory is a read and write memory device. However unlike storage device the system memory is a volatile read and write memory such as a random access memory RAM . The system memory stores some of the instructions and data that the processor needs at runtime.

Instructions and or data needed to perform processes of some embodiments are stored in the system memory the permanent storage device the read only memory or any combination of the three. For example the various memory units include instructions for processing multimedia items in accordance with some embodiments. From these various memory units the processor retrieves instructions to execute and data to process in order to execute the processes of some embodiments.

In some embodiments the bus connects to the GPU . The GPU of some embodiments performs various graphics processing functions. These functions may include display functions rendering compositing and or other functions related to the processing or display of graphical data.

The bus also connects to the input and output devices and . The input devices enable the user to communicate information and select commands to the computer system. The input devices include alphanumeric keyboards touch screens and cursor controllers. The input devices also include audio input devices e.g. microphones MIDI musical instruments etc. and video input devices e.g. video cameras still cameras optical scanning devices etc. .

The present application describes a GUI that provides users with numerous ways to perform different sets of operations and functionalities. In some embodiments these operations and functionalities are performed based on different commands that are received from users through different input devices e.g. keyboard trackpad touchpad mouse etc . For example the present application describes the use of a cursor in the GUI to control e.g. select move objects in the GUI. However in some embodiments objects in the GUI can also be controlled or manipulated through other control such as touch control. In some embodiments touch control is implemented through an input device that can detect the presence and location of touch on a display of the device. An example of such a device is a touch screen device. In some embodiments with touch control a user can directly manipulate objects by interacting with the GUI that is displayed on the display of the touch screen device. For instance a user can select a particular object in the GUI by simply touching that particular object on the display of the touch screen device. As such in some embodiments when touch control is utilized a cursor is not even provided for enabling selection of an object of a GUI. However when a cursor is provided in a GUI touch control can be used to control the cursor in some embodiments.

The output devices include printers electronic display devices that display still or moving images and electronic audio devices that play audio generated by the computer system. Electronic display devices in some embodiments display the graphical aspects of a GUI. Electronic display devices include devices such as cathode ray tubes CRT liquid crystal displays LCD light emitting diode displays LED including organic light emitting diode displays OLED plasma display panels PDP surface conduction electron emitter displays alternatively referred to as a surface electron display or SED electronic paper etc. Audio output devices include a PC s sound card and speakers a speaker on a cellular phone a Bluetooth earpiece etc. Some or all of these output devices may be wirelessly or optically connected to the computer system.

Finally as shown in bus also couples computer to a network through a network adapter not shown . In this manner the computer can be a part of a network of computers such as a local area network LAN a wide area network WAN or an Intranet or a network of networks such as the Internet . Internet. For example the computer may be coupled to a web server through network so that a web browser executing on the computer can interact with the web server as a user interacts with a GUI that operates in the web browser.

Any or all of the components of computer system may be used in conjunction with the invention. However one of ordinary skill in the art will appreciate that any other system configuration may also be used in conjunction with the invention or components of the invention.

Some embodiments include electronic components such as microprocessors storage and memory that store computer program instructions in a machine readable or computer readable medium alternatively referred to as computer readable storage media machine readable media or machine readable storage media . Some examples of such computer readable media include RAM ROM read only compact discs CD ROM recordable compact discs CD R rewritable compact discs CD RW read only digital versatile discs e.g. DVD ROM dual layer DVD ROM a variety of recordable rewritable DVDs e.g. DVD RAM DVD RW DVD RW etc. flash memory e.g. USB drives flash drives SD cards mini SD cards micro SD cards etc. magnetic and or solid state hard drives read only and recordable blu ray discs ultra density optical discs any other optical or magnetic media and floppy disks.

The computer readable media stores a computer program that is executable by at least one processor and includes sets of instructions for performing various operations. Examples of hardware devices configured to store and execute sets of instructions include but are not limited to application specific integrated circuits ASICs field programmable gate arrays FPGA programmable logic devices PLDs ROM and RAM devices. Examples of computer programs or computer code include machine code such as produced by a compiler and files including higher level code that are executed by a computer an electronic component or a microprocessor using an interpreter. In some embodiments the hardware includes one or more of the above described computer readable medium memory or storage.

It should be recognized by one of ordinary skill in the art that any or all of the components of computer system may be used in conjunction with the invention. Moreover one of ordinary skill in the art will appreciate that any other system configuration may also be used in conjunction with the invention or components of the invention.

While the invention has been described with reference to numerous specific details one of ordinary skill in the art will recognize that the invention can be embodied in other specific forms without departing from the spirit of the invention. For example several embodiments were described above by reference to particular image capture applications with particular features and components e.g. particular arrangements of window areas . However one of ordinary skill will realize that other embodiments might be implemented with other types of image capture applications with other types of features and components e.g. other arrangements of window areas .

Moreover while the examples shown illustrate many individual modules as separate blocks one of ordinary skill in the art would recognize that some embodiments combine these modules into a single functional block or element. One of ordinary skill in the art would also recognize that some embodiments divide a particular module into multiple modules.

Cursor operations can be managed any number of ways e.g. use of a mouse trackpad etc. but also touch screen based operations. Some embodiments do not even have cursor for enabling selection in touch screen approaches. The media editing application can be a standalone application on a desktop part of another program e.g. part of the OS part of a server based solution fat client thin client browser based web based etc. or some combination of the preceding.

One of ordinary skill in the art will realize that while the invention has been described with reference to numerous specific details the invention can be embodied in other specific forms without departing from the spirit of the invention. For instance alternate embodiments are implemented by using a generic processor to implement the video processing functions instead of using a GPU. One of ordinary skill in the art would understand that the invention is not to be limited by the foregoing illustrative details but rather is to be defined by the appended claims.

The following Appendices provide examples of frameworks. Appendix A includes the APIs of an example image kit framework while Appendix B includes the APIs of an example of an image capture core framework. One of ordinary skill in the art will realize that frameworks with different listings can still fall within the scope of the inventions. For example some embodiments could use some APIs from the Image Capture framework from Apple .

 abstract for device filtering indicates that the IKDeviceBrowserView should include network shared scanners.

 discussion Based on the IKScannerDeviceViewTransferMode the downloaded file will be saved on disk using the url or returned in memory as NSData

 void scannerDeviceView IKScannerDeviceView scannerDeviceView didScanToURL NSURL url fileData NSData data error NSError error 

 Best viewed with the following settings Tab width 4 Indent width 2 Wrap lines Indent wrapped lines by 3 Page guide 128.

 discussion The meaning of this value is defined by the EXIF specification. Here is what the letter F would look like if it were tagged correctly and displayed by a program that ignores the orientation tag thus showing the stored image 

 Best viewed with the following settings Tab width 4 Indent width 2 Wrap lines Indent wrapped lines by 3 Page guide 128.

ICDevice is an abstract class that represents a device supported by Image Capture. ImageCaptureCore defines two concrete subclasses of ICDevice and ICScannerDevice. ICDeviceBrowser creates instances of these two subclasses to represent scanners it finds.

 constant ICDeviceLocationTypeLocal Device found directly attached to the Macintosh via its USB or FireWire port.

 constant ICDeviceLocationTypeShared Device found over the network by searching for devices shared by other Macintosh hosts.

 constant ICDeviceLocationTypeBonjour Device found over the network by searching for Bonjour services supported by Image Capture.

 constant ICDeviceLocationTypeMaskBonjour Mask to detect a network device that publishes a Bonjour service.

 discussion Indicates that the device uses TCP IP transport. These devices are discovered using Bonjour.

 discussion Indicates either the device is mounted as a mass storage volume and can be ejected or the it is a remote device with an active connection that can be disconnected.

 discussion This message completes the process initiated by the message requestOpenSession sent to the device object.

 discussion A scanner device is ready when its functional units are found and the default functional unit is selected for use.

 discussion This message completes the process initiated by the message requestCloseSession sent to the device object. This message is also sent if the device module in control of the device ceases to control the device.

 discussion This happens if the device module overrides the default name of the device reported by the device s transport layer or if the name of the filesystem volume mounted by the device is changed by the user.

 discusson Any Image Capture client application can choose to share the device over the network using the sharing or webSharing facility in Image Capture.

 abstract This message is sent to the device delegate when status information is received from a scanner.

 discussion This message is sent only if a session is open on the device. The value of buttonType argument is one of the ICButtonType values defined above.

 abstract ICDevice is an abstract class that represents a device supported by Image Capture facility. ImageCaptureCore defines two concrete subclasses of ICDevice and ICScannerDevice. ICDeviceBrowser creates instances of these two subclasses to represent scanners it finds.

 abstract The delegate to receive messages once a session is opened on the device. It must conform to ICDeviceDelegate protocol. In addition it should respond to selectors defined in ICScannerDeviceDelegate protocols in order to effectively interact with the device object. The messages this delegate can expect to receive are described by these protocols.

 abstract The type of the device as defined by ICDeviceType OR d with its ICDeviceLocationType. The type of this device can be obtained by AND ing the value retuned by this property with an appropriate ICDeviceTypeMask. The location type of this device can be obtained by AND ing the value retuned by this property with an appropriate ICDeviceLocationTypeMask.

 abstract Name of the device as reported by the device module or by the device transport when a device module is not in control of this device. This name may change if the device module overrides the default name of the device reported by the device s transport or if the name of the filesystem volume mounted by the device is changed by the user.

 abstract Filesystem path of the device module that is associated with this device. scanner specific capabilities are defined in ICScannerDevice.h.

 abstract The bundle version of the device module associated with this device. This may change if an existing device module associated with this device is updated or a new device module for this device is installed.

 abstract Executable Architecture of the device module in control of this device. This is equal to a value as defined in NSBundle.h or CFBundle.h.

 abstract Indicates whether the device is a remote device published by Image Capture device sharing facility.

 abstract Indicates whether the device is shared using the Image Capture device sharing facility. This value will change when sharing of this device is enabled or disabled.

 abstract The transport type used by the device. The possible values are ICTransportTypeUSB ICTransportTypeFireWire ICTransportTypeBluetooth ICTransportTypeTCPIP or ICTransportTypeMassStorage.

 abstract Filesystem path of an application that is to be automatically launched when this device is added.

 discussion Make sure the receiver s delegate is set prior to sending this message otherwise this message will be ignored. This request is completed when the delegate receives a device didOpenSessionWithError message. No more messages will be sent to the delegate if this request fails.

 discussion This request is completed when the delegate receives a device didCloseSessionWithError message. This will be the last message sent to the delegate.

 discussion This message should be used only if the client is planning on communiting with the device directly. The device module may not yield control of the device if it has an open session.

 Best viewed with the following settings Tab width 4 Indent width 2 Wrap lines Indent wrapped lines by 3 Page guide 128.

 discussion The ICDeviceBrowser object is used to find devices such as scanners that are supported by Image Capture. These device may be directly attached to the USB or FireWire bus on the host computer shared by other computers or available over a TCP IP network. This object communicates with an Image Capture agent process asynchronously to accomplish this. There is only one instance of this class per process.

 discussion If several devices are found during the initial search then this message is sent once for each device with the value of moreComing set to YES in each message except the last one.

 discussion If several devices are removed at the same time then this message is sent once for each device with the value of moreGoing set to YES in each message except the last one.

 void deviceBrowser ICDeviceBrowser browser didRemoveDevice ICDevice device moreGoing BOOL moreGoing 

 discussion This happens if the device module overrides the default name of the device reported by the device s transport layer or if the name of the filesystem volume mounted by the device is changed by the user.

 discusson Any Image Capture client application can choose to share the device over the network using the sharing or webSharing facility in Image Capture.

 abstract This message is sent when an event that occurred on the device may be of interest to the client application.

 discussion In Mac OS X 10.6 this message is sent when a button is pressed on a device and the current application is the target for that button press. In the case of the button press event if a session is open on the device this message will not be sent to the browser delegate instead the message device didReceiveButtonPress is sent to the device delegate.

 abstract This message is sent after the device browser completes sending deviceBrowser didAddDevice moreComing message for all local devices.

 discussion Detecting locally connected devices USB and FireWire devices is faster than detecting devices connected using a network protocol. An Image Capture client application may use this message to update its user interface to let the user know that it has completed looking for locally connected devices and then start looking for network devices.

 abstract The ICDeviceBrowser object is used to find devices such as scanners that are supported by Image Capture. These device may be directly attached to the USB or FireWire bus on the host computer shared by other computers or available over a TCP IP network. This object communicates with an Image Capture agent process asynchronously to accomplish this. There is only one instance of this class per process.

 abstract The delegate. It must conform to ICDeviceBrowserDelegate protocol. The messages this delegate can expect to receive are described by ICDeviceBrowserDelegate protocol.

 abstract A mask whose set bits indicate the type of device s being browsed after the receiver receives the start message. This property can be changed while the browser is browsing for devices. This property can be constructed by OR d values of ICDeviceTypeMask with values of ICDeviceLocationTypeMask.

 abstract All devices found by the browser. This property will change as devices appear and disappear.

 discussion Make sure that the receiver s delegate is set prior to sending this message otherwise this message will be ignored. The messages the delegate can expect to receive are described by ICDeviceBrowserDelegate protocol.

 Best viewed with the following settings Tab width 4 Indent width 2 Wrap lines Indent wrapped lines by 3 Page guide 128.

ICScannerDevice is a concrete subclass of ICDevice class. ICDeviceBrowser creates instances of this class. In this release an instance of ICScannerDevice class is intended to be used by the ICScannerDeviceView object. The ICScannerDeviceView class encapsulates the complexities of setting scan parameters performing scans and saving the result. The developer should consider using ICScannerDeviceView instead of building their own views using the ICScannerDevice object.

 discussion A non localized notification string to indicate that the scanner is requesting an overview scan to be performed.

 discussion Scanners require exclusive access only one client can open a session on a scanner. The scanner is available if it does not have a session opened by another client. Attempting to open a session on a scanner that already has an open session for another client will result in an error. A client that wants to open a session on a scanner as soon as it is available should implement this method and send requestOpenSession message to scanner object from that method.

 discussion A functional unit is selected immediately after the scanner device is instantiated and in response to requestSelectFunctionalUnit message.

 void scannerDevice ICScannerDevice scanner didSelectFunctionalUnit ICScannerFunctionalUnit functionalUnit error NSError error 

 abstract This message is sent when the scanner device receives the requested scan. If selectedFunctionalUnit is a document feeder then this message will be sent once for each scanned page.

 discussion This message is sent when the scanner device receives the requested scan. If selectedFunctionalUnit is a document feeder then this message will be sent once for each scanned page.

 abstract ICScannerDevice is a concrete subclass of ICDevice class. ICDeviceBrowser creates instances of this class.

 discussion In this release an instance of ICScannerDevice class is intended to be used by the ICScannerDeviceView object. The ICScannerDeviceView class encapsulates the complexities of setting scan parameters performing scans and saving the result. The developer should consider using ICScannerDeviceView instead of building their own views using the ICScannerDevice object.

 abstract An array of functional unit types available on this scanner device. This is an array of NSNumber objects whose values are of type ICScannerFunctionalUnitType.

 abstract The document UTI. Currently supported UTIs are kUTTypeJPEG kUTTypeJPEG2000 kUTTypeTIFF kUTTypePNG etc.

 discussion When this request is completed the delegate will be notified using the scannerDevice didSelectFunctionalUnit error message.

 discussion When this request is completed the delegate will be notified using the scannerDevice didCompleteOverviewScanWithError message. The content of error returned should be examined to determine if the request completed successfully.

 discussion When this request is completed the delegate will be notified using the scannerDevice didCompleteScanWithError message. The content of error returned should be examined to determine if the request completed successfully.

 abstract Cancels the current scan operation started by sending a requestOverviewScan or requestScan .

 Best viewed with the following settings Tab width 4 Indent width 2 Wrap lines Indent wrapped lines by 3 Page guide 128.

 abstract ICScannerFunctionalUnit is an abstract class that represents a scanner functional unit. ImageCaptureCore defines three concrete subclasses of ICScannerFunctionalUnit ICScannerFunctionalUnitFlatbed ICScannerFunctionalUnitPositiveTransparency ICScannerFunctionalUnitNegativeTransparency and ICScannerFunctionalUnitDocumentFeeder. ICScannerDevice creates instances of these concrete subclasses.

 constant ICScannerFunctionalUnitTypePositiveTransparency Transparency functional unit for scanning positives.

 constant ICScannerFunctionalUnitTypeNegativeTransparency Transparency functional unit for scanning negatives.

 abstract Unit of measurement used by the scanner. This corresponds to values used for ICAP UNITS as defined in the TWAIN Specification.

 abstract Identifies color data formats. Only relevant for multi channel data. Corresponds to ICAP PLANARCHUNKY of the TWAIN Specification.

 constant ICScannerColorDataFormatTypeChunky For multi channel data e.g. RGB data from all channels are interleaved.

 constant ICScannerColorDataFormatTypePlanar For multi channel data e.g. RGB each channel is transferred sequentially.

 abstract Document size types. Corresponds to ICAP SUPPORTEDSIZES used by the Image Capture scanner modules. Also refer to TWAIN 1.9 Specification page 9 483.

 constant ICScannerDocumentTypeDefault This is the platten size. Not valid for scanners without a platten.

 constant ICScannerStateOverviewScanInProgress The scanner functional unit is performing an overview scan.

 constant ICScannerFeatureTypeEnumeration This feature can have one of several discrete values strings or numbers.

 abstract ICScannerFeature class is an abstract base class used to describe a scanner feature. ImageCaptureCore defines three concrete subclasses of ICScannerFeature ICScannerFeatureEnumeration IC ScannerFeatureRange and ICScannerFeatureBoolean.

 discussion The scanner functional units may have one or more instances of these classes to allow users to choose scanner specific settings or operations before performing a scan.

 abstract ICScannerFeatureEnumeration object is used to represent a feature of a scanner functional unit that can have one of several discrete values.

 abstract The current value. The current value can be set to one of the possible values in the values property below .

 abstract The default value. The default value can be set to one of the possible values in the values property below.

 abstract The human readable menu item labels to be used in a menu to allow the user to select the current value from an array of possible values.

 abstract ICScannerFeatureRange object is used to represent a property of a scanner functional unit whose value lies within a range.

 abstract The current value. Attempting to set the current value to a value that is not coincident with a step will result in a value corresponding to the nearest step being assigned to the current value.

 abstract The default value . Attempting to set the default value to a value that is not coincident with a step will result in a value corresponding to the nearest step being assigned to the default value.

 abstract ICScannerFeatureBoolean object is used to represent a property of a scanner functional unit whose value can be YES or NO.

 abstract ICScannerFeatureTemplate object is used to define a group of one or more rectangular scan areas that can be used with a scanner functional unit.

 abstract ICScannerFunctionalUnit is an abstract class that represents a scanner functional unit. ImageCaptureCore defines three concrete subclasses of ICScannerFunctionalUnit ICScannerFunctionalUnitFlatbed ICScannerFunctionalUnitPositiveTransparency ICScannerFunctionalUnitNegativeTransparency and ICScannerFunctionalUnitDocumentFeeder. ICScannerDevice creates instances of these concrete subclasses.

 abstract Supported bit depths. The values in this set are valid values defined by ICScannerBitDepth.

 abstract The bit depth to use when performing the final scan. This will always be one of the supported bit depths.

 abstract Supported measurement units. The values in this set are valid values defined by ICScannerMeasurementUnit.

 abstract Desired orientation of the scan area. This property along with scanArea describes the area to be scanned.

 discussion This property is set to ICEXIFOrientationl initially. This property is not used by the IC ScannerFunctionalUnitDocumentFeeder subclass.

 abstract Indicates if this functional unit accepts threshold value to be used when performing a scan in black white.

 abstract Indicates if this functional unit uses threshold value to be used when performing a scan in black white.

 abstract Default threshold value used when performing a scan in black white. This value is from 0 to 255.

 abstract Threshold value to be used when performing a scan in black white. This value should be from 0 to 255.

 abstract Indicates if this functional unit can perform an overview scan. Not all functional units can perform an overview scan. For example a document feeder or a sheet feeder unit cannot perform an overview scan.

 abstract Overview scan image. This property will be NULL for functional units that do not support overview scans.

 abstract Overview image resolution. Value assigned to this will be contrained by resolutions allowed by the device.

 abstract ICScannerFunctionalUnitFlatbed is a concrete subclass of ICScannerFunctionalUnit class. ICScannerDevice creates instances of this class.

 abstract ICScannerFunctionalUnitPositiveTransparency is a concrete subclass of ICScannerFunctionalUnit class. ICScannerDevice creates instances of this class.

 abstract ICScannerFunctionalUnitNegativeTransparency is a concrete subclass of ICScannerFunctionalUnit class. ICScannerDevice creates instances of this class.

 abstract ICScannerFunctionalUnitDocumentFeeder is a concrete subclass of ICScannerFunctionalUnit class. ICScannerDevice creates instances of this class.

 abstract Supported document types. The values in this set are valid values defined by ICScannerDocumentType.

 discussion This value will change when the document is loaded or removed from the feeder if the scanner module has the capability to detect this state.

 Best viewed with the following settings Tab width 4 Indent width 2 Wrap lines Indent wrapped lines by 3 Page guide 128.

