---

title: Displaying a menu of commands in a video game environment
abstract: In a gaming system, a user controls actions of characters in the game environment using speech commands. In a learning mode, available speech commands are displayed in a command menu on a display device. In a non-learning mode, the available speech commands are not displayed. A speaker-independent context-sensitive speech recognition module contains a vocabulary of available speech commands. Use of speech commands is combined with input from a controller device to control actions of a character or characters in the game environment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07877262&OS=07877262&RS=07877262
owner: Sony Computer Entertainment America LLC
number: 07877262
owner_city: Foster City
owner_country: US
publication_date: 20091012
---
This application is a continuation and claims the priority benefit of U.S. patent application Ser. No. 11 764 795 filed Jun. 18 2007 now U.S. Pat. No. 7 613 616 and entitled Training a User to Execute a Sequence of Commands in a Game Environment by Using Voice Control which is a continuation and claims the priority benefit of U.S. patent application Ser. No. 11 403 716 filed Apr. 13 2006 now U.S. Pat. No. 7 233 904 and entitled Menu Driven Voice Control of Characters in a Game Environment which is a continuation and claims the priority benefit of U.S. patent application Ser. No. 09 859 034 filed May 14 2001 now U.S. Pat. No. 7 085 722 and entitled System and Method for Menu Driven Voice Control of Characters in a Game Environment. The disclosures of these commonly owned applications are incorporated herein by reference.

This invention relates generally to electronic entertainment devices and relates more particularly to a system and method for menu driven voice control of characters in a game environment.

In electronic entertainment systems such as gaming systems a user typically interacts with a game program using some type of manually activated controller device. Common controller devices are buttons joysticks switches keyboards and combinations of these. Some gaming systems use specifically designed control devices such as a steering wheel and pedals for driving simulations and a stick and pedals for flight simulations.

Each gaming system typically uses manually activated controller devices of a single design for most games playable on the system and buttons or keystrokes are assigned different meanings for each game. In one game a particular button may correspond to a punch while in another game the same button corresponds to firing a torpedo. Thus use of a controller device is not very intuitive for the user in the context of a particular game environment.

Use of manually activated controller devices requires a user to memorize which buttons or keys are assigned to particular actions. For complicated games the number of buttons or combinations of keystrokes can be very large. In many games a user only controls the actions of a single character. In games where the user controls a group of characters the characters act as a group so in effect the group of characters acts as a single character. Allowing the user to control multiple characters independently using manually activated controller devices may be possible but would be very complex and difficult to learn and use.

In accordance with the present invention a system and method are disclosed to implement menu driven voice control of characters in a game environment. The system of the invention includes game software and a speech recognition module. The speech recognition module is a speaker independent and context sensitive with a vocabulary of available command words or phrases to control actions of a character or characters in the game environment. A user speaks commands from the vocabulary into a microphone to control the actions of a character or characters in the game environment.

In a learning mode menus of available commands are displayed to the user. A level command menu shows available characters to control. A level command menu shows available actions for character or characters selected from the level menu. The available actions in the level menu depend upon a current state of the game. A level command menu shows available options for the character actions selected from the level menu. The available options in the level menu may also depend upon a current state of the game.

In a non learning mode menus of available commands are not displayed to the user. The user speaks memorized commands in the vocabulary of the speech recognition module. The speech recognition module is context sensitive it will not react to a level command unless a level command was previously input and will not react to a level command unless a level command was previously input. Thus the user inputs verbal sentence type commands actor plus action to control the character or characters in the game environment.

CPU VU VU GPU and IOP communicate via a system bus . CPU communicates with main memory via a dedicated bus . VU and GPU may also communicate via a dedicated bus . CPU executes programs stored in OS ROM and main memory . Main memory may contain pre stored programs and may also contain programs transferred via IOP from a computer readable storage medium such as a CD ROM DVD ROM or other optical disc not shown using optical disc control unit . IOP control data exchanges between CPU VU VU GPU and other devices of system such a controller interface .

CPU executes drawings instructions from CPU and VU to produce images for display on a display device not shown . VU transforms objects from three dimensional coordinates to two dimensional coordinates and sends the two dimensional coordinates to GPU . SPU executes instructions to produce sound signals that are output on an audio device not shown .

A user of system provides instructions via controller interface to CPU . For example the user may instruct CPU to store certain game information on memory card or may instruct a character in a game to perform some specified action. Other devices may be connected to system via USB interface and IEEE 1394 interface . In the preferred embodiment a USB microphone not shown is connected to USB interface to enable the user to provide voice commands to system .

Speech recognition module is a speaker independent context sensitive speech recognizer executed by CPU . In an alternate embodiment IOP executes speech recognition module . Speech recognition module includes a vocabulary of commands that correspond to instructions in game software . The commands include single word commands and multiple word commands. When an input speech signal utterance matches a command in the vocabulary speech recognition module notifies game software which then provides appropriate instruction to CPU .

The user of system and game software inputs one or more of the commands via the microphone and USB interface to control the actions of characters in game software . The spoken commands are preferably used in conjunction with controller commands however other embodiments of game software may implement spoken commands only.

In the embodiment of game software the user controls the actions of a team leader character using controller actions such as actuating buttons or manipulating a joystick. The user inputs spoken commands to control the actions of a two character team. Team item represents the availability of a team command that selects both members of the two character team to perform an action. Alpha item represents the availability of a command that selects one member alpha to perform an action. Bravo item represents the availability of a command that selects one member bravo to perform an action.

The user says the word team into the microphone to select team item says the word alpha to select alpha item and says the word bravo to select bravo item . When speech recognition module recognizes one of the level commands it notifies game software which then displays a level menu command screen.

Level menu illustrates available commands for the two character team. The available commands depend upon a current state of the game. For example if the user verbally selects hold position item then the two character team will appear to hold their position in the game environment. The next time the user verbally selects team item hold position item will not appear but a follow item not shown will appear instead.

The combination of team item and hold position item is a complete command so if the user says hold position while screen is displayed game software then stops displaying screen and causes the selected characters to perform the selected action in the game environment both members of the team hold their position . Similarly the combination of team item and fire at will item is a complete command so if the user says fire at will while screen is displayed game software then stops displaying screen and causes the selected characters to perform the selected action in the game environment both members of the team fire their weapons . The combination of team item and deploy item is not a complete command. If the user says deploy while screen is displayed game software then displays a level menu command screen.

The combination of team item deploy item and frag item is a complete command so if the user says frag while screen is displayed software module stops displaying screen and causes the selected characters to perform the selected action in the game environment both members of the team deploy a frag grenade . The combination of team item deploy item and smoke item is a complete command so if the user says smoke while screen is displayed software module stops displaying screen and causes the selected characters to perform the selected action in the game environment both members of the team deploy a smoke grenade .

Although in only three menu levels are shown any number of menu levels is within the scope of the invention. In the preferred embodiments the number of menu levels is three for ease of use and to facilitate learning of the various command combinations. Once the user has learned or memorized all of the various command combinations the user may play the game without using the command menus non learning mode .

As stated above in conjunction with speech recognition module is context sensitive. For example the word deploy is in the vocabulary of speech recognition module . However speech recognition module will only recognize the word deploy in the context of a level command such as team or alpha . In other words speech recognition module will not react to an input level command unless a level command has been input and will not react to an input level command unless a level command has been input. The speech recognition module recognizes sentence type commands actor plus action that game software uses to control actions of the characters in the game environment.

Although illustrate command menus and as branching menus that branch from left to right any other configuration for displaying available commands to the user is within the scope of the invention.

In step game software displays level commands on a level menu command screen. Then in step speech recognition module determines whether the user has verbally input a level command. If not the method returns to step . If the user has verbally input a level command then in step game software displays level commands on a level command screen. In step speech recognition module determines whether the user has verbally input a level command. If not the method returns to step . If the user has verbally input a level command the method continues with step .

If the input level command does not have associated level commands then in step game software executes the commands whereby a character or characters in the game environment perform the selected action. If the input level command does have associated level commands then in step software module displays level commands on a level menu command screen. In step speech recognition module determines whether the user has verbally input a level command. If not the method returns to step . If the user has verbally input a level command then in step game software executes the commands whereby a character or characters in the game environment perform the selected action.

In the non learning mode the available commands at each level are not displayed to the user. In step speech recognition module determines if the user has verbally input a level command. If not speech recognition module continues to listen for a level command. If the user has verbally input a level command then in step speech recognition module determines whether the user has verbally input a level command. If not speech recognition module continues to listen for a level command. If the user has input a level command the method continues with step .

If the input level command does not have associated level commands then the method continues in step where game software executes the commands whereby a character or characters in the game environment perform the selected action. If the input level command does have associated level commands then in step speech recognition module determines whether the user has verbally input a level command. If the user has not verbally input a level command then speech recognition module continues to listen for a level command. If the user has verbally input a level command then in step game software executes the command whereby a character or characters in the game environment perform the selected action.

In the non learning mode the user experiences the game environment as if he or she is actually giving verbal instructions to a character or characters making the game play more intuitive and realistic. In one embodiment of game software after the user has given a spoken command to one of the characters a prerecorded acknowledgement of the command or other audible response is played back to the user via a speaker or headset not shown .

