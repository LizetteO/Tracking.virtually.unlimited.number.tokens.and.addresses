---

title: TICC-paradigm to build formally verified parallel software for multi-core chips
abstract: This invention teaches a way of implementing formally verified massively parallel programs, which run efficiently in distributed and shared-memory multi-core chips. It allows programs to be developed from an initial abstract statement of interactions among parallel software components, called cells, and progressively refine them to their final implementation. At each stage of refinement a formal description of patterns of events in computations is derived automatically from implementations. This formal description is used for two purposes: One is to prove correctness, timings, progress, mutual exclusion, and freedom from deadlocks/livelocks, etc. The second is to automatically incorporate into each application a Self-Monitoring System (SMS) that constantly monitors the application in parallel, with no interference with its timings, to identify and report errors in performance, pending errors, and patterns of critical behavior. This invention also teaches a way of organizing shared-memory for multi-processors that minimizes memory interference, protects data and increases execution efficiency.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07979844&OS=07979844&RS=07979844
owner: EDSS, Inc.
number: 07979844
owner_city: Port Saint Lucie
owner_country: US
publication_date: 20090505
---
Since the dawn of computer age in the 1950 s we have seen remarkable progress in computer hardware systems design and computer software systems design. This progress has now led us to where we are today. We have taken an unimaginably great leap from the days of our ancestors who lived in the tropical jungles of Africa 100 thousand years ago. We now enjoy and suffer unprecedented use of computers in every aspect of human life unprecedented communication among peoples via internet as also unprecedented opportunities for invasions of privacy data stealing and cyber warfare.

There is now a growing gap between our ability to produce complex secure computing hardware systems at ever decreasing costs and our ability to produce software systems that exploit available hardware configurations at ever increasing costs. Cost of producing and maintaining software systems far exceed costs for hardware systems at more than 12 trillion dollars per year around the world cost of software systems is more than five times the cost of hardware systems. In spite of this enormous cost software systems are intrinsically error prone prone to attacks by intruders and cannot guarantee data privacy and system security. This has given rise to a vast industry catering to data and system protection from potential intruders.

Our computing technology has reached an impassable computing bottleneck. We will have several occasions to refer back to this computing bottleneck later in this chapter.

As software systems keep getting progressively more complex they also keep getting progressively more error prone and more prone to attacks by hackers. Complexities of software systems design implementation and maintenance and our inability to deploy viable technological solutions to solve problems of unreliability lack of security and ever increasing production costs have led us to this bottleneck. Much of the advances in software engineering technology have been driven by corresponding advances in programming technology and not advances in system design independent of programming. Presently there does not seem to be any way out of this vicious cycle of programming and system implementation and the computing bottleneck it pushes us in to.

Almost all software systems we use today fall into the category of time sliced concurrent software systems. By time sliced concurrent we mean software systems in which the same CPU performs multiple computations in multiple distinct non overlapping time slices controlled and coordinated by a monitor no two computations being ever performed by any CPU simultaneously at the same time. As number of time slices per second increase these computations become intrinsically unreliable and unpredictable.

With multicore technology we have today and new technologies available for very fast parallel inter process communications U.S. Pat. No. 7 210 145 B2 there is hope that parallel software systems may provide viable solutions to cater efficiently to ever increasing software complexity lack of reliability and security and increasing costs. By parallel software we mean software systems in which multiple distinct computations in multiple ComPutinq Units CPUs occur simultaneously at the same time and the CPUs automatically coordinate their activities through communication with each other with no need to use monitors.

However there is little evidence that this hope could be realized using current technologies of parallel program design and development. This is because current parallel processing technologies have serious limitations parallel software systems that use current technologies are much harder to implement even harder to debug and validate and harder still to update and maintain and do not run efficiently making optimal use of available hardware resources and the gap between computation timings and communication timings is vast and growing ever wider in spite of all the advances we have made in communications technology.

There have been several discussions of different paradigms for parallel programming based on languages and libraries used 1 based on different message passing interfaces 2 6 based on data flow models 7 8 based on different hardware architectures 8 10 based on network models 10 12 and based on communication models calculus 26 27 . All of these accept the inevitability of two fundamental incompatibilities and one serious limitation 

Thus parallel programs become very difficult and very costly to develop and maintain requiring special expertise not commonly available. One seeks higher productivity 17 18 by increasing peak flops sec yields of parallel processors without having to increase parallel program execution efficiencies. Commodity based massively parallel cluster computing will find its limits in realizable flops sec efficiency which is currently about 30 realizable flops unit of power efficiency and flops unit of space efficiency measures. These efficiencies are likely to decrease dramatically at scaling factors of 10or 10. It is claimed Blue Gene IBM has been scaled up to 10processors. Published papers indicate 30 efficiency with 9000 processors. It is not clear whether applications using all the 10processors have ever been written and tested.

With nano scale computing and quantum computing 19 we may confront a need to perform massively parallel computations at scales of 10or more. Scalable parallel processing hardware networks appear in cellular automata 20 21 systolic machines 9 and asynchronous data flow machines 7 8 . It is not however clear how these might be adopted to meet anticipated requirements of scalable software.

Thus both concurrent and parallel software system design and implementation have now reached their limits of scalability and practical viability and are caught in a computing bottleneck. Further scaling of these technologies to implement yet more complex more reliable and more secure systems is no longer possible.

To make parallel programming address issues we face and solve problems we encounter we need totally new ways of designing implementing validating and maintaining parallel software systems. We need methods in which computer itself is used to help design implement validate and maintain such software systems. We need methods to arbitrarily scale our parallel software systems to meet ever increasing complexities through increased parallelism. Also we need self monitoring capabilities that enable us to constantly monitor such software systems at run time and issue timely reports on errors pending errors and critical behaviors and take appropriate predefined actions automatically in a timely fashion. We also need a framework in which self diagnosis and self repair become possible. Hardware technology to supply practically unlimited supply of hardware resources needed for such parallel software systems is here today in the form of multicore chips and nano technology based computing units are over the horizon. But software technology to put available hardware resources to good use is not here yet.

In the following we use acronym Ppde to refer to a viable Parallel program development and execution platform and postulate the set of requirements Ppde should satisfy in order to help us free ourselves from the computing bottleneck we are in today.

There are compelling reasons to be open to scalable and efficient computer assisted methods which simplify parallel programming updating and maintenance formally verify them and provide self monitoring capabilities.

In the following we use the phrase formal language to refer to a language which can be used to communicate with both computers and humans. Programming languages or languages of logic are examples of formal languages while natural languages are not at least not yet . We use the term cell to refer to a parallel software execution unit. Each cell defines an independent parallel software process run by a distinct ComPuting Unit CPU that is assigned to that cell. Cells have the capability to exchange messages among themselves through communication pathways that interconnect them in a network of cells and pathways.

Cells are used in parallel software systems to process messages received from other cells and to build and send messages to other cells. Each cell polls its input output ports cyclically and either receives and processes messages delivered to the input ports and possibly respond to them or builds service request messages and sends them to other cells through its output ports. These are the only operations performed by cells. This is similar to Actor systems 39 40 . There are several differences though between the proposed Ppde and Actor systems.

There are two kinds of cells i Compound cell which may be decomposed to a sub network of cells and pathways that may be encapsulated with in the compound cell. ii Simple Cell which cannot be further decomposed. We use the term cell to refer to both compound and simple cells. A simple cell is abstract if computer programs used by the cell have not all been implemented defined yet. A compound cell is abstract if either its decomposition has not been specified yet or the specified decomposition contains abstract cells. Defining computer programs used by an abstract simple cell is called cell refinement. Similarly specifying decomposition of an abstract compound cell is called network refinement. We now state the desirable properties of a viable Ppde as follows 

If we get a Ppde platform that satisfies all of the above requirements and it can be easily used to systematically design develop update validate and run self monitoring parallel software systems then we can surely escape from the computing bottleneck we are in today. We will then be ready to take the next great leap from benefits of computer revolution we enjoy and suffer today to land in an era of next great computer revolution this leap being analogous to a leap from the era of steam engine days to the era of fuel cells.

TICC Technology for Integrated Computation and Communication TICC Ppde TICC based Parallel Program Development and Execution platform which are the subjects of this patent application together satisfy all of the above requirements as described in Chapter 2. The term TICC paradigm is used to refer to abstractions methods rules and conventions used in TICC and TICC Ppde to design and build parallel programming applications validate them and run them with self monitoring. Hereafter we will use the terms Ap design Ap implementation and Ap requirements to refer to TICC Ppde designs implementations and requirements of parallel software system applications Ap using the TICC paradigm. We briefly outline principal features of the TICC paradigm pertinent to this patent application in the next subsection. Details are given in Chapter 2.

 i Proof of concept prototypes of TICC and TICC Ppde have both been implemented and tested for parallel program development and execution to demonstrate that it is possible to build platforms that satisfy requirements listed in the previous subsection. Implementation and testing of the proof of concept prototypes of TICC and TICC Ppde were supported by NSF grants DMI 0232073 and DMI 0349414 during the years 2003 through 2005. The prototypes are implemented in C and work in HP PROLIANT 760 Shared Memory Multiprocessor SMM in Linux OS environment.

TICC Ppde provides an API Application Programming Interface and a Graphical User Interface GUI called TICC GUI for design development and documentation. GUI is used to develop and display the network of cells and pathways in Ap design update the network display properties of components in the network and activate components in the network when requested to do so The network is called TICC network. TICC GUI was designed and implemented by Mr. Rajesh Khumanthem Mr. Kenson O Donald and Mr. Manpreet Chahal as per specifications provided by this inventor. TICC and TICC Ppde were both designed and implemented by this inventor with in a period of two man years. Specifications for TICC and TICC Ppde were also designed and developed by this inventor.

 ii TICC Ppde prototype uses Operating System only for memory management secondary memory access input output and internet access It does not use the Operating System for interrupt control scheduling coordination synchronization monitoring process and pthread parallel thread activations and communications. Application programmers do not have to write programs for scheduling coordination synchronization process activations and monitoring in parallel software systems they implement. Once abstract system design is completed and specified TICC Ppde automatically becomes self scheduling self coordinating self synchronizing self activating self monitoring and self communicating.

Each cell executes its own communication protocols in parallel with other cells to exchange messages asynchronously with other cells with guaranteed message delivery having only 350 to 500 nanoseconds latencies. The number of parallel simultaneous message exchanges occurring at any given time being limited only by the number of available cells. TICC Ppde does not use sequential buffers to implement asynchronous communications. TICC Ppde provides validated compiled codes for all protocols likely to be used in any parallel programming system. The prototypes run completely autonomously using the operating system only for dynamic memory management and input output. All of these features have been tested in the prototype TICC Ppde. Eventually all operating system functions may be installed in TICC Ppde itself thereby providing an integrated environment for design development validation and running of self monitoring parallel software systems.

 iii TICC Ppde automatically derives and builds a formal model of computations specified in Ap implementation at every stage of its refinement including the Ap design stage. Models are expressed in terms of ALLowed Event Occurrence Patterns ALLEOPs . Intended computations in parallel software systems specified by Ap design and Ap implementation causes a set of events to occur at run time which in turn cause other events to occur as computations and communications continue further. ALLEOPs identifies classes of events that may occur in intended computations specify causal relations between classes of events and describes patterns of causal chains of event classes that may occur at run time. ALLEOPs thus specify event class partial ordering causal model of Ap implementation . This event class ALLEOP model is referred to here as Ap ALLEOPs .

TICC Ppde uses Ap ALLEOPs for two purposes i to prove properties of Ap implementation such as correctness mutual exclusion progress freedom from deadlocks livelocks and other properties that may be specific to given applications at different stages of refinement of Ap implementation including the completed implementation and ii to interactively derive the self monitoring system Ap SMS for given Ap implementation using Ap ALLEOPs and automatically install it as a part of mechanisms used to execute Ap implementation the installed Ap SMS having all the features described in items ix and x in the previous subsection.

Properties to be proven are stated as assertions in a Causal Temporal Logic CTL language as explained in Chapter 2. The set of all such CTL assertions constitute Ap requirements Designers and implementers have the responsibility to specify Ap requirements and update them at each stage of refinement. TICC Ppde automatically updates Ap ALLEOPs at each stage of refinement of Ap implementation and automatically derives Ap traces and Ap ECT networks Event Characterization Tables networks from Ap ALLEOPs . Ap traces and Ap ECT networks are used to interactively validate assertions in Ap requirements as illustrated in Chapter 2 Section 7.

 iv TICC Ppde automatically incorporates into its execution mechanisms facilities needed for enforcement of data and system security specifications provided by designers and implementers The specifications set values for pre defined attributes in TICC Ppde for data and system components as explained in Section 8 of Chapter 2. The attributes together constitute a universal system which can be used to specify any kind of data and system security features specific to any application implemented in TICC Ppde.

 v Finally TICC Ppde defines a single criterion which may be used to ascertain that the set of all CTL assertions in Ap requirements when validated would indeed establish correctness of Ap implementation .

 vi Comments All of these and many additional features of TICC Ppde are described and illustrated in Chapter 2. Static verification techniques used by TICC Ppde have not been implemented and tested yet but this inventor has defined the denotational semantics of Parallel Programming Languages PPL used in TICC Ppde called TICC PPL and defined a proof theory to validate proof methods used in TICC Ppde. These will be published in appropriate journals in the near future and do not constitute patentable materials. Methods used to interactively build refinements of Ap implementation and proofs of assertions in Ap requirements at any stage of refinement are informally defined and illustrated with examples in Sections 3 and 7 of Chapter 2. It is not hard to implement the static verification techniques described and illustrated in Chapter 2.

Proofs of mutual exclusion freedom from deadlocks livelocks and synchronization coordination characteristics given in Chapter 2 are properties of implementations derived from implementations and not just properties of intended system designs stated in an abstract non executable language. These are the first computer assisted interactive formal proofs of their kind that pertain to actual executable programs.

We present in Chapter 2 organizational principles that explain why TICC paradigm has the right structure and operational characteristics to provide the means to address all of the requirements listed in the previous section and all the features described above. As explained in Chapter 2 even without pressing need to scale by factors of 10or more the new paradigm has several immediate benefits to offer. The paradigm is ideally well suited to build validated parallel software systems using multicore chips validated real time systems and secure systems with guaranteed security.

 vii Nature of Inventions The inventions here pertain to a collection of abstractions which facilitate the following i specify abstract designs ii provide methods to automatically derive ALLEOPs models from specifications of abstract designs and their refinements iii provide guidance to perform successive and progressive refinements of designs and implementations preserving at each stage of refinement properties validated in earlier stages iv provide methods used to validate implementations at each stage of refinement using ALLEOPs v modify TICC communication pathway structures and protocols in order to provide above mentioned characteristics vi methods used to derive and install SMS for given design specifications vii facilitate practically unlimited simultaneous parallel high speed guaranteed asynchronous communications over TICC Ppde communication pathways without having to use sequential buffers viii enable program organization using virtualMemories ix provide special facilities to ComPuting Units CPUs called TICC CPUs to execute TICC Ppde programs without need to use an Operating System at any level of program execution x enable precise prediction within given timing bounds and control of execution times of program segments and protocols xi enable automatic implementation of specified data and system security conditions and xii leads to the specification of special hardware facilities in TICC CPUs needed to execute TICC Ppde programs efficiently validate implementations enforce security and incorporate SMS.

An important invention that makes possible all of the above inventions is the invention of Causal Communication Primitive CCP as a basic programming primitive U.S. Pat. No. 7 210 145 B2 which can be used for hardware and software subsystems to dynamically communicate with each other by exchanging signals in order to coordinate and synchronize their activities in a manner that is similar to how asynchronous hardware systems communicate with each other and coordinate their activities CCP being implemented as a basic machine instruction and used to define communication protocols that enable guaranteed very high speed parallel communications both in shared memory and distributed memory systems. As a machine instruction it will take only 5 nanoseconds estimated to execute a CCP in a 2 gigahertz CPU and it requires only about 8 CCP executions to deliver a message from one cell to another. Thus with hardware assistance communication latency may be drastically reduced to tens to a few hundreds of nanoseconds estimated or less. TICC Ppde using a variant of communications organization proposed in TICC U.S. Pat. No. 7 210 145 B2 . Variation is quite small but its consequences are profound.

Where as TICC communications were possible only in shared memory software systems TICC Ppde communications are possible both in shared memory and distributed memory parallel software systems. Distributed memory communications using CCPs over a local area TICCNET . Also TICC allowed only a limited number of parallel simultaneous communications. Message delivery latencies in TICC communications are not predictable. TICC Ppde allows unlimited guaranteed almost instantaneous and simultaneous parallel communications with predictable message delivery times in nanoseconds the number of such parallel communications that may occur at any given time being limited only by the number of available cells in a parallel software system.

 viii No need to develop new technologies As described in the concluding remarks of Chapter 2 the most important characteristic of inventions claimed here is that the inventions do not require any new technologies in order to be built and deployed. Inventions require only a new way or organizing computations and computing systems. Fully operational commercial version of TICC Ppde platform can be built validated and deployed with in a period of 3 to 5 years using only currently available technologies. The proof of concept prototype TICC and TICC Ppde supported by NSF validate this claim. We outline in the concluding remarks of Chapter 2 short term tasks that should be completed in order to deploy TICC Ppde. TICC Ppde platform may then be used to build complex guaranteed high speed high efficiency validated secure parallel software systems in every area of human endeavor some of which are outlined in the concluding remarks as long term tasks.

 ix Remarks Both TICC and TICC Ppde are unique and are the first of their kind. There are no other integrated platforms of this kind in published literature or in patent literature with capabilities similar to TICC and TICC Ppde except reference 22 below which pertains to TICC and the patent U.S. Pat. No. 7 210 145 B2 for TICC issued to this inventor for which international patent is still pending patent application number PCT US2006 015305 published in PCT Gazette on Nov. 1 2007 publication number WO 2007 123527 . TICC Ppde uses a modified version of TICC .

TICC message passing paradigm and TICC Ppde adapts and integrates aspects of seven other programming paradigms i the OO Object Oriented paradigm 1 2 3 4 ii parallel computations as in Actors 5 6 37 iii interaction specifications as in calculus 7 8 9 iv integration of computation and communication as in CSP 10 11 12 v verification of implementations similar to design verification through FSPs Finite State Processes 13 vi verification of NFSP non FSP systems similar to 15 and 16.17 18 and vii communication using RESTCLK pathways 19 . Only the OO paradigm is used practically unchanged. Among the rest RESTCLK TICC and proof methods are new.

Integration of these paradigms is made possible by the use of TICC which enables hardware and software computing components to exchange signals programmatically. All communications and pthread parallel thread interactions scheduling security enforcement interrupt handling synchronization coordination and self monitoring are driven by programmatic signal exchanges without need to use an Operating System OS while preserving mutual isolation of all software and hardware components. Computing units called cells operate in parallel and not in time sliced concurrency as in FSP 13 and CCS 14 . Each cell operates in its own assigned ComPuting Unit CPU . TICC based parallel processing requires and can accommodate large numbers of CPUs. The paradigm is ideally well suited to develop parallel programs that run in a grid of Shared Memory Multi core Chips SMMCs interconnected by TICCNET . Besides simplifying parallel programming and providing methods for formal verification and dynamic self monitoring TICC offers several other benefits. They are outlined in Section 1.1.

This chapter presents the following through a series of examples i Principles of organization ii Nature of communications and computations iii Models of intended computations as defined by ALLowed Event Occurrence Patterns ALLEOPs which are automatically derived from implementations iv Verification of implementations using evaluations of given CTL Causal Temporal Logic assertions over Event Characterization Tables ECTs which are automatically derived from ALLEOPs using interactively developed logical characterizations of actions v synchronization coordination data protection security enforcement and self monitoring vi design of software systems based on the TICC paradigm and refinement of design to implementation through successive refinements vii design for CPUs called TICC CPU that execute TICC Ppde parallel programs efficiently with dramatically increased efficiency data protection and system security viii programming abstractions introduced by TICC Ppde that make all of the above possible and ix unique features of TICC Ppde platform.

Section 2 presents an overview of TICC pathways and presents the basic interaction machineries of TICC Ppde. It introduces the concepts of transactions correctness of transactions and the property of ports connected by pathways being well matched to each other. An application implementation is correct if and only if all ports in the application connected by pathways are well matched.

Section 3 presents two simple examples of implementations for problems taken from 13 which illustrate concurrency automatic coordination and automatic synchronization in TICC Ppde and encapsulation of networks of cells and communication pathways into a compound cell. Section 3 also introduces ALLEOPs models of intended computations derived from implementation specifications traces derived from ALLEOPs and causalnets which are abstractions derived from traces by SMS. Several examples of syntax of TIPs Thread Interaction Protocols CIPs Cell Interaction Processes ALLEOPs causalnets and traces are illustrated here with informal description of rules for deriving ALLEOPs from TIPs and CIPs and rules for deriving traces from ALLEOPs.

Sections 4 5 and 6 present an outline of computational and communication facilities in TICC Ppde that support general parallel computations. Section 4 presents additional features of pathways and comparisons with other currently used parallel programming paradigms. Section 5 presents details on TIPs and organization of computations in TICC Ppde. Section 6 introduces the OO organization in TICC Ppde concept of evaluation nature of computation and communication defines events and the concept of causality concept of evaluations and notation.

Section 7 presents three more examples of implementations who s ECTs Event Characterization Tables automatically derived from traces are used to construct proofs called ALLEOP proofs for correctness mutual exclusion condition synchronization fairness and freedom from livelocks and deadlocks. These illustrate the fundamental concepts in TICC Ppde implementations and ALLEOP proofs through symbolic evaluations of CTL assertions over ECTs. Appendices I through III describe implementations associated with the examples in Section 7 and their ALLEOPs.

Section 8 presents the protocol for group to group communication and shows how the infrastructure for SMS and data security are built into TICC Ppde communication mechanisms. Section 9 briefly presents details on developing specifications in TICC Ppde for abstract designs through successive network refinements and reducing the abstract design to a validated implementation through successive TIP refinements.

Section 10 summarizes hardware design requirements for TICC CPUs that run TICC Ppde cells and designs for TICC CPUs to meet special requirements of TICC Ppde parallel programs it also presents a new shared memory organization using Shared Memory Modules SMMs that exploits the presence of software virtualMemories used in TICC Ppde implementations. The hardware enhancements enable efficient running of TICC Ppde parallel programs with dramatically increased data and system security. They also simplify CPU designs for CPUs in multi core chips.

Section 11 summarizes the collection of new programming abstractions introduced in the TICC paradigm of parallel programming that simplify programming tasks facilitate efficient running of programs in multi core chips and enable formal verification and self monitoring. Section 12 concludes this paper with brief comments directions for future research and developments and the scope of applications that TICC Ppde can support.

1. ALLEOPs and Proofs There are two kinds of events communication events and action events. Roughly speaking more detail in Section 6 communication event is a pair p t where p is a port that sends or receives a message via a pathway and t is the time at which message is sent or delivered. An action event is a pair name t where name is a variable condition or action and t is the time at which name is generated and or set and accessed condition becomes true or action is performed. Action is any statement in a programming language any condition or method defined in that programming language. Whereas action events may change a world state communication events will change only the states of components in communication pathways.

Timing here is a property of events used to model computations not a parameter of computations. Every computational step has one or more events associated with it. All such events occur at discrete points of real time. During proof construction the time points are postulated for events in a manner that is consistent with ALLEOPs derived from implementation specifications. Event occurrence patterns conditions associated with them event timings and states of computing units are all used in proof construction.

ALLEOPs model both FSP Finite State and NFSP Non Finite State processes. Unlike FSP models ALLEOPs are not models of intended system designs but they are models of both intended computations in abstract desiqn specifications and implementations that realize specified designs. Traces are derived from ALLEOPs and ECTs represent information in traces in a tabular form that is convenient for proof construction. Proofs are constructed through symbolic evaluation of CTL 101 assertions over ECT networks. CTL assertions are similar to assertions used in 38 40 41 42 they are also similar in certain ways to the FSP language used in 13 . But there are significant differences.

Proofs of properties of implementations are developed interactively with users specifying implementations CTL assertions to be proven and providing definitions axioms and other assertions that may be pertinent to the proofs. We refer to the proofs as ALLEOP proofs. A finite ALLEOP is one that has an equivalent FSP model. A given ALLEOP may have both FSP and NFSP properties. Symbolic ECT evaluations may be used to prove both kinds of properties proofs of the latter will necessarily be more complicated.

2. Dynamic Self Monitoring SMS Self Monitoring System is an intrinsic built in part of TICC Ppde program execution mechanism. Thus once a TICC Ppde implementation is completed self monitoring is automatic with no need for any component of SMS to be implemented by implementers. Monitoring is done in parallel with an application while the application is running with little or no degradation of program execution efficiency and its timings. SMS is used during the life time of an application in order to identify errors in performance pending errors and patterns of critical behavior and generate timely reports or a priori defined remedial actions. SMS provides the infrastructure for developing self diagnosis self repair and learning capabilities and capabilities to dynamically modify parallel program execution based on occurrences of pre defined event patterns.

3. High speed Parallel Communications TICC adapts RESTCLK 19 communication paradigm. The adaptation enables high speed message passing with self synchronized self coordinated secure and guaranteed message delivery both in shared memory and distributed memory environments. Distinct cell groups may simultaneously exchange messages in parallel with other cell groups the number of such parallel group to group message exchanges being limited only by the number of available cells. Each cell group may contain one or more cells.

With the right kinds of hardware support explained in Section 10 and 2 gigahertz computing units and 1 gigabit memory bus point to point messages may be exchanged in shared memory environments with in tens of nanoseconds and group to group messages in hundreds of nanoseconds. Messages may be exchanged in distributed memory environments using TICCNET in about 500 nanoseconds estimated plus signal transmission time.

4. Self synchronization and Self Coordination Coordination occurs between two sets of independently running parallel processes when a new computation is started in one set only after all parallel processes in the other set have completed their respective computations. The term synchronization is used to denote temporal synchronization where a set of computational events always occur at the same time with in say nanoseconds picoseconds or femtoseconds of each other depending on the technology. Group to group communications and computations are automatically coordinated and synchronized. Cells in a cell group all receive identical time synchronized messages and send out coordinated joint reply messages.

5. Efficient Low Grain size Executions Organization of TICC Ppde allows for high speed executions because of i elimination of OS intervention in communications process and pthread parallel thread activations scheduling coordination synchronization interrupt handling data protection and security enforcement ii very low communication latencies iii parallel simultaneous message exchanges iv elimination of sequential buffers in asynchronous communications and v minimized memory contention. Since communication latencies are very low it is possible to run parallel programs with good efficiencies 90 to 100 even at low grain sizes of the order of 1 to a 100 microseconds if cache memories are not used. Cache memories and speed up techniques are not needed in TICC Ppde to achieve high throughputs. High throughputs may be achieved through arbitrary scaling of number of parallel processes executing very low grain size parallel computations.

6. Built in Data Security and Protection All processes and pthreads parallel threads are activated only through message exchanges and messages are delivered to recipients only if each message recipient satisfies a priori specified security conditions for message the recipient receives. Ports attached to cells give access to the cells to methods and data to process or build messages only when they are allowed to do so. Each cell executes its own message exchange protocols as soon as a message is ready to be sent. All message processing building computations and protocol executions are self activated by the cell itself without using an operating system or any other augmentation as described in Section 10. There is no distinction between message processing building computations and communications performed by a cell. All security checks are built into communication protocols. Yet they add little to communication latencies latencies quoted in this paper include in them times needed for security checks.

Each cell operates independently in its own assigned CPU. No CPU is ever shared among cells unless a cell voluntarily suspends or terminates its computations relinquishes its assigned CPU and the CPU relinquished by one cell is assigned later to another cell by TICC Ppde. TICC Ppde performs all of its own CPU assignments and cell activations in CPUs assigned to them.

There are no monitors no schedulers and no dynamic link libraries. Thus it is impossible for any intruder to track or interfere with either protocol evaluations or process pthread activations.

7. Ideal Environment for Multi core Chips TICC Ppde provides the ideal environment for building formally verified parallel software systems that run in multi core chips. Section 10 describes augmentations for TICC CPU in multi core chips to make them compatible with TICC Ppde. The augmentations contribute to increased execution efficiency increased data protection and increased security. Section 11 summarizes programming abstractions introduced by TICC Ppde that simplify parallel programming program verification and self monitoring. It also summarizes the unique features of TICC Ppde parallel programming platform. A scalability theorem for TICC Ppde parallel program asserts as long as interaction overhead caused by scaling is small when compared to program execution times parallel programs in TICC Ppde are arbitrarily scalable. The interaction overhead and execution times are defined relative to the structure of the TICC network see Feature 3 Section 11.1 used for an application. Parallel computations may be scaled to millions of CPUs if the necessary conditions are satisfied.

8. Dynamic Flexibility and Mobility TICC Ppde parallel programs may be dynamically modified dynamically tested and updated see in situ testing in 19 . Program mobility is achieved by dynamically installing cells and pathways and changing pathway connections. A cell may install other cells and pathways only if it has requisite privileges.

Five examples are presented in this disclosure three from 13 and the remaining two are classical examples. The first example introduces organization of programs ALLEOPs associated with them and traces derived from ALLEOPs. The second example introduces encapsulation in TICC Ppde coordination and concurrency. The remaining three present TICC Ppde solutions to the following problems Ornamental Garden problem from 13 Producer Consumer problem and Dining Philosophers problem. ALLEOP proofs are presented for these three for properties of implementations such as synchronization coordination mutual exclusion fairness and freedom from deadlocks. Properties to be proven are stated as CTL assertions.

The examples illustrate implementation methods used in TICC Ppde through successive refinements methods used for automatic generation of ALLEOP models from implementations traces from ALLEOPs and proofs using ECT networks and encapsulation of TICC sub networks into compound cells or refinements of compound cells to TICC sub networks. They illustrate similarities differences between TICC paradigm and other programming and proof paradigms. Computational characteristics of adopted paradigms manifest in TICC Ppde significantly differently from their original incarnations. We begin with adaptation of RESTCLK Das 19 in TICC and compare TICC pathways with CSP channels. Later we compare TICC Ppde with calculus and Actor systems.

It is a necessary common practice in hardware systems to use signals to control synchronize and coordinate activities of hardware components. In synchronous hardware clock signals are used and in asynchronous hardware start and completion signals are used. Gopinath 21 first proposed exchanging signals programmatically between software hardware components and Das 19 first defined the structure of shared memory RESTCLK pathways over which signals may travel. Gopinath and Das used short threads to send receive and process signals and implemented their systems with time sliced concurrency managed by an Operating System OS . Signal exchange mechanisms defined by threads were used to implement message exchanges in shared memory environments. Communication over a distributed network was done using a network facility such as for example ETHERNET 22 .

Time sliced concurrent thread scheduling and activation introduced non determinism into signal exchanges. Messages could not be delivered within bounded latencies and messages were sometimes lost. TICC adapts and modifies the framework introduced by Gopinath and Das to provide thousands of guaranteed parallel simultaneous message deliveries with precisely predictable latencies in tens to hundreds of nanoseconds range for application to parallel programming of shared memory and distributed memory systems in the context of an OO Object Oriented programming language.

Guaranteed programmatic exchange of signals between software hardware components at high speeds allows software to directly control its execution in a hardware system while preserving component isolation. In TICC we currently do this for all communications CPU assignments and activations of cells in CPUs process and pthread parallel thread scheduling and activations interrupt handling data protection security enforcement synchronization coordination and self monitoring in both shared memory and distributed memory environments. Prototype TICC Ppde uses the operating system only for memory management paging caching and input output. It should eventually be possible to implement all operating system services in TICC Ppde itself.

Signal exchange between pairs of hardware software components is programmatically specified in TICC by using a new programming primitive called Causal Communication Primitive CCP. Each CCP has the form x z Y where z is a start or completion signal and x and Y are software or hardware components. Each type of signal may have sub types defined for it. CCP is like an assignment in programming languages in that it assigns a signal to a component. But unlike an assignment in a programming language the effect of signal assignment might manifest only after a certain delay. In TICC the desired effect is ultimately either message delivery or message dispatch hence the name CCP.

Specifying signal exchange using CCP has several advantages i just as assignments in a programming language CCPs may be freely embedded in to other programming statements and more importantly implemented as a machine instruction in a CPU thus enabling programmatic signal exchanges with in a computation ii flexibly organize program executions iii eliminate the distinction between communication and computation iv use the same protocol invocation formats for shared memory and distributed memory communications and v make it possible to keep RESTCLK pathway structures with only minimal changes even though TICC signal exchange mechanisms and protocol execution mechanisms are different from those of RESTCLK 19 .

Each CCP is implemented by a 2 state or 4 state ndFSM non deterministic Finite State Machine . The FSMs are non deterministic only in the sense state transitions are not defined for all inputs in every state of the FSM. It takes about 25 to 50 nanoseconds to execute a CCP implemented in software in a 2 gigahertz computer with 100 megabits sec memory bus. If implemented in hardware as a machine instruction in a 2 gigahertz CPU it should take no more than 5 nanoseconds estimated .

It takes only four 2 state ndFSMs controlled by CCPs for point to point message transfers it may take 10 or more 2 state ndFSMs for transferring a message from one group of cells to another group of cells in shared memory environments depending on the number of cells in each group Section 8 and up to 24 or more 2 state and 4 state ndFSMs for similar message transfers in distributed memory environments using TICCNET . Incorporating the SMS mechanism into message transfers requires four more 2 state ndFSMs see for each shared memory pathway sm pathway. It may require 10 or more additional ndFSMs for a distributed memory pathway dm pathway depending on the number of functionPort groups to which message is transmitted see . Thus as mentioned earlier it should take only tens or hundreds of nanoseconds for point to point and group to group message transfers if CCP is implemented as a hardware instruction.

Communication is reduced to a Turing computation 20 performed by ndFSMs and becomes an integral part of computations performed by cells. Each cell transmits its message immediately as soon as it is ready via hardware software pathways connected to its ports. There are no synchronization and scheduling delays. Multiple protocols may be executed by cells operating in parallel without mutual interference. Each cell may at any time execute only one protocol. All communications are asynchronous and they do not use sequential buffers.

It is necessary to explain how these are made possible and how computations and communications performed by each cell are organized before the reader can see how the benefits outlined in Section 1.1 flow directly from this.

Cells use their ports to exchange messages with each other via pathways that interconnect the ports. Each port may be attached to only one unique cell called its parent cell prevents port interference and each port may be connected to only one pathway prevents message interference . There are three kinds of ports qeneralPorts g through which cells send out service requests to other cells these are like the output ports of calculus Agents 7 8 9 functionPorts f through which they receive service requests from other cells and respond to them these are like the input ports of calculus and interruptPorts i through which they receive interrupt messages from other cells there are no calculus analogs for these . GeneralPort and FunctionPort are subclasses of the abstract class Port. InterruptPort is a subclass of FunctionPort. Every Cell subclass should have at least one of each kind of Port.

Each port C.p attached to a cell C holds the communication protocol C.p.protocol to send signals over the pathway C.p.pathway connected to it. This protocol is defined using concatenations of CCPs having the form X x Y y Z where x Y and z are components in the pathway and x and y are signals. CCPs may appear in a protocol possibly embedded in other programming language statements Section 8 . Protocols are dynamically updated as pathways are changed. Each pathway is defined by a collection of interacting ndFSMs which execute the CCPs. Only the parent cell of a port may execute the protocol associated with that port.

Pathways and CSP Channels Pathways in shared memory environments contain only software components like CSP channels 10 12 . Pthreads parallel threads in TICC Ppde correspond to Communicating Sequential Processes in CSP. Unlike CSP i pathways allow group to group asynchronous communications with time synchronized message deliveries ii data exchange mechanisms among interacting pthreads are not coded into the pthreads iii unlike CSP channels pathways do not block senders and receivers iv pathways transmit only signals and v if messages are transmitted then pathways contain virtualMemories which hold messages and pthreads to build and process messages. Real memories are assigned to virtualMemories during compile time or run time.

Signals traveling over a pathway eventually establish the context in which the message in its virtualMemory is delivered to intended recipients in the case of shared memory pathways sm pathways or transported to other virtualMemories belonging to intended recipients in the case of distributed memory pathways dm pathways . For each sm pathway the virtualMemory that holds the message if there is one is unique and private to that pathway. Similarly for each dm pathway see all virtualMemories in that pathway are private to that pathway. No pathway may use the virtualMemory of another pathway.

We refer to sm pathways with virtualMemories as Das pathways since they were first introduced by Souripriya Das 19 . We use the term pathway to refer to both sm pathways and dm pathways.

Let us first consider some simple sm pathways. The parent cell C of a port C.p executes the protocol C.p.protocol at the port in order to transmit signals via the pathway C.p.pathway connected to that port. While executing the protocol the parent cell uses only its local memory and memories associated with the pathway components. Protocol execution will not invoke any method pthread or process that is defined outside the protocol. Thus Operating System OS is not used for message exchanges.

A simple sm pathway is shown in . Here a software branch connects generalPort C.g of cell C to functionPort D.f of cell D. In signal requesting a service travels first through the branch from C.g to D.f and then the response signal indicating completion of the requested service travels back from D.f to C.g. Cells use their ports also software components only when they send out signals via the ports or when they receive and respond to signals received at the ports. Two cells connected to two ends of a pathway as in may never use the ports connected to that pathway at the same time. Signals travel over a pathway only in one direction at a time. These hold true for all pathways in TICC .

Each port in contains a 2 state non deterministic finite state machine ndFSM with states S send and R receive as shown in the figure. All generalPorts g start with the initial state S and all functionPorts f with initial state R double circles in . The C.g.pathway in is C.g D.f and D.f.pathway is D.f C.g C.g.pathway D.f.pathway read as congruentTo since they both denote the same physical pathway. We will often write C.g.pathway D.f.pathway it should be understood as C.g.pathway D.f.pathway.

The initial state of C.g.pathway is S R and the initial state of D.f.pathway is R S . In its initial state C.g.pathway is ready to send a signal from port C.g to port D.f and port D.f is ready to receive the signal sent by port C.g. In the following we use the following convention for any port or agent x x.state x.ndFsm.state and x.input x.ndFsm.input where x.ndFsm is the ndFSM embedded in x. The pathway in has no agents we will later see pathways with agents.

Logical characterizations of CCPs This is shown in Table 1. Characterizations are presented in Hoare s Hoare 15 pre condition post condition notation. Pre condition for a CCP in Table 1 may depend on the states of both signal sending and signal receiving ports. Interpretations of the CCP characterizations 1 through 10 in Table 1 are described below.

Signal Transmission from g to f 1 When port g is in state S it accepts signal c completion signal as its input signal from its parent cell C. 2 While in state S with input c port g sends out signal s and moves to state R while port f that receives this signal s is in state R. Port f accepts s as its input signal. 3 Port f moves to state S when its input signal s is sensed by its parent cell D by executing the signal sensing test f mR mR for messageReady . If f.input s then f mR returns truth value true and f.state moves to S. 4 Else f mR returns false. Signal s here is referred to as the delivery signal. Sensing of a delivery signal by a recipient cell constitutes message receipt by that cell. Since f mR does not change the value of f.input the delivered signal at f may be successfully sensed several times. As we shall see below f.input changes value only when D begins to send back its reply signal.

Reply Signal Transmission from f to g 5 Cell D sends completion signal c to f indicating it has completed its task. This sets f.input c. 6 When f.state S f.input c and g.state R f sends start signal s to port g and changes its state to R. This is the response signal from D. 7 10 Cell C may use one of two sensing tests to receive the delivery signal s at its port g g mR or g pR pR for pathwayReady . Notice the delivery signal at g may be sensed only once using the sensing g mR test since g.input is reset to the empty symbol after sensing. In both g mR and g pR tests g.state moves to S. Whereas g mR test will succeed only once on sensing a delivery signal g pR will succeed repeatedly after the first sensing since the state of g changes to S.

For any port p whether p is a general or function port sensing of a delivery signal always moves p to state S. This has a special significance which we will later see in Sections 5.3 and 7.2.

Thread Interaction Protocols TIPs TIP 1 in Table 1 specifies the following If the pathway is ready then C executes the pthread g x to do whatever it needs to do before sending a service request. This pthread is defined in the cell C g x g and is executed in the private memory assigned to C. Immediately after executing g x C executes g s s for send which causes the communication protocol 1 in Table 1 to be evaluated in the memory commonly shared by ports g and f. As we shall later see one may think of this commonly shared memory as a signalMemory associated with the branch. The signalMemory holds input signals and states of ports in the pathway. This results in the delivery of service request signal s to port f.

TIP 2 in Table 1 specifies the following When D senses the service request signal sent by C to its port f by applying the f mR test D begins to respond to the received signal by executing the pthread f r D r f r for reply which is defined in cell D and executed in the private memory of D. Immediately after completing the execution of f r D executes f s . This causes communication protocol 2 in Table 1 to be evaluated which results in the delivery of reply signal s back to port g. Sensing of this reply signal by the parent cell C of port q marks the end of the transaction which began when C sent its service request signal to D.

Restrictions Imposed by Pathway State Changes At the beginning of the transaction the state of C.g.pathway is S R and the state of D.f.pathway is R S . At the time the signal is sensed by cell D the state of the pathways change to R S and S R respectively. In this new state the pathway is ready to send back a reply signal. When the reply signal is sensed by cell C the transaction is completed and C.q.pathway state reverts back to S R . These state changes enforce the following restriction C.g can send a second service request signal and D.f can receive a second service request signal only after the first transaction has been completed. Successive service request signals may be sent through a pathway only after successive transaction completions. This hold true for all TICC Ppde pathways.

Mandatory Responses to Service Requests Another general rule that holds true for all TICC Ppde pathways is that every service request is responded to without fail via the same pathway through which the request was received. An exception to this general rule occurs in one way ring streets Section 8.1 . Every transaction takes place through a dedicated pathway. Receipt of the response always resets the pathway to its initial state even in one way ring streets.

Tuning In each signal transmission session each ndFSM in a pathway is always in a state in which it is ready to receive and immediately respond to the signal sent by another ndFSM. This is true for all TICC pathways however complex they are and however many ndFSMs are embedded in them. This is called tuning. Tuning eliminates the need for synchronization sessions during signal transmissions and speeds up signal transmissions considerably.

NdFSMs in a pathway that exchange signals are tuned to each other by i setting them to appropriate initial states. ii When a signal is sent one way through a pathway it resets the initial state of the pathway to a new state in which the pathway is ready to transport the response signal the other way. iii Sending the response signal through the same pathway always resets the pathway to back to its initial state. iv Tuning is maintained by requiring that every transaction initiated through a pathway should be completed by sending a reply signal through the same pathway and v by requiring that a new transaction may be initiated through a pathway only after the current transaction over that pathway has been fully completed.

Integration of Computation Communication Computations and communications are both performed by the same cell. Computations occur by executing pthreads. Communications occur by evaluating protocols. Computations are defined by programs sequences of statements in a programming language. Protocols are defined by sequences of CCPs which may be embedded in programming language statements. Compiled codes for programs define computations and compiled codes for protocols define communications. They are no different from each other since each CCP may itself be compiled into a machine instruction. Thus there is no distinction between executing pthreads to perform computations and evaluating protocols to perform communications. They are both invoked and executed by cells when they execute TIPs. Every port of a cell has a TIP defined for it. TIPs are executed only by the parent cells of ports at which they are defined.

It should however be noted no protocol evaluation will occur in the middle of a pthread execution. Always protocols are evaluated only after pthread executions have been completed and messages are ready to be sent. They are never interleaved with each other. However it is possible that after one pthread execution followed by a protocol evaluation at one port another pthread execution and or protocol evaluation at another port of the same cell may take place with in the same TIP. In all cases TIPs always isolate message processing computations from protocol evaluations. A TIP at a port C.p of a cell C has the form C.p TIP C.p C.p tip . If C.p is true at the time C.p is polled by C then C executes the C.p tip 0 else C skips port C.p. We refer to C.p tip as the TIP body and C.p as the TIP guard.

Polling Each cell polls its ports cyclically in some order. Polling order does not determine the order in which ports of a cell are serviced since a service is performed only if a delivery signal is sensed at a port at the time it was polled and signal delivery times and polling times are not synchronized to each other communication is asynchronous.

In Table 2 the pthreads g x g msg x g and f r f msg r f . These pthreads are defined in message subclasses of messages written by parent cells of g and f in to the virtualMemory M. We refer to the virtualMemory M by g.vM f.vM M g.pathway.vM f.pathway.vM since M in is uniquely associated only with these ports and the pathway. Compiled codes for message subclasses of messages in a virtualMemory are also held in the virtualMemory. Here M provides the execution environment for the pthreads thus defined in it and M provides the shared memory environment for both cells C and D. Structure of virtualMemory that allows for this kind of activity is described in Section 7.2 and Section 10.

Cell D in may not sense the signal delivered to it at the time it was delivered it is possible that D was servicing one of its other ports at that time. Eventually when cell D polls its port D.f and evaluates the guard D.f mR in the second TIP of Tables 1 and 2 it will sense the delivery signal at D.f if there is one. Cells never miss sensing any signal delivered to any of their ports. Signals missed in one polling cycle are caught in the ensuing cycle. CCP characterizations given in Table 2 are similar to the ones in Table 1.

Let us suppose that m is the service request message sent by g in and m is the response message sent back to g by f. As in the case of transaction will end at the time port g senses the delivery signal for the reply message m . Let us suppose m was delivered to g at time tand m was sent by g at time t t

Correctness of Transactions The transaction between ports g and f is correct iff the messages m and m satisfy an a priori defined relation R m m where R is the name of relation that is specific to ports g f and in addition t t g f holds true where g f is the maximum time it may take for the transaction between g and f to complete. In cases where no messages are exchanged as in only the timing condition given above should hold true.

Well matched Ports Ports g and f are well matched iff R m m and t t g f hold true for all transactions between g and f in which messages m m were exchanged and only t t g f holds true when no messages were exchanged.

Correctness of an Implementation An implementation is correct iff all pairs of ports in the implementation that are connected by pathways are well matched.

Port groups shows a simple pathway with an agent a0. The agent broadcasts a time synchronized signal to both ports in D.f D.f . Ports of the same kind i.e. all generalPorts all functionPorts or all interruptPorts attached to distinct cells and connected to the same agent in a pathway form a port group. Thus ports D.f D.f in constitute a port group.

Agents Signals are delivered to ports D.f and D.f at the same time by agent a0. However since cells operate in parallel and cell activities are not synchronized with signal deliveries Dand Dmay not sense and respond to delivery signals at D.f and D.f at the same time. Eventually Dand Dwill each sense the delivered signal and respond to it each at its own time. Agent a0 will send a response signal back to C.g only after receiving completion signals from both D.f and D.f. We refer to this as dispatch coordination. The Agreement Protocol method a0 AP c c in the 2nd protocol in Table 3 enforces dispatch coordination as described below. Agent a0 thus does time synchronized signal delivery to the port group D.f D.f and coordinated signal dispatch from D.f D.f .

Coordination of parallel protocol executions Evaluation of protocol 2 in Table 3 proceeds as follows Both D.f and D.f have similar protocols We use p.protocol to refer to the protocol at a port p. The protocols at ports D.f and D.f are shown below 1 .protocol 0 and 2 .protocol 0

The protocols P1 and P2 above are evaluated in parallel respectively by cells Dand D. They may not however be evaluated simultaneously. Dand Dstart evaluating their respective protocols in parallel but not necessarily synchronously. After executing the CCPs D.f c a0 and D.f c a0 that precede the agreement protocol method AP c c in P1 and P2 above both Dand Devaluate a0 AP c c in parallel. The condition a0 AP c c will become true only after a0 has received both signals cand c signal cfrom D.f and cfrom D.f. Dor D which ever starts evaluating a0 AP c c first keeps evaluating a0 AP c c repeatedly until it becomes true. The cell that starts evaluating a0 AP c c last it will evaluate to true the very first time it is evaluated. As soon as a0 AP c c becomes true one of the cells Dor Dis non deterministically chosen by a0 to execute the rest of the protocol and the other is forced to stop its protocol execution.

Reader may verify that the segment of the protocol that follows a0 AP c c is the same for both D.f.protocol and D.f.protocol. Therefore on satisfaction of a0 AP c c agent a0 in sends response signal s to port C g no matter who executed the protocol. Thus a0 coordinates parallel execution of different segments of the protocol by parent cells Dand Dof ports in the port group D.f D.f .

A Das pathway with a virtualMemory similar to the pathway in is shown in . Its associated TIPs and protocols are shown in Table 4. In this figure a1 does time synchronized message delivery and coordinated message dispatch a0 does message dispatch when a service request is sent out and message delivery when a response message is sent back.

Networks in represent synchronized fork join operations A fork occurs when signal is sent by port g to a functionPort group and a join occurs when ports in the functionPort group send back response signal. We extend this notion of fork and join to the situation where a generalPort group containing more than one port sends a joint service request to a functionPort group. Protocol for such group to group fork and join operations are discussed in Section 8.

It may be noticed for any port p always p mR p pR holds true i.e. p always becomes ready to send out a message if the guard at the port returns true.

Sm pathways Links that connect ports to agents or other ports are called branches. Links that interconnect agents are called h branches hidden branches . All components of a sm pathway ports agents branches h branches and virtualMemories are software components. They all operate in the shared memory environment of the pathway that contains them.

Dm pathways Agents and some ports in dm pathways of the TICCNET are hardware components each operating in its own local memory branches and h branches in dm pathways are signal transmission lines. Besides agents ports and virtualMemories dm pathways also have specialized hardware switches and routers embedded in them. Communication occurs in two phases i pathway establishment and ii signals data exchange. Switches and routers are used only during pathway establishment. A typical dm pathway is shown in . Once established a pathway is kept in place and repeatedly used until it is dismantled and a new pathway is established. Messages may be exchanged only through already established dm pathways. Signal and data exchanges through signal data transmission lines are managed through CCP evaluations. As in sm pathways all agents and ports in a dm pathway that exchange signals data always remain tuned to each other. No two dm pathways share components except switches and routers which are not used during message transmission. Thus while there may be interference while trying to establish dm pathways in parallel there will be no interference while exchanging messages through already established dm pathways. This coupled with tuning enables high speed parallel message exchanges over TICCNET . The TICCNET can accommodate thousands of distinct mutually non interfering point to point and point to group dm pathways allowing thousands of simultaneous parallel message exchanges.

Kinds of Pathways There are only three kinds of pathways i Simple pathways like the ones in ii Das pathways like the ones in and and iii distributed memory pathways called dm pathways like the one shown in . The first two kinds of pathways together constitute the shared memory pathways or sm pathways. It should be noted even simple pathways will have memories associated with them. Thus the pathways in will each have a signalMemory associated with it which will be shared by the parent cells of ports connected to that pathway. It is not shown in . Every virtualMemory will also have a signalMemory component see . SignalMemory will hold signals and states associated with ports and agents embedded in a pathway and it will also hold compiled codes of protocols associated with those ports. Parent cells of ports connected to a pathway will use the signalMemory of that pathway to execute the respective protocols.

Pathway Subclasses and Parameterized Protocol Methods These three kinds of pathways constitute three pathway subclasses Smpl Pathway Das Pathway and Dm Pathway where Smpl Pathway and Das Pathway are themselves subclasses of Sm Pathway. As we shall later see protocols for these pathway subclasses are parameterized using components ndFSMs embedded in the pathway subclasses. Thus for example the protocol for C.g.pathway C.g D.f in will be C.g.protocol C.g.pathway protocol C.g D.f . The protocol for C.g.pathway C.g a0 D.f D.f in will be C.g.protocol C.g.pathway protocol C.g a0 D.f D.f . The protocol for D.f.pathway D.f a0 C.g will be D.f.protocol D.f.pathway protocol D.f a0 C.g . These pathway protocols would be defined in the Smpl Pathway subclass as Smpl Pathway protocol Port Port Smpl Pathway protocol Port Agent PortGroup and Smpl Pathway protocol Port Agent Port respectively.

Compiled codes for all parameterized protocols are built into TICC Ppde by being defined in the various pathway subclasses. For any port p when p is connected to an instance of a pathway subclass p.protocol is set equal to p.pathway protocol . . . substituting appropriate parameters in the appropriate protocol defined in that pathway subclass. Executing eval p.protocol executes p.pathway protocol . . . in the signalMemory associated with that pathway instance. Thus protocols are invoked and executed as methods. Eval p.protocol is automatically invoked and executed when implementers use p s s for send or p f f for forward commands in TIPs they define at ports p. Implementation of eval operator in TICC Ppde using TICC CPU is discussed in Section 10.2. Implementers do not have to define protocols. Thus implementers do not have write any synchronization and coordination programs. Therefore TICC Ppde is self synchronizing and self coordinating.

Properties that sm pathways and dm pathways share in common are listed below in three categories. Some of the properties have been already mentioned.

TIP formats are Independent of Pathway Structure i The communication primitives are p s s for send and p f f for forward where p is a port f forwards a received message to a port of another cell may be after some modifications s sends a newly formed message. The primitives p s and p f are used to invoke and evaluate the unique protocol p.protocol p.pathway protocol . . . associated with p.pathway. ii p.protocol is dependent of the nature of p.pathway. The protocol is different for different pathways. iii The same communication primitives p s and p f are used to invoke and evaluate p.protocol no matter which kind of pathway is connected to p. iv Communication primitive p s or p f is evaluated immediately after message to be sent or forwarded becomes ready. v Invoking and evaluating p.protocol causes signals to be transmitted over p.pathway which in turn causes a message if any to be delivered or transmitted to its recipient ports also connected to p.pathway. vi Only the parent cell of p may invoke and execute the communication primitives p s and p f vii TIP formats at ports p are independent of the kinds of pathways connected to p. viii Finally all components in any pathway that exchange signals remain always tuned to each other at all times. These properties eliminate the distinction in software systems between shared memory and distributed memory communications and totally eliminate the need for scheduling and synchronization sessions in communications and thus significantly speed up message transfers.

Simultaneous Parallel Execution of Group to group Message Exchanges Distinct parent cells Cof distinct ports C.p belonging to a port group G C.p C.p . . . C.p n 1 Sections 2.3 and 8 constitute a cell group. i Cells Cin the cell group simultaneously evaluate in parallel their designated segments of C.p.protocol distinct segments being specialized to distinct cells in the cell group. Each such segment being a component of G.pathway.protocol where G.pathway is the pathway connected to ports in the port group G. Parallel execution of all segments together implements the group to group asynchronous message exchange over G.pathway . Agents embedded in G.pathway coordinate such simultaneous parallel protocol segment evaluations Sections 2.3 and 8 . Agents also signal specialized cells called eb Event Builder cells which install message dispatch and message delivery events that occur while a message is being sent or forwarded over G.pathway. ii In a distributed memory environment a generalPort group in one shared memory multiprocessor SMP may broadcast through a dm pathway in TICCNET a joint message to several functionPort groups F F . . . F m 1 each Fresiding in a distinct SMP . The broadcast message is transmitted in parallel to all the destination functionPort groups and delivered synchronously to all recipient functionPort groups. The functionPort groups send their replies back to the source generalPort group in multiplexed mode one after the other through the same pathway. This maintains mutual tuning of components in dm pathways.

High speed Parallel Message Exchanges i In all pathways all messages are sent immediately as soon as they are ready. There is no message scheduling. ii All agents and ports in a pathway that exchange signals are always tuned to each other so that the signal sent by one to another is immediately received by the recipient and responded to at the appropriate time no matter how complicated the pathway might be. This eliminates the need for scheduling and synchronization sessions. iii No two pathways share components or any process or thread in common and thus no two parallel executions of distinct protocols will ever interfere with each other. No protocol uses any process or thread not defined in the protocol itself. This holds true both for software sm pathways in SMPs and hardware dm pathways in TICCNET . Therefore iv the number of messages that may be exchanged in parallel is limited only by the number of distinct pathways and the number of distinct cells.

Mobility Dynamic changes of connections to sm pathway destination ports may occur in the middle of a transaction in sm pathways. Consider a destination functionPort q to which q.pathway is connected with virtualMemory q.vM. When the parent cell of port q transfers pathway connection from the destination port q to a new destination functionPort p while computing the response to message received at port q q.pathway becomes the new pathway p.pathway that is now connected to p and q.vM becomes p.vM. Parent cell of p may then read messages in p.vM and execute pthreads and methods in p.vM to process and respond to messages in p.vM. Once the parent cell of p completes processing the messages and completes writing a response message in p.vM the pathway connection is returned to port q by the parent cell of port p when p.vM becomes q.vM again. Parent cell of q may then modify the response message in q.vM and send it back to ports that sent the service request. This enables program mobility in shared memory environments.

Pathway connections to generalPorts that sent the message cannot be changed in this manner. Also such dynamic changes of pathway connections cannot be made in dm pathways. However new pathways may be installed dynamically at any time between dynamically formed port groups both in sm pathways and dm pathways before messages are sent. By transporting the contents of an entire virtualMemory over a dm pathway from one virtualMemory to another one may obtain program mobility across dm pathways.

Top Level Classes TICC defines the following top level classes Cell Port Pathway Agent VirtualMemory Branch and Message. We use the notation cell port agent pathway virtualMemory branch and message to refer to objects which are instances of these classes all software components. As with Actors Hewitt 5 6 and calculus Agents 7 8 9 each cell is an inherently parallel software component that runs in its own assigned ComPuting Unit CPU . There are several differences between cells Actors and calculus Agents. We will describe them later.

Restrictions on Pathway Structure No two ports belonging to the same cell may be connected by a branch and no two branches may connect two ports belonging to the same cell to agents in the same pathway unless the ports belonged to a port vector Section 5.2 . For example see pathway in . Here the ports eb.fand eb.fare respectively connected to agents a2 and a3 that belong to the same pathway. Here eb.f eb.f is a port vector of the cell eb. In all cases a cell cannot send messages from one of its ports to another one of its ports this prevents possible deadlocks. However distinct ports belonging to distinct cells may be connected by branches to the same agent. As mentioned earlier such ports form ordered port groups D.f D.f in is an example. No two distinct port groups may intersect with each other and no two ports belonging to the same cell may ever be in the same port group. All cells in any cell 645 group will always reside in the same SMP. As we shall see in Section 8 these restrictions make it possible to exchange messages between port groups through group to group pathways.

Cell Interaction Process Each C CIP contains the collection of all TIPs defined at the ports of cell C one for each port together with a cell initialization method. Initialization and interrupt message handling described below illustrate the general control structure for CIP operations. These will vary from cell to cell depending upon when interrupt message at interruptPorts are recognized in a cell s polling cycle the nature of interrupt messages and the order in which ports are polled. A CIP has the form 

The pthread i r i msg r i is defined in message subclass of the message in virtualMemory i.vM of the interruptPort i. Let InterruptMsg refer to this message subclass. The definition of InterruptMsg r i is shown below and discussed in the second paragraph following the definition.

CIP Initialization In the CIP in 2.1 initialize is the truth value of the local variable cell.initialize of the cell and i is the interruptPort of the cell. A dormant cell C is activated in a processor selected by TICC Ppde by the first interrupt message delivered to C.i. In general a dormant cell may be activated by the first message delivered to any of its ports. The protocol that delivers message performs this activation Section 8 before message delivery. Upon activation if initialize is true then the cell sets initialize stopPolling false performs init which may install other cells and pathways in a network and send messages to other cells and other cell variables defined in the cell subclass sends an acknowledgement back to the cell that started it by executing i s if indeed it was activated by an interrupt message at port and then proceeds to the while loop. The order in which these operations are done may vary from cell to cell. CIPs of different cells differ only in their initialization routines.

InterruptPort Servicing In the while loop the cell first polls its interruptPort. If there is no interrupt message it skips the port. If there is then it executes i r i msg r i shown in 2.2 where i msg is the interrupt message in the virtualMemory i.vM. There are four cases to consider in selectOne in 2.2 . i If cell suspended is true then it means the cell had been previously suspended. In this case cell.suspended is set to false and the cell immediately proceeds to execute the rest of the while loop. ii If i msg suspend is true then cell.suspended is set to true and the cell prepares to suspend itself and immediately release its assigned processor after doing these the cell becomes dormant. The next interruptMsg delivered to the cell will activate the cell in an available processor. When so reactivated the cell will skip initializations and proceed directly to the while loop since initialize will then be false. iii If i msg terminate is true then the cell terminates operations at the end of the current cycle of the while loop and releases its processor since cell.stopPolling is set to true. iv The default case of selectOne in 2.2 is to assign priorities to the ports of the cell as specified in i msg . These priorities are used by the ensuing poll SortPorts in 2.1 . The suspend resume operations here are managed by TICC Ppde without having to invoke the operating system Section 10 .

Polling After polling its interruptPort the cell begins to poll its other ports in the order specified in C.pollingOrder sorts ports that are ready to be serviced into C.sortedPortsList. A port is ready to be serviced if it is ready to send out a message or if it has received a service request message. Polling a port determines whether it is ready or not. Sorting is done based on the times at which messages were delivered to ports and attribute C.priorityList associated with a port p which is a list of lists of ports attached to C having the structure priority 1 ports priority 2 ports . . . priority n ports 1 All ports with the same priority are sorted according to message delivery times associated with them. GeneralPorts with no messages are sorted only based on their sorting priority. For 1 i i 1 n ports with priority i are sorted before ports with priority i 1. Sorting is done by executing poll SortPorts .

After sorting the cell executes p tip for each p in that list in the order they appear in the list. The while loop is repeated until stopPolling becomes true. The while loop in 2.1 is called the polling cycle. Polling cycles are not synchronized with message deliveries. While polling its ports in a polling cycle if a port is not ready for service then the cell skips that port and polls its next port. Ports that are skipped may receive new messages while polling other ports or during execution cycle in the while loop. Ports whose pending messages were missed in one polling cycle will be sensed and included in the sortedPortsList in the next polling cycle. Ports may not be serviced in the same order in which messages were delivered to them. However no input message would ever be missed by the cell unless the cell was prematurely terminated or there were deadlocks in the application system. Thus every transaction is completed under normal operating conditions i.e. when there are no deadlocks and livelocks in the system. This is an important requirement in TICC Ppde.

CIP 2.1 is the default CIP defined in the top level Cell class All cells instances inherit this default CIP unless designers defined a different CIP for the subclasses to which the cells belong. Cells are classified into subclasses according to numbers of ports of different kinds they have and according to their CIPs. Implementers need not define CIPs for cells unless cells in an application require special CIPs that are different from the default CIP. Implementers may have to define the init routine for each cell subclass. Compiled codes for the CIPs are moved into private memories of every CPU that has been assigned to each cell instance.

Other Modalities of Port Servicing It is possible that sorting cycle is dispensed with and cells are serviced in the order ports are polled as it happens in the Dining Philosophers example in Section 7.4. It is possible to have synchronous computations of the following kind a cell waits at its port until a message is received or until the port is ready and sorts the port when it arrives according to its priority and then only proceeds to poll its next port. Such synchronous computations are specified by using guards of the form C.p in TIPs. The indicates the need to repeatedly evaluate the guard until it becomes true. Starred guards are called synchronous guards and TIPs with starred guards are called synchronous TIPs.

Simple examples of TICC Ppde implementations are presented in Section 3. An outline of computational facilities in TICC Ppde that support general parallel computations is presented in Sections and 4 and 5. More details are presented in Section 6. Examples with ALLEOP proofs are presented in Section 7. Examples in Section 3 use networks similar to those in . The examples are taken from 13 . The first example in Section 3 is used to introduce ALLEOPs generated by the system from implementation specifications traces and causalnet derived from ALLEOPs and the role played by SMS at run time. This example also illustrates concurrency automatic coordination and temporal synchronization performed by TICC Networks with no need to use monitors Hoare 12 semaphores Dijkshtra 23 24 or rendezvous. The second example in Section 3 introduces the concept of encapsulation in TICC Ppde and illustrates use of non deterministic guards.

Implementation specification in each example consists of the TICC network TIPs for the various ports CIPs for cells and a polling cycle for each cell. The polling cycle specifies the order in which ports are polled in a cell. The TICC network is an abstraction of message exchanges forks and joins and synchronization and coordination that occur in parallel computations. It specifies the control structure of parallel computations. No proofs are presented for the examples in this section examples with ALLEOP proofs are presented in section 7.

We begin with a simple game from Magee Kramer 13 . FSP model of the game as it is given in Magee Kramer 13 is 

Synchronization in the conventional sense 12 13 is supposed to occur on the action term meet . TICC Ppde implementation of the game is presented here. We show the ALLEOPs models derived from implementation specifications traces derived from ALLEOPs and the causalnet that SMS produces. All derivations are done automatically by the system. ALLEOP models are models of implementations derived from implementation specifications. They are not models of intended designs of a system as FSP models are in Magee Kramer 13 . Thus ALLEOP models are more complicated than FSP models but in a sense their structures are similar to FSP structures.

The TICC network is shown in . Every TICC network has at least one environment cell E also at times called the confiqurator cell. It is used to configure the network and start operations. When TICC GUI Graphical User Interface screen is opened it comes with E installed in it. Application programmer should have already defined the cell subclass E and other cell subclasses needed for the application before opening TICC GUI. E is activated by user by clicking on its image on GUI screen and sending an interrupt signal to its interruptPort E.i. E is used to install all other cells and all pathways in the TICC network. All the installed cells and pathways appear on the TICC GUI screen and the resultant picture after user performed repositioning of images looks like the one shown in except that TICC GUI figures are in color. Once this is done application is started by clicking on E and selecting the start command from a drop down menu. In response E broadcasts an interrupt signal to the interruptPorts of other cells in the network via its port E.g1. This activates the cells.

In the following we use abbreviations Be for Ben Bi for Bill Me for Meeting and B for Ben and Bill . Be.f Bi.f B.f and Be.g Bi.g B.g are port groups. Ben and Bill both receive synchronized signals and send out coordinated signals through these port groups Agents a1 and a2 in perform synchronization and coordination as discussed in Section 2.3.3. The CIP of cell E is shown below 

The above CIP specifies the following operations The first interrupt signal sent by user to the interruptPort E.i activates E and causes it to perform initialization defined in init which installs all cells and pathways needed for the application. After this E sends an interrupt signal to the interruptPorts of cells in the game via its port g1. This activates the cells in the network in . Once activated E replies to the interrupt signal that started it initializes its variables and then proceeds to execute its while loop. In the while loop it first polls its generalPort E.g. If port E.g is ready to send out a signal and E is ready to start the game E.g sends a signal to Be.f Bi.f B.f. This starts the game. Having started the game E waits at its port E.g to receive end of game signal.

After receiving end of game signal E polls its interruptPort E.i. If E senses an interrupt signal then it begins to terminate its operations. This will be the second interrupt signal received by E from user. The first one started it. Before terminating E broadcasts an interrupt signal to all other cells via its port g1. This would be the second interrupt signal broadcast by E. The first one started the cells. Each cell that receives the second interrupt signal sends back a response and then terminates itself. E terminates only after receiving the coordinated response to the interrupt signal it broadcast to them from all the cells. This coordinated response is forwarded to E by agent a3 in . This with minor variations is the general start stop process used in all applications.

If there is no interrupt signal at E.i then E may repeat its polling cycle as shown in 3.2 and 3.7 . Other cells in have similar CIPs. Notice the TIP at port E.g in 3.2 has another TIP g mR embedded in it whose tip body is empty. But in general tip bodies of embedded TIPs need not be empty. For example in TIPs 3.4 and 3.5 below TIP bodies of embedded TIPs are not empty. Multiple such embeddings may occur in a TIP. We have omitted the start stop processes and interruptPort polling and servicing in the following discussions.

When Bill and Ben sense the signal sent by E they begin to do their respective things play and work as shown in 3.4 and 3.5 . After finishing whatever they did each of them sends a signal to Me.f via their respective ports Bi.g and Be.g. Of course they do not synchronize the time at which they send signals. Agent a2 waits until it has received signals from both Bi.g and Be.g and then sends a coordinated signal to Me.f. Thus meeting always begins only when both Bill and Ben are ready for it. When meeting is over Me.f sends synchronized signals to Bi.g Be.g B.g via agent a2 see . When Bill and Ben receive this signal they both send a coordinated end of game signal back to E.g via a1. At this point E may start the next iteration of the game if gaming is not terminated by an interrupt signal at its port E.i.

What is called synchronization in the FSP framework of Magee Kramer 13 is called coordination in TICC Ppde. Here agent performs coordination through a kind of rendezvous operation on received signals. The difference between conventional programming using rendezvous and TICC Ppde is that implementers do not have to ever write programs to perform rendezvous in applications they implement. Agents in pathways perform this coordination and coordination is built into pathway protocols.

Synchronization in TICC Ppde always refers to temporal synchronization of events that occur in parallel. In this example temporal synchronization occurs when signal from E.g is delivered to Bi.f Be.f B.f by agent a1 and when signal from Me.f is delivered to Bi.g Be.g B.g by agent a2.

POLLING CYCLES InterruptPort pollings have been ignored here. Polling Polling 3.7 Polling Polling 3.8 Polling Polling 3.9 Polling Polling 3.10 

Polling is recursive because of the while loop in CIPs see 3.2 . This completes the design of the Bill Ben game. When refinements for E readyToStart Bi.f play Be.f work and Me.f meet are completed the implementation of the Bill Ben game will be complete. Computations performed by specifications given so far are characterized by the following ALLEOPs.

Read in the following as causes and as immediately causes . These are called causal connectives. They are defined in Section 6. ALLEOPs combine information in TIPs TICC network and polling cycles. All ALLEOPs begin with but we often omit the symbol but it should always be assumed to be present the symbol is read as always . Five simple transformations occur when ALLEOPs are derived from TIPs 

 i is replaced by ii . . . is replaced by . . . if ALLEOPs continue after the last right chain bracket else it is replaced by . . . . Similarly . . . and . . . are replaced by . . . and . . . respectively if ALLEOPs continue else by . . . and . . . . iii signal sending actions caused by evaluation of p s at ports p that appear in TIPs are replaced by their expansions in terms of signal sending and delivering events with associated time maps as described below iv also parallel activations caused by signal deliveries are specified as described below and v each signal sensing action p mR or p mR is given the signal delivery event that is sensed by it as its argument.

The port ALLEOPs described below illustrate these transformations. Each port ALLEOP has two components ALLEOP guard and ALLEOP body with the structure ALLEOP guard ALLEOP body ALLEOP body is invoked only if ALLEOP guard is true else the body is skipped. Let us first consider the port ALLEOP for port E.g. This is derived from E.g TIP in 3.3 the TICC network in and the polling cycle in 3.7 . It is shown in 3.11 and its interpretation follows thereafter.

Here E.g ALLEOP guard is identical to E.g TIP guard appearing in 3.3 . Communication statement E.g s appearing in TIP body in 3.3 has been transformed to signal sending delivering events that occur when E.g s is executed signal sending event is E.g T E.g 0 for Send and signal delivery events are Be.f T E.g 1 and Bi.f T E.g 1 for Delivery . The suffixes T E.g 0 and T E.g 1 appearing in the signal sending and delivering events are the time maps. Each time map maps to an increasing sequence of time points. The angle brackets . . . appearing around the delivery events in 3.11 specify that the event occurrences were completed at time points specified in the time maps. Absence of such angle brackets around the sending event E.gindicates the event started occurring at a time point specified in the time map. Thus the presence and absence of angle brackets around events distinguish between starting and ending times of those events.

The two signal delivery events in 3.11 Be.fand Bi.f have identical time maps T E.g 1 . This specifies that signal is delivered synchronously to both the ports Be.f Bi.f at the same time point in T E.g 1 . Different values of in the time maps T E.g for 0 and 1 uniquely identify the two different sequences of time points associated with the same port E.g. Distinct communication events at the same port appearing in a CIP or TIP have distinct values of associated with them. The events E.g Be.fand Bi.fare all caused by evaluation of the protocol at port E.g. Details of protocol evaluations are not shown in ALLEOPs.

Sequences of time points associated with time maps are interpreted as follows The sequence T E.g 0 t t . . . t t

The delivery events cause parallel activations of other ALLEOPs in the cells to which signals are delivered. The symbol appearing in the delivery events in 3.11 specifies that signals activate the ALLEOPs Be.f ALLEOP and Bi.f ALLEOP in parallel. System gets this information from the TICC network for the game. We refer to this as parallel activation even if only one other ALLEOP is activated by signal transmission because all the activated cells always work in parallel with the activating cell. The ellipse . . . accompanying in 3.11 indicates that activation may not happen immediately after signal delivery. Ben and Bill might have been doing something else at the time of signal delivery instead of listening to the delivered signal. However eventually they come around to sense the signal and respond to it.

Finally the argument E.g T B.f 1 appearing in E.g mR E.g T B.f 1 in 3.11 identifies the signal delivery event that is sensed by E.g mR . It is the signal delivered back to E.g by the ports Be.f Bi.f B.f. Receipt of this signal indicates to E that the game started by E by sending a signal via E.g had terminated. The synchronous signal sensing operation E.g mR in 3.11 specifies cell E should wait at port E.g to receive this termination signal. The sensing action E.g pR at the beginning of 3.11 is not given any argument since in this case it only tests the state of port E.g for readiness to send out a signal it does not test for a delivered signal. The delivered signal was already tested by E.g mR in 3.11 . If p pR is used in a TIP to sense a delivered signal then an argument will be provided for it.

System supplies arguments to signal sensing operations in ALLEOP guards at the time parallel activations are specified. There are no parallel activations associated with E.g pR in any of the ALLEOPs 3.11 through 3.14 . Thus E.g pR in 3.11 does not have an argument. However 3.12 and 3.13 specify parallel activations for E.g mR and thus E.g mR . . . in 3.11 has an argument. Other ALLEOPs given below are similarly derived from their respective TIPs TICC network and polling cycles 

Notice in 3.12 the time map in signal sending event Be.g T Be.g 0 does not refer to the port group B Be.g Bi g however the time map in the signal delivery event Me.f T B.g 1 does refer to B. This is because Ben does not coordinate with Bill the time he sends out the signal via Be.g but agent a2 see sends a coordinated signal causing the delivery event Me.f T B.g 1 to occur. Similar timing specifications appear in events Be.f T Be.f 0 and E.g T B.f 1 .

Identical time maps appearing in distinct port ALLEOPs indicate that events associated with those time maps occur at the same time in the different ALLEOPs. Thus Me.f T B.g 1 in ALLEOPs 3.12 3.13 and 3.14 indicate that the same delivery event is being referred to in the three ALLEOPs. Similarly E.g T B.f 1 in ALLEOPs 3.11 3.12 and 3.13 refer to the same delivery event. Notice there are no ellipses . . . following parallel activations in 3.12 3.13 and 3.14 . This is because the signal receiving cells are waiting at their respective ports for the signals so they sense the delivered signals immediately.

Rules for deriving ALLEOPs from TIPs are simple. ALLEOP structures look similar to FSP structures. But as the reader can see there are several differences. ALLEOPs represent events and causal links. FSPs represent states and transitions. We will later see a possible relationship between ALLEOPs and FSPs. It should be pointed out actions specified in ALLEOPs like the actions Be.f work Bi.f play and Me.f meet may in general cause branching causal sequences to occur in the ALLEOP. There are two kinds of branchings One is choice branching where one alternative from a finite set of causal sequences is chosen to run at run time by evaluating choice conditions associated with the causal sequences and selecting the first one that evaluated to true. We use symbol to separate out the choice alternates see 5.14 . No choice branches occur in the above ALLEOPs. The other kind of branching is multiple parallel activations forks like the ones in ALLEOPs 3.11 and 3.14 that occur as a result of communications.

Partial Ordering of Time Maps Various time maps and their partial ordering in this example are 0 signal is sent to and start game

Incomparable Pairs of Time Maps 0 0 0 2 sends coordinated signal to 0 0 0 1 sends coordinated signal to 3.16 

It is possible that pairs of incomparable time maps in 3.16 intersect with each other i.e. T Be.g 0 T Bi.g 0 and T Be.f 0 T Bi.f 0 . This implies that at times both Ben and Bill could send out signals simultaneously just by chance. The combined ALLEOP is 

Here parallel operations of cells are constrained by the partial ordering in 3.15 and 3.16 . This restriction is automatically imposed by the TICC network and signal exchange timings. No scheduling is involved. Port ALLEOPs defined in statements 3.11 through 3.14 define the model of event patterns that occur in computations performed by the application. TICC Ppde can generate series parallel combinations of port ALLEOPs that are consistent with TICC network and polling specifications in order to generate the complete ALLEOPs model of an implementation. Any property we prove using the ALLEOPs models will be a valid property of the implementation not just a property of an intended design. All ALLEOPs begin with the universal temporal operator . We will omit this operator in ALLEOP descriptions. It should always be assumed to be present.

Let us now write the ALLEOP for the CIP in 3.2 Here we have postulated a port called User.g which sends interrupt signals to E.i. User is not shown in .

Notice time maps T E.g 2 and T E.g 3 are used in 3.18 . This is because T E.g 0 and T E.g 1 have been already used in E.g ALLEOP see 3.11 and E.g ALLEOP appears in E CIP ALLEOP body in 3.18 . Here E initialize E.initialize similarly E stopPolling E.stopPolling. Every Boolean attribute of an object has a predicate of this kind. In 3.18 ports of cell E are not sorted before their TIP bodies are executed.

In CIPs of the kind shown in 2.1 ports are sorted before their TIP bodies are executed. The CIP ALLEOP for 2.1 is shown below In 3.19 . Following assumptions have been made in 3.19 port X.g sends the interrupt signal that activates the Cell in 3.19 and poll SortPorts method appearing in 2.1 has been split into two components polling and sorting Cell.ports j mR does the polling Cell sortInto . . . does the sorting The latter has three arguments i Cell.ports j is the jth sorted port attached to Cell ii Cell.spL is Cell.sortedPortsList which is a vector of sorted ports with pending messages and iii sortR is the sorting relation. All are defined in the Cell class.

Differences between traces and ALLEOPs are the following i Traces postulate virtual time points hereafter simply referred to as time points at which events and evaluations begin and or end. ii Traces associate precondition and postcondition with actions when they are known. Characterization of an action A has the form

where A is either a pthread a protocol or a program statement A is the maximum time it might take to complete execution of A is the action evaluation symbol A begins execution at the same time twhen the precondition becomes true and execution of A is completed at time twhen A.output C postcondition becomes true. Such action characterizations are developed interactively by users with assistance from the system. iii Traces also specify characterizations of input messages if any in the precondition. A.output C may characterize the output message if any. Traces may contain branches specifying alternates and parallel forks if their corresponding ALLEOPs contain them. We omit the symbol in trace statements it is assumed to be present.

When system derives the trace for a port ALLEOP it simply postulates distinct virtual time points for distinct events in port ALLEOPs taking care identical virtual time points are associated with identical time maps in the port ALLEOPs. This captures synchronization and coordination of events occurring in different port ALLEOPs. Ordering of time points with in a trace is dictated by the order in which events occur in the port ALLEOP. Three assumptions are made in this ordering i Successive actions linked by will occur immediately one after the other the action at the end of the link starting at the same time as the action at the beginning of the link terminates. ii Every action takes a finite amount of non zero time to complete execution with a known upper bound iii If a cell is waiting for a signal at a port at the time signal is delivered to that port then the delivered signal is sensed immediately at the same time as the signal delivery time otherwise signal sensing may occur sometime after signal delivery. iv When a cell sends out a signal through a port C.p at virtual time say Cp.t if C.p belonged to a port group pG then the system knows that the agent that receives signals sent by the ports in pG would dispatch a coordinated signal only after receiving signals from all the ports in pG. Let us say this dispatch occurs at time pG.t. In this case the system introduces the ordering Cp.t pG.t into the port trace for every port C.p in pG.

Traces for the port ALLEOPs in 3.11 through 3.14 are presented below together with their interpretations. Traces for the Ben Bill solution contain parallel forks. Trace 3.21 below corresponds to ALLEOP 3.11 . The expression . . . . . . . . . in 3.11 describes the parallel forks. There are no actions appearing in this trace. Actions play work and meet appear in traces 3.22 through 3.24 . These actions do not have pre post conditions defined for them. Therefore none appear in traces. An example of a trace with pre post conditions and message conditions appears in 3.26 .

In each trace the trace body is invoked for analysis during a proof construction process only if the trace guard is to true else it is skipped. The trace E.g trace Eg.t at port E.g corresponding to ALLEOP E.g ALLEOP in 3.11 is shown below 

Expression on the right side in E.g trace guard Eg.t in 3.21 asserts that evaluation of the condition E.g pR E readyToStart begins at time Eg.tand terminates at time Eg.t. Assignment of the same virtual time point Eg.t to the two events Be.f and Bi.f in 3.21 indicates that signal deliveries to ports Be.f and Bi.f were made simultaneously at the same time. Specification E.g Eg.t T E.g 0 in E.g trace body without angle brackets around E.g asserts that evaluation of action that caused event E.gto occur started at time Eg.t T E.g 0 . Notice the starting time of E.g is the same as the ending time of E.g pR E readyToStart Eg t Eg.t . Ending time of E.g is not specified. Interpretations of timings associated with other statements in 3.21 are the same as in ALLEOPs with the difference that virtual time points are postulated in each case. Just as time maps represent sequences of time points each virtual time point also represents a sequence of time points. Thus in 3.21 Eg.t T E.g 0 is a sequence of time points at which E started the Bill Ben game. Other port traces associated with the ALLEOPs in the Bill Ben game are shown below.

Reader should be able to follow how time points that are identical to each other in different port traces are identified through their membership in time maps. Equalities between virtual time points so identified are introduced into the existential declarations on top of each trace. All time points that occur in traces of ports in different cells that are not related to each other by equality or inequality relations are incomparable time points.

Once all traces have been generated the system knows the virtual time points that appear in the time maps specified in ALLEOPs and all virtual time points that do not appear in any time maps. The system then sets time points appearing in identical time maps in different port traces equal to each other. This identifies all coordinated and synchronized signal dispatches and deliveries. In the case of the trace in 3.21 the existential declaration of time points at the top of the trace thus declares Eg.t Bf.twhere Eg.tis the virtual time at which port E.g receives the signal delivered to it and Bf.tis the time point at which agent a1 delivered that signal see . The delivered signal is here sensed immediately since E.g is waiting for the signal. This identifies coordinated signal delivery to port E.g specified by the time map T B f 1 in the ALLEOPs 3.11 3.12 and 3.13 . Similarly in 3.22 and 3.23 Bef.t Eg.t Bif.t. This specifies synchronized signal deliveries to ports Be.f Bi.f B.f. These identifications of virtual time points are consistent with the partial ordering shown in 3.15 . After setting up the relationships among virtual time points the system assigns the delivery event arguments to all signal sensing operations in the traces in a manner that is consistent with traces that are activated by those events. Translating ALLEOPs to traces is not complicated if message characterizations and pre post conditions associated with actions are known user assistance may be needed to acquire these.

Port traces in this application use only signal sensing conditions. In section 7.4 and Appendix III traces contain a variety of conditions and branching actions with pre post conditions associated with actions. Each trace gives rise to its Event Characterization Table ECT which is simply a reorganization of information in the trace in a tabular form that is convenient for proof generation. We will see examples in Section 7.

Trace fragments of the CIP ALLEOP 3.19 are presented below in 3.26 to illustrate how statements with V enumerators are handled. The phrase p i q i appearing in 3.26 asserts that there is a pathway between the ports p i and q i . Indices or items are enumerated by V enumerators in an order. In the following it is assumed enumeration of an index i is followed by the enumeration of the index i 1 for 0 i

Features to be noticed in 3.26 are the following i signal is delivered to port p k at time q k .tand the delivered signal is sensed at time cp k .t. The sorting action Cell sortInto . . . for index k starts immediately at the same time Cp k .t. This sorting action for index k terminates at Cp k .t when sorting action for the index k 1 begins. This is declared in the timing specifications on top where the declaration Cp k .t Cp k 1 .t appears. A similar timing structure appears for the other enumerator statement. ii Pre post conditions are presented for the Cell sortInto p k spL sortR Cp k .t Cp k .t action. Generating traces for the CIP ALLEOP 3.19 using the above trace fragments should be quite straight forward.

Graphical representation of ALLEOPs for this application is shown in . It represents the series parallel composition of the port ALLEOPs described in 3.11 through 3.14 . Nodes that appear in the ALLEOP graph in are called event classes since many instances of each node may occur when the application runs iteratively. Directed links between pairs of event classes represent causal relationship between the event classes. Labels on the links in mark conditions which should hold true for those links to occur. Only signal sensing conditions appear here.

The causalnet produced by the SMS in a single run of the game for the ALLEOPs graph in is shown in . Each node in is an instance of its corresponding ALLEOP node. Where as ALLEOPs show action events for play work and meet causalnets show only the communication events which are instances of communication event classes that appear in ALLEOPs and traces. Instead of the virtual time points postulated in traces the time instances associated with causalnet events are the time points in a global clock associated with the application. It is the time at which the events occurred in a run of that application. shows the causalnet when the game is repeated several times. The causalnet preserves the temporal ordering shown in with the difference that the looping link in is replaced by iterations as shown in . It should be clear just like time maps virtual time points in traces also have sequences of time instances associated with them.

The set of event nodes that appear in a causalnet is simply the set of all communication events that occur in a run of an application and appear in the traces of the application together with their respective times of occurrence. If traces contained choice points then not all events that appear in traces will have corresponding events in the causalnet only the events selected at choice points will have corresponding events in the causalnet. All pre post conditions sensing of events and action events that appear in traces do not appear in causalnets. Thus causalnets are abstractions of trace fragments that correspond to communication events that occur in a run of an application. Nodes that receive synchronous input signals have identical global time instances associated with them. Similarly nodes that dispatch coordinated output signals through agents also have identical global dispatch time instances associated with them. Each distinct virtual time point associated with an event class in a trace corresponds to a distinct sequence of time instances associated with the instances of that event class in the causalnet generated from that trace. Thus the virtual time point Eg.tappearing in the phrase E.g Eg.t T E.g 0 in 3.21 represents the sequence of time points T E.g 0 t t t . . . t shown in .

If the causal link x Y or x Y occurs in a port ALLEOP and event instance x t of x occurs in the causalnet then event instance Y t of Y is bound to occur in the causalnet after a certain delay X Y 0 as per definition 6.27 a in Section 6.4. If the causal link X Y or X Y occurs in the graph of a port ALLEOP with condition C X Y associated with causal link or the phrases C X Y X Y or C X Y X Y in the textual description of the port ALLEOP then event instance Y t of Y is bound to occur in the causalnet after a certain delay X Y 0 only if the condition C X Y is true at time t . This is guaranteed because as explained in Section 6.5 i any pthread or protocol that is executed by a cell is uninterruptible ii activation of the pthread and protocol is automatic not scheduled by any program that is external to the cell and iii progress is guaranteed unless of course there is a system failure deadlock or livelock part of the system is deadlocked . In the general case one has to prove freedom from deadlocks and livelocks.

Nodes are linked to each other in causalnet by directed links as shown in . The links specify partial ordering of the nodes. There are two kinds of links i causal links which specify ordering of events that occur during the execution of a TIP and ii execution links which specify ordering of different TIP executions as they occur in cells during a run of the application. Partial ordering of event instances in a causalnet is the union of causal links and execution links. In the links between successive iterations of the game are execution links. All other links are causal links. In this case each cell has only one TIP since we have ignored interruptPort activities. More execution links will appear in a causalnet if cells have multiple generalPorts and functionPorts.

The Self Monitoring System SMS may be set up to issue alerts any time the causalnet of an application deviates from ALLEOPs. Also one may specify alert situations by defining event patterns as regular expressions of ALLEOP nodes. Thus if event Y does not occur after a specified upper bound X Y in X Y and X Y then SMS will issue an error alert. If the event Y occurs after the specified upper bound for the delay then SMS will issue an impending error alert. Under normal operating conditions every event in the ALLEOP in is bound to occur if its pre conditions are satisfied once the event corresponding to the bottom node occurs else an alert will be generated. Thus in this case progress is guaranteed.

As discussed in Section 8 events in a causalnet are dynamically installed by specialized cells called Event Builder cells eb cells in parallel with an application s operations while the application is running and events are occurring in the application. Event patterns that appear in a growing causalnet are recognized by Event Analyzer cells ea cells . If a pattern in an a priori specified alert condition occurs in a growing causalnet then the ea cell associated with that pattern will generate an alert. SMS may be set up to notice any departure from progress specified in ALLEOPs and issue alerts. SMS may also be set up to influence ongoing computations in an application based on patterns recognized dynamically in a growing causalnet by setting up pathways between selected generalPorts of ea cells and interruptPorts of appropriate cells in an application and defining TIPs for those ports.

Non Determinism in TIP executions TIP executions in distinct cells are not synchronized with each other. Neither are they synchronized with signal delivery events. A TIP at a port is executed only if there is a delivery signal at that port at the time the parent cell of the port polls that port else the port is skipped. One cannot predict the order in which signals arrive at different ports of a cell. Thus the order in which a cell executes TIPs at its ports cannot be predicted. Therefore one cannot predict when a cell will sense a signal delivered to one of its ports and respond to it. Since a signal missed at a port in one polling cycle is always caught in the next polling cycle one can set a bound on when a cell may respond to a signal after the signal has been delivered to a port If is the maximum time needed in a polling cycle of cell C to service all ports with pending messages then this bound is 

Sharing CPUs The network shown in requires at least three CPUs to run it. The environment E may suspend its operations and release its CPU after sending signals to Bill and Ben. When Meeting receives signal from Bill and Ben it may get activated automatically in an available free CPU and later when E receives signal from Bill and Ben it may similarly resume suspended operations in any available free CPU. In general the number of CPUs needed to run a network is at least one plus the maximum number of cells that run in parallel. The CPUs are switched around the cells that run intermittently if cells have been programmed to suspend resume their operations. It is not however desirable to switch CPUs dynamically in TICC Ppde since CPU assignment to cells and activation of assigned CPU are relatively expensive operations taking anywhere from 2.5 to 5 microseconds. This is done in TICC Ppde only when dynamically growing TICC networks are encountered Section 7.7 .

Progress In the diagrams in there is an implicit assumption that the pthreads play work and meet are unconditional and are assumed to always terminate. With this assumption the application does not have deadlocks or livelocks and meeting synchronization occurs in all iterations of the game. We introduce formal proof methods in Section 7. We will see situations in the Dining Philosophers example where precautions are taken to guarantee that the implementation is free of deadlocks and livelocks and the refinement structure of computations plays a role in being able to prove this guarantee.

ALLEOPs and FSPs As mentioned earlier nodes in ALLEOPs and traces of TIPs are event classes and links specify partial ordering if loops in ALLEOPs are removed. It may be noticed if the looping link is removed in then the ALLEOPs graph is a lattice. This is a special case. As mentioned earlier nodes and links in ALLEOPs graphs do not represent states and transitions. However if the number of states in the state diagram of an application that is modeled by ALLEOPs is finite then the ALLEOPs should be in some sense equivalent to an FSP. We refer to such ALLEOPs as finite ALLEOPs. The set of all possible causal chains in a finite ALLEOP should then be a regular set.

FSPs Viewed as Abstractions of Finite ALLEOPs Suppose in the ALLEOPs 3.11 through 3.14 we focused only on the cells and actions like play work and meet performed in the cells and ignored signal exchange events and signal sensing operations. Then the ALLEOPs 3.11 through 3.14 yield the following FSP description of the implementation 

Here E stops after an interrupt. This is not shown in the ALLEOPs but specified in CIPs. We have here taken the liberty to include it here. As per FSP conventions FSP synchronization occurs on meet and E. This is called coordination in TICC . FSP does not distinguish between synchronization and coordination and FSP does not have a simple framework to specify temporal synchronization of distinct actions i.e. actions with different names unless actions are renamed based on their synchronization characteristics.

When cells contain multiple functionPorts generalPorts and interruptPorts actions are conditional and messages are exchanged then TIPs get complicated as discussed in Section 5. FSP descriptions that correspond to ALLEOPs will also get complicated. Nevertheless it seems ALLEOPs of any application with a fixed finite number of ports may be abstracted to obtain its equivalent FSP specification. Thus it seems ALLEOPs of every application with a fixed finite number of ports is a finite ALLEOP.

Reverse translations of FSPs to their corresponding finite ALLEOPs and implementations will be hard since i FSP does not distinguish between synchronization and coordination ii identify states of communication links or iii introduce the concept of transactions. For example the FSP in 3.27 does not specify that after meet E is informed about the end of the game by synchronized and coordinated communications via Ben and Bill. There are hidden states here states of ports and agents which do not appear in FSP. This happens because FSP has no concept of ports agents transactions pathways and protocols. We have not investigated adequately ALLEOP abstractions to FSP and FSP refinements to ALLEOP to comment further on these. The relationship between ALLEOPs and FSPs suggested by this discussion is significant and should be pursued further.

All proofs that depend only on the structure of a finite ALLEOP will have the simplicity of FSP proofs. User defines CTL assertions to be proven and may also provide assertions to guide proof search. System verifies that every assertion provided by user is valid for the given implementation before accepting it.

NFSP Proofs ALLEOP proofs that depend on values of variables used in computations may require NFSP Non FSP proof methods. Such NFSP proofs may require induction over the structure of the ALLEOP. We will see simple examples of both FSP and NFSP proofs in Section 7. For an application in which the network grows dynamically during computations its ALLEOP may be an NFSP ALLEOP containing context dependent and general recursive structures with potentially infinite number of ALLEOP nodes. An example is presented in Section 7.7.

The next example is an augmented version of the Talking and Itching example described in Magee Kramer 13 . Here it is intended to illustrate use of non deterministic guard concurrency encapsulation hiding and coordination.

A person talks and itches simultaneously. In 13 there is only one person and the person talks and itches with time sliced concurrency. We consider a generalized version of that example with two persons where conversation takes place between them and each person scratches intermittently while he she is talking. The scheme could be generalized to more than two people. An orderly conversation is maintained with no more than one person talking at any one time. This example uses a Das pathway with a virtualMemory which was introduced in .

The network is shown in . P0 and P1 are the two Persons. They are compound also referred to as composite cells because they encapsulate a network inside them. Each person Pj for j 0 1 is a composite cell containing of one Converse cell Cj and one Itch cell Ij. These two cells run in parallel in distinct CPUs in each person. Each composite cell has hidden internal connections and some have connections to external ports. Decomposition of a composite cell to define the network it encapsulates is called refinement. Let us first review the connections that are internal and external to the two encapsulated cells and the network activities they support.

External Connections For j 0 1 there is a pathway Cj.f0 Pj.f0 a1 a0 E.g1 see . Here ports P0.f0 P1.f0 form a port group agent a1 delivers synchronized signals to P0.f0 P1.f0 and delivers back to E.g1 coordinated signals from P0.f0 P1.f0 via agent a0. Similarly E.g0 is connected through an agent to the external interruptPorts in the port group P0.i P1.i which in turn are connected to the internal interruptPorts C0.i C1.i respectively. E uses this pathway to activate cells Cj for j 0 1. There is a pathway Cj.f2 Pj.f2 Pk g2 Ck g2 for i k 0 1 and 1 k which allows communications between Cj.f2 and Ck g2. Similarly pathway Cj.f3 Pj.f3 Pk g3 Ck.g3 enables communicates between Cj.f3 and Ck.g3.

Internal Connections Pj.g has an internal connection to the interruptPort Ij.i. When Pj is activated it uses this connection to activate Ij. Other two internal connections are Pj.g0Ij.f0 and Pj.g1Ij.f1. Cj and Ij use these two connections to coordinate their activities.

Hiding Only ports and agents linked to the external ports of the encapsulated cell may be accessed from the outside world. Pathways internal to an encapsulation are hidden from the outside world we refer to this as hiding.

Network Activities The environment E activates the Converse cells Cj for j 0 1 by broadcasting an interrupt signal to ports in the port group P0.i P1.i . Once activated the cells initialize acknowledge receipt of interrupt signals and then begin to poll their ports. During initialization each cell Cj for j 0 1 activates the Itch cell Ij by sending an interrupt signal to Ij.i through Cj.g see . This causes both the Itch cells Ij for j 0 1 to begin polling after performing their own respective initializations. After activating the Converse cells E broadcasts a randomly chosen 2 bit signal b b to ports in the port group P0.f0 P1.f0 . Restriction on these bits is that they cannot both be 0 s or both be 1 s. The agent a1 see sends delivery signal to P0.f0 P1.f0 only if bit b 1 b 1 else it does not.

When a person receives a signal at port Pj.f0 the signal goes to Cj.f0 through the internal connection. When Cj senses this signal it begins to talk. Since band bcannot both be 1 the two persons cannot both begin to talk simultaneously. While one person is talking the cells in the other person will be polling their ports and just spinning and presumably listening to the talk. Before beginning to talk Cj sends a signal to Ij.f0 through Cj.g0 see . When Ij senses this signal it begins to scratch intermittently and continues to scratch intermittently while Cj is talking. Intermittent scratching is controlled by the Boolean variables Ij.itching and Ij.continue. Scratching occurs only when both true. The truth values of Ij.itching and Ij.continue are set in each scratching cycle by a random truth value generator Ij random . Thus a person may not scratch throughout a talking session. There is an assumption here that scratching intervals will always be much shorter than the talking intervals. Since the Itch and Converse cells operate in parallel actions performed by them occur in parallel even though the time points at which a person begins to talk and begins to scratch are not synchronized to each other.

After talking Cj first sends a signal through the pathway Cj.g1Ij.f1. This informs Ij to stop scratching. Cj then does one of two things either i it signals Ck.f2 for k j through ports in the pathway Cj.g2 Pj.g2 Pk.f2 Ck.f2 see to advise Pk to begin talking in order to continue the conversation or ii it signals Ck.f3 through ports in the pathway Cj.g3 Pj.g3 Pk.f3 Ck.f3 to terminate the conversation. The way these mutually exclusive signals at the two functionPorts Ck.f2 and Ck.f3 are used to continue or to stop a conversation is described below.

One of the TIPs below uses a non deterministic guard of the form f f Ck.f2 Ck.f3 f mR . The symbol specifies alternates. Here each cell Ck evaluates this guard in every one of its polling cycles. The guard evaluates to true only if one of the ports among the alternates specified in the guard has a signal delivered to it. Signal deliveries to ports in the guard should be mutually exclusive in order for a non deterministic guard to operate successfully. If a signal is sensed at Ck.f2 then conversation continues if it is sensed at Ck.f3 then conversation terminates. If the conversation terminates then a signal is sent back to E.g1 via port Ck.f0 if this port is ready to send that signal. Ck.f0 will be ready to send that signal only if it had received earlier a signal from E.g1 via agent a1 see . Thus only the cell that received a signal from E responds to it. Coordination occurs here because at this point agent a1 will be expecting to receive a signal only from the port to which it had earlier delivered a signal. When a1 forwards this signal to E.g1 it will inform E that conversation has terminated. At that point E may start another conversation session or terminate the game by sending the second interrupt signal to the interruptPort Cj for j 0 1. Cj will terminate Ij by sending an interrupt signal to Ij see before terminating itself. Starting and termination processes are not shown in the TIPs below.

Cells in each person Pj for j 0 1 has the following polling cycles interruptPort pollings are not shown 

Let us suppose Cj started the conversation and sent signal to Ck to continue the conversation. After sending this signal Cj will begin polling its ports as per polling cycles above presumably at the same time listening to the other person talk listening processes are not included in this implementation one may introduce a Listen cell for listening. . Cj may go through multiple polling cycles while conversation is continuing. This will cause the delivery signal received at Cj.f0 to be repeatedly sensed since delivery signal is changed only when a response is sent and no response is sent as long as the conversation continues. Thus sensing of signal at Cj.f0 will succeed every time sensing is done. Thus while Ck is talking Cj may also begin to talk. To prevent this Cj sets Cj.f0.input immediately after sensing the delivery signal at Cj.f0. This prevents repeated sensing of the signal at Cj.f0. We use the statement Cj.f0 suspend to do this. Since suspension does not change the state of a port response may still be sent through a suspended port when it is appropriate to do so.

With this preamble and the comments given below reader should now be able to follow the TIPs described below.

Conversation begins every time a signal is received either at P0.f0 or P1.f0. Scratching begins every time conversation begins or continues intermittently. We leave it to the reader to figure out how correct coordination occurs. The network does not provide for listening. To provide for this a third Listen cell should be introduced inside the encapsulation with proper coordination with Converse cell.

TICC network TICC network together with CIPs Cell Interaction Process TIPs Thread Interaction Protocols and polling cycles controls all pthread scheduling synchronization and coordination. Cells enforce mutual exclusion of TIP executions at their respective ports communications prevent interference between message senders and message receivers during message exchanges. Ports prevent interference between any two communicating cells during message processing and message building operations since ports allow their parent cells to use virtualMemories only when their state is S and the state of message receivers is always R when the state of senders is S. Thus TICC network specifies the complete control structure for executing a collection of pthreads in parallel without mutual interference enforcing all of their synchronization coordination scheduling and fork join operations. There being just one exception to this.

This exception occurs when cells in a cell group parent cells of ports in a port group use the same virtualMemory simultaneously in parallel for executing pthreads. VirtualMemories provide special facilities to coordinate such parallel simultaneous activities through its scratchpad Section 7.2 which may be used by cells in a cell group to coordinate their activities. Cells in cell groups may use locks to protect commonly shared data in the virtualMemory from each other and communicate with each other via the scratchpad possibly using simple and efficient methods of CSP 10 . Pthreads which are thus simultaneously executed by cells in cell groups should therefore be jointly developed with some care since there may be a need to use locks and exchange data via scratchpad.

Communication latencies in TICC Ppde are only in tens to hundreds of nanoseconds scale. Grain size time spent by a cell between successive message sending sessions can therefore be small too of the order of only 10 to 25 microseconds. Thus pthreads will be short sequential programs. It should therefore be easy to implement them even if some of them may have to be jointly implemented with locks and dynamic data exchange via scratchpad. As we shall see there are only six different kinds of TIPs each kind of TIP coming in two versions either synchronous or asynchronous.

TICC Ppde provides compiled codes for all protocols likely to be used in any parallel program. Thus implementers do not have to define them. There is a standard CIP Cell Interaction Process used by all cells shown in statement 2.1 and abstract TIPs are easily defined but it may require some experience to do so. Thus after abstract specifications of parallel programs using TICC network CIPs and TIPs sequential programs for pthreads and defining needed message subclasses used by those pthreads and CIP initializations would be the only ones left for programmers to implement in order to complete the implementation. These sequential programs are easily defined. We refer to the process of defining pthreads and CIP initialization as TIP and CIP refinement. TICC Ppde separates out the system design phase of building software systems from the refinement phase. The hard part of building parallel programs for applications in TICC Ppde is not programming but it is system decomposition defining the TICC network developing logical characterizations for pthreads and validating designs and implementations.

As we shall see in Section 9 TICC Ppde simplifies the task of system decomposition by using a process called network refinement in which one begins a design with a top level compound cell say CC decomposes CC to a network of component compound cells say CCfor 1 i k for some k 1 define a network interconnecting CCthrough pathways as needed unwraps the encapsulation of CC exposing the resultant network and iteratively applies this process to every CC. In this iterative process one keeps the encapsulation for a compound cell only if that cell is used more than once in an application or a compound cell designed in one application is likely to be used in other applications.

ALLEOPs ALLEOPs integrate structural information provided by the TICC network with computations specified by TIPs. They make explicit the control structure of parallel computations synchronization and coordination that are implicit in the TICC network the TIPs and Polling Cycles and define partial ordering of time points postulated by time maps. They present the integrated information in a form that is accessible to machine processing. For a human they answer questions like the following What does a pathway do What is a TIP What are polling cycles What are communication patterns The answers to these questions may go as follows Pathway enables communication of signals between ports performs synchronization coordination of communications provides access to exchanged messages and activates parallel computations in the signal receiving cells. TIPs process create messages send receive signals and isolate methods used for message processing creation from communications. Polling cycles specify the order in which cells attend to TIP executions at their ports. Communication patterns arise because of choices made among alternate causal chains based on associated conditions and activations of parallel tasks forks through parallel signal deliveries. Event patterns thus define patterns of branchings forks and joins in control structures of parallel computations. Such patterns may be described using a regular grammar or other kinds of grammars that use ALLEOPs nodes as terminal symbols. ALLEOPs do not specify details of computations performed by cells. Each ALLEOP node represents an event class. Multiple instances of an ALLEOP node may occur in a causalnet.

Just as the same sequential program may be run with different data structure definitions the same collection of pthreads defined for an application may be run in parallel in different TICC networks for the same application. Thus one may view TICC networks as abstractions of control structures of parallel computations just as data structures are abstractions of data manipulations in a sequential program.

Traces Traces add information to ALLEOPs. They postulate virtual time points associate them with event classes and time maps that occur in ALLEOPs in a manner that is consistent with ALLEOP specifications. Thus they make explicit timings that are implicit in ALLEOPs. Traces also define the semantics of computations performed by TIPs by associating pre post conditions with actions and by characterizing exchanged messages if any. For a human they answer questions like the following What does an action compute Is an action being correctly executed What events occur synchronously What events are coordinated The answers to these questions may go as follows An action is defined by pre conditions that characterize what should hold true before its execution in order for the action to succeed and post conditions that characterize what should hold true after the execution terminates. These pre conditions and post conditions may include in them characterizations of messages processed created by the action. An action implementation is correct if it s pre condition and post condition are both satisfied at appropriate moments every time the action is executed. Events with identical virtual time points are interpreted as occurring synchronously. Message dispatching events with identical virtual time points are coordinated events.

Causalnets Causalnets are abstractions of traces that focus only on communication event occurrences in traces and their synchronization coordination characteristics ignoring all conditions and actions. They are generated by the SMS while an application is running. As explained in Section 8 Event Analyzer cells ea cells may analyze growing causalnets of applications in parallel with applications while causalnets are being created by Event Builder cells eb cells with little or no interference with timings of on going operations in applications. Analysis performed by ea cells may be based on a priori defined event patterns or event patterns that are dynamically learnt by the ea cells. It is even possible that patterns recognized by ea cells are used to direct computations performed in an application.

The partially ordered domain for an application is simply a representation of all possible causalnets that SMS may generate for all possible ways in which that application may run. It so happens this domain together with a monotonic continuous mapping from the domain to itself is sufficient to define the denotational semantics of TICC Ppde. This is consistent with calculus view Logic is not needed for computations communications with suitable hiding and substitution rules are sufficient. Logic is needed only to define and prove correctness of computations. That is why information provided by traces is needed in order to prove CTL assertions. ECTs reorganize information in traces and polling cycles and ECT networks provide series parallel combinations of port ECTs in an implementation. They are used for proving CTL assertions. We will see some examples in Section 7.

Implementations presented in Appendices I through III and proofs presented in Section 7 illustrate the perspectives outlined above. What is significant is that ALLEOPs are easily automatically derived by the system from implementation specifications. Traces are easily and automatically derived from ALLEOPs if pre post conditions for actions are made known to the system. TICC Ppde provides tools for interactive development of pre post conditions for actions. Four features of TICC Ppde make this possible i Organization of TICC network in terms of cells with attached ports pathways with agents and optionally virtualMemories ii Organization of computations in terms of TIPs polling cycles pthreads and protocols iii Integration of computation and communication each cell that performs computations also performs all of its communications using protocols that use CCPs and iv Mutual isolation of cells discussed in Section 4.2 .

Attachments and tunings have a special significance in TICC . Only attached or tuned components may freely share each others data and methods. Thus attached and mutually tuned ports cells agents and virtualMemories may freely share each others methods and data.

Attachments Only components connected to each other by branches or h branches hidden branches or components attached to each other may send signals to each other in the pathway. In ports are attached to their parent cells connected to agents and or other ports by branches and agents are connected to each other by h branches they are h branches because agent interconnections cannot be dynamically changed when pathways are dynamically modified . Thus agents and ports and pairs of agents in a pathway may exchange signals and cells may send signals to their ports. As mentioned earlier pathways allow signal transfers only in one direction at any given time and components that exchange signals are always tuned to each other.

Tuning Connecting a port p to an agent a through a branch b tunes p to a by setting i the initial states of p and a which enables them to exchange signals between each other and ii transfers to p addresses of data and methods in virtualMemory a.vM attached to a which is the same as the virtualMemory p.vM tuned to p. This enables the parent cell of p to access data and pthreads in p.vM when the state of p is S. Tuning p to a also tunes its parent cell to p.vM a.vM. Since a cell may have several ports the cell may have several virtualMemories tuned to it distinct ones for distinct ports of the cell. Two agents are tuned to each other by connecting them with an h branch which sets their initial states. Application programmers do not have to rite any code to tune components on a pathway to each other.

Transaction Completion As mentioned earlier cyclic polling of ports in every cell guarantees that every service request sent to a port of a cell is sensed and responded to. No cell may be interrupted while it is responding to a service request. Cell senses and responds to interrupts only between successive TIP executions. These features together with cell isolation described in the next subsection guarantee transaction completion for every transaction and guaranteed transaction completions maintain tunings between pathway components.

Cells perform computations by polling their ports and executing TIP bodies defined at the ports. Since cells operate in parallel in distinct computing units they provide a parallel pthread execution mechanism and do not use time sliced interrupt driven pthread executions. Pthreads and protocols are uniquely associated with cells and their ports. Each port of a cell may have pthreads and will have a unique protocol associated with it. Cell isolation is defined by the following two properties.

Private Local Pthreads While executing a pthread a cell may only use data and methods defined in the cell or components attached to or tuned to the cell. No other data or method may be used during TIP executions. In particular operating system cannot interfere with TIP executions. Operating system is not used in TICC Ppde to either schedule or activate pthreads or to synchronize or coordinate their executions or to recognize and process interrupts. A pthread associated with a cell may not be executed by any other cell even though copies of the same pthread may be executed in parallel by different cells each in its own private memory or associated virtualMemory. A pthread execution can only change the state of the cell that executes it. These characteristics of cells are similar to those of Actors and calculus Agents.

Parent cells of ports in a port group see may simultaneously execute the same pthread in the same shared virtualMemory of ports in the port group. During such executions they may use common shared variables. We will see in Section 7.2 how pthreads are organized to block memory interference during such executions.

Using dedicated virtualMemories to execute pthreads and methods is unique to TICC Ppde. This is exploited in Section 10.2 to propose a new shared memory organization for multi core chips.

Private Local Protocols Distinct ports have distinct protocols defined for them. A protocol defined at a port of a cell may not be executed by any cell other than the parent cell of the port. While executing a protocol at its port a cell executes CCPs and other action statements in the protocol over the pathway connected to that port Section 8 . Protocol execution does not cause the cell to execute any other thread or process not defined in the protocol itself. Nor does it use data not already defined in the components of the pathway. Protocols do not use declarations. Distinct cells may execute in parallel only distinct protocols. As mentioned earlier segments of protocols defined at the ports of a port group are executed in parallel by parent cells of the ports over the same group to group pathway as described in Section 8.

Protocols are methods defined at port instances not port subclasses. In our prototype C implementation this forced us to execute protocols interpretively chasing through the components of a pathway. This contributed to considerable inefficiency due to repeated cache replenishments that occurred during protocol executions. Thus even though it takes only 25 to 50 nanoseconds to execute a CCP in a 2 giga Hertz machine it took 350 to 500 nanoseconds to execute a protocol with four CCPs. This may be avoided by providing an Eval operator as defined in Section 10.2 which may be used to evaluate compiled protocols associated with a port and eliminating use of cache memories.

No Sequential Buffers Ever Needed No generalPort C.g could send a second service request message to a functionPort D.f as in for example before C.g has received the response to the first service request sent by C.g. This holds true for all generalPorts and functionPorts in a TICC network. Therefore no virtualMemory will ever hold more than one pending service request message at any time. Every pending service request message is preserved in its virtualMemory until the request has been sensed and responded to.

Similarly every reply message is preserved in its virtualMemory until it is sensed and used by the message receiving cell. No virtualMemory will ever hold more than one reply message at any time. Each virtualMemory may hold at most one service request and one reply at any given time. Distinct ports connected to distinct pathways will have distinct virtualMemories associated with them. Thus virtualMemories in a TICC network provide a parallel buffering mechanism for service requests and replies. This eliminates the need for sequential buffers. Unlike Actor systems there are no buffer contentions to resolve and serializers are not needed.

Parallel Message Transfers We have already mentioned some of these. We will mention them again i Each cell itself executes protocols needed for message exchanges in parallel with other cells. ii No two distinct pathways share components in common. iii Each port is connected to only one pathway. iv It is never possible that both message sending and message receiving cells connected to a pathway simultaneously execute protocols associated with that pathway. v Finally no protocol executes any thread or process not defined in the components of a pathway. Therefore distinct protocols may be executed in parallel by distinct cells without mutual interference whether they are over point to point or group to group pathways. Thus the number of messages that may be simultaneously exchanged in parallel among cells in a TICC network is limited only by the number of active cells and number of distinct pathways in the network. CCPs keep pathway components isolated from cells and from each other.

Mobility A sm pathway connected to a port may be dynamically changed in order to introduce mobility as long as the following pathway requirements are not violated i No port may be connected to more than one pathway ii no two ports of the same cell may be connected to the same pathway unless the ports are in a port vector Section 5.2 and Section 8 and iii no two distinct pathways may share components. The message destination functionPorts of a sm pathway may be disconnected from the sm pathway and routed to different destination functionPorts in the middle of a transaction. Parent cells of the new destination ports may then process the service request message in the virtualMemory of the sm pathway write a reply message in that virtualMemory and reconnect the sm pathway back to its original destination ports whose parent cells may then modify the reply if necessary and send it to the generalPorts that requested the service. Thus reply is always sent back through the same pathway that delivered the service request. GeneralPorts connected to a pathway cannot be changed dynamically in the middle of a transaction but may be changed before a transaction begins. Neither generalPorts nor functionPorts connected to a dm pathway may be dynamically changed in the middle of a transaction.

By transferring the entire contents of a virtualMemory M tuned to a port C.p of cell C to a different virtualMemory M tuned to another port C .p of another cell C one may transfer to port C .p the functions performed at port C.p. This feature is useful in computations distributed over several SMPs interconnected by TICCNET in which contents of virtualMemories are transferred through dm pathways.

TICC and Actors In Actor systems communication protocols invoke OS methods and other processes that are external to Actors. Asynchronous communications require the use of sequential buffers. Serializers are needed to resolve buffer contentions. One cannot predict when a message sent by one Actor will arrive at a recipient Actor. Communications are not order preserving messages may not arrive at destinations in the same order they were sent. Also message transfer latencies are several orders of magnitude higher than in TICC 

In TICC unlike Actor systems communication is connection oriented. Communication may occur between two cells only if a pathway between the two had been already established. Cells execute protocols by themselves in order to exchange messages. Message sending and delivery times are in the hundreds of nanoseconds range which may be precisely predicted with in given bounds. The only distinction between protocol executions and pthread executions in TICC is that protocols do not contain declarations but contain CCPs. Protocols thus define a restricted form of computation performed by cells.

Besides transferring messages protocols also transfer access rights to delivered messages and methods used to process delivered messages enforce a priori defined security restrictions on message deliveries and drive the SMS Section 8 . All of these take place with no operating system involvement. Communications are integrated with computations performed by cells hence the name TICC Technology for Integrated Computation and Communication . Also unlike Actor systems TICC supports group to group communications automatic synchronization and coordination and dynamic SMS Self Monitoring System . TICC eliminates the need for sequential buffers in asynchronous communications by using a parallel buffering mechanism. It is not possible to define an SMS in Actor systems like the one in TICC Ppde. TICC provides unique synchronization and coordination features not provided by Actor systems. Support for transactions is not intrinsic to Actor systems.

TICC and calculus Both in calculus and in TICC Ppde parallel computations are specified as interactions among parallel computing units. Also as in TICC communication in calculus is connection oriented. Names are exchanged between calculus Agents through already established links and just as pathways links may be dynamically established. These are the only common features between calculus and TICC Ppde. Nothing else in the operation of TICC Ppde is similar to operations in calculus. Dynamic changes to pathway connections in TICC and dynamic changes to link connections in calculus seem to achieve different computational objectives since changes made to a pathway in the middle of a transaction have to be reset to their original configuration before the transaction is completed. There is no concept of transactions in calculus.

The most important difference between TICC and calculus is the following pathway protocols define communication as a Turing computation Turing 20 performed by interacting ndFSMs and executed by the same cells that process build and send out messages. calculus does not specify a computational mechanism for communications. Indeed it is impossible to specify the needed computational mechanisms using the calculus formalism. In this sense calculus does not specify all of parallel computations. It specifies parallel computations only if communication is assumed as a given primitive.

TICC and CSP We have already mentioned the differences. We will state them again. Pthreads in TICC Ppde correspond to Communicating Sequential Processes Csps in CSP. Unlike Csps pthreads do not contain communication primitives. Only TIPs contain communication primitives. TIPs isolate communications from interacting pthreads. Also unlike CSP where channels block interacting Csps pathways do not block interacting pthreads. In addition unlike CSP channels pathways support both point to point and group to group asynchronous communications with automatic synchronization coordination and data security enforcement. Concept of transaction is not built into CSP. Finally it is not possible to define SMS Section 8 in CSP.

Pair wise Independence of Pthreads No method defined in one cell subclass may ever invoke and execute another pthread defined in another subclass unless the subclass instances are attached to or tuned to the cell. Two cells running in parallel may however execute copies of the same method each in its own distinct execution environment. No method pthread executed by one cell may change the state of another cell. Pairs of pthreads executed by different cells remain mutually independent of each other except when pthreads are simultaneously executed in the same virtualMemory by different cells in a cell group. Such pthreads coordinate their parallel activities using the scratchpad memory provided by the virtualMemory Section 7.2 they have to be jointly developed and verified. All other pthreads may be independently and separately verified majority of pthreads in a system are likely to be mutually independent.

It is common that a cell C with a service request at one of its functionPorts C.f could not by itself compute the response to a received service request. In this case C may have to spawn new computations in one or more other cells in order to compute the response. TIP with the following format is used for this purpose 

where is the empty symbol. This prevents C from sensing the delivery signal at port C.f in its ensuing polling cycles. We saw this used in a different context in the Talking Itching example in Section 3.2. In 5.1 the pthread C.f r C.g C.f msg r C.f C.g is defined in the subclass of message in the virtualMemory C.f.vM tuned to port C.f. C.f spwn C.f.spwn where C.f.spwn is a local Boolean variable associated with C.f. The truth value of C.f.spwn is set in C.f r C.g .

TIP 5.1 does one of two things After executing the pthread C.f r C.g the TIP sends out message either via port C.g or via port C.f depending upon the value of C.f spwn . The pthread C.f r C.g either writes a response message in C.f.vM and sets the Boolean variable C.f.spwn false or writes a new service request message in C.g.vM and sets C.f.spwn true. In latter case C spawns a new computation in the cell that receives the service request sent via C.g and suspends its activities at port C.f. Suspending C.f resets the delivery signal at C.f.input . Thus polling will fail at C.f in ensuing polling cycles. After suspending C.f C immediately proceeds to service its next port. Data and execution states in C.f.vM are preserved. C continues its activities at ports C.g and C.f only when it later senses a reply message at port C.g.

Notice in 5.2 suspension at C.f does not change C f.state. Thus when a response is received at C.g and computations are resumed C.f will be ready to send back a response.

Conditional statement with else clause in 5.1 C.f spwn C.g s C.f suspend else C.f s is interpreted as follows 

where selectOne scans its conditions top to bottom and selects the one that evaluates to true. The last clause in selectOne is an unconditional escape clause. Thus if C.f.spwn then no message is sent out. This case will occur when the cell does not satisfy conditions required for sending a message. In this case the pthread that set C.f.spwn will reset C.f.input s if computations are to be resumed using the message received at port C.f or C.g.input s if computations are to be resumed using the message received at port C.g. This will enable C to sense message at C.f or C.g in an ensuing polling cycle and send message via C.f or C.g after the cell satisfies required conditions see Section 5.1.1 .

When a message receipt is sensed at port C.g in an ensuing polling cycle C executes a TIP with a similar body as the TIP in 5.1 with the difference it now executes C.g r C.f instead of C.f r C.g using the message received at C.g and the TIP repeats the same pattern of message transmission.

Spawning may thus be repeated as many times as needed before a response is sent back via port C.f and the transaction is completed. Completion of transaction is mandatory in every such computation. Here C.g r C.f C.f msg r C.f C.g is defined in the subclass of message received at port C.g.

For each functionPort C.f the generalPort C.g through which it may spawn new computations is unique. No other functionPort of C may use C.g. This is intended to prevent possible deadlocks which may otherwise occur. One may also note any time C sends out a service request via C.g the port C.g will be ready to send that message.

The cell to which C.g sends its service request may itself similarly spawn new computations. Also C.g may broadcast its service request to a functionPort group. This may cause computations to spread over the network. Every cell to which service request is so sent is mandated to respond to it and will always do so. Eventually all spawned transactions terminate and the response message is received by C.g. This response message at C.g will then be used by C to respond to the service request it received at C.f or may be to spawn again .

We illustrate below occurrence of alternates in ALLEOP and trace due to branchings caused by choice points. We choose spawning computations specified by TIPs 5.1 and 5.3 as examples. Let us assume that port C.f in TIP 5.1 receives its message from port B.g at a time point in T B.g 1 and port C.g in TIP 5.1 communicates with the port D.f. ALLEOP for TIP 5.1 will then have the form 

In 5.4 the ALLEOP specifies alternates enclosed between parenthesis . . . . . . . . . separated by . The pthread C.f r C.g in 5.1 will also have alternates specified by choice points corresponding to the alternates in 5.4 as shown in 5.5 below 

Notice when C.f.spwn is set in 5.5 C.f.input is reset to s so that C may sense again the message received at port C.f in its next polling cycle. In 5.5 when message is sensed again the entire C.f tip in 5.1 will be executed all over again. It is possible to resume execution of C.f tip from a specified address in the compiled code of C.f tip . This is done by replacing C.f.input s in 5.5 by C.f suspendTip resume which sets C.f.input s and sets the address of instruction in the compiled code of C.f tip at which C.f tip should resume operations to resume details in Section 10.2 . The form of pthread C.g r C.f C.g msg r C.f C.g is shown below The only difference is in the roles played by C.f and C.g 

Forks and joins occur when port vectors are used. A port vector C. C.p C.p . . . C.p is a vector of ports of the same kind attached to the same cell c either all functionPorts or all generalPorts or all interruptPorts. In the TIP associated with this port vector the parent cell of the ports in the vector will use a guard having the form C. mR or C. pR to check for messages or to check port readiness where guard guard guard . . . guard or 5.8 In the asynchronous case and in the synchronous case guard guard guard . . . guard . 5.9 Thus the cell begins to respond to signals at its port vector only when the guard evaluates to true at all ports in the port vector. If guard is not true for all the ports in the port vector then the port vector is skipped and the parent cell begins to poll its next port in the asynchronous case or in the synchronous case the parent cell repeatedly evaluates the guards until they become true.

In Tables 1 and 2 when g mR or g pR test is performed at a generalPort g the input signal g.input is reset to . This resetting of input signal does not happen for the subclass of generalPorts gthat belong to a port vector . This specialization enables g mR tests to be repeated in successive polling cycles before the test succeeds for all the ports in in one of the ensuing polling cycles TIPs here have one of the forms 

Cell C may use messages from only a subset of C. depending on computations defined in C r or C r . Similarly it may send out messages that spawn computations only through a subset of the ports in . In this case C will remember the generalPorts through which messages are sent out so that it can later listen for responses only at those ports. C always responds to every functionPort and interruptPort in . It may be noticed all the ports in C. are always ready to send out messages whenever C sends them out.

Disjunctions are not allowed in guard expressions except in the context of non deterministic existential guards described in Section 5.4 below. We saw an example using a non deterministic guard in Section 3.2. However a disjunctive response to received messages is possible depending upon how C r or C r uses messages received at the ports in C.. Thus it is possible that when a message is sensed at one of the ports of a port vector depending on the nature of that message message received at another port of the same vector is ignored. An important difference between specifying a guard with disjunctions and the port vector method is that in the latter case response occurs only after all ports in the port vector have received messages and are ready to send responses and anticipated computational contingencies for disjunctive use are coded into the pthread. A reply is always sent back through every functionPort and interruptPort in the port vector. An acknowledgement for message receipt would be sent even if that message was ignored. Thus transactions are always completed.

A consequence of this convention is that to introduce certain patterns of interactions among ports in a port vector of a cell like for example where message at one port inhibits message at another port it may be necessary to change an already coded pthread that is used by the cell to respond to messages received through that port vector. We opted for this option because avoiding disjunctions simplifies interaction specifications and analysis of implementations and guarantees transaction completions.

Two ports p and q in a network are said to be cycle synchronized if one of them say q services its ninput message only after the other p has completed servicing its ninput message and p services its n 1 input message after q has completed servicing its nmessage always maintaining this order of cyclic servicing of input messages. Cycle synchronization of a collection of distinct ports in a network forces activities at those ports to always occur in a prescribed order it also synchronizes servicing of successive messages in the sense that ports in the collection service their n 1 message only after all the ports have completed servicing the nmessage. We refer to imposition of a fixed order of execution as coordination.

Cycle synchronization should be contrasted with temporal synchronization where activities at a collection of ports are always forced to begin simultaneously at the same time. Whereas a collection of ports belonging to the same cell may be cycle synchronized no collection of ports belonging to the same cell may ever be temporally synchronized.

Coordination As mentioned earlier in 5.11 and 5.12 it is possible that the parent cell of a functionPort vector spawns service requests only through a subset of generalPorts in its associated generalPorts vector . However reply messages are always sent through all functionPorts in . Thus n 1 messages at ports in are serviced only after all of the nmessages have been serviced. Ports in are here cycle synchronized because responses are always sent through the ports in in an a priori fixed order even though messages at may all be serviced together. In contrast ports in are not cycle synchronized. As described in Section 5.5 dependent ports in a cell will always be cycle synchronized. Both of these examples of cycle synchronization perform coordination.

In group to group communications Section 8 ports in a generalPort group G are always cycle synchronized but ports in a functionPort group F are not. This is because it is possible that a joint service request message sent by ports in G is delivered only to a subset of functionPorts in F. The particular subset of functionPorts to which a given joint service request message was delivered may depend on the message that was sent and on security specifications examples in Sections 3.2 and 8 . Agent that broadcasts message delivery signals to functionPorts F keeps track of the functionPorts to which message is delivered and will expect responses only from those functionPorts.

Synchronous Joins and Forks In a group to group communication the dispatch and delivery of messages that cause forks and joins are respectively coordinated and synchronized by agents in the group to group pathway as described in Sections 2.3.3 and 8. Different cells in a cell group may begin responding to a synchronously delivered message at different times since the times at which response computations begin are not synchronized. However since dispatch and delivery of messages are synchronous we refer to these as synchronous loins and forks.

Asynchronous Joins and Forks Messages received by ports in a functionPort vector constitute a join operation and messages sent out through the generalPort vector constitute a fork operation. These messages may arrive depart at different times and come from go to different cells. Since dispatch and delivery of messages are here asynchronous we refer to these as asynchronous forks and loins. However note that response computations to messages received at the ports in a port vector begin synchronously after all the ports in the port vector have received messages. Here synchronization is done by the message receiving parent cell of the port vector in a manner that is similar to rendezvous.

Ad hoc Synchronization Coordination In Section 7.6 combinations of spawning port group and port vector organizations are introduced in order to perform at any stage of refinement of an implementation i cycle synchronization of events occurring at any given collection of distinct ports in a TICC network or ii temporal synchronization of events at distinct ports of distinct cells such synchronizations being done without having to change any of the refinements done up to that stage of implementation and with little or no change in the timings of other events in the implementation. We refer to these as ad hoc synchronization and coordination since they are done as an after thought.

As mentioned earlier TICC Ppde requires no monitors semaphores and no rendezvous 10 12 23 24 to be coded into programs written by application programmers in order to coordinate synchronize or schedule activities in parallel computations. We saw in Section 3 two examples of synchronization and coordination without implementers having to code use monitors semaphores and rendezvous into application programs and will see more in Section 7. Application programmers have responsibility only to specify the TICC network. It implicitly specifies all needed synchronization coordination and scheduling for all parallel programs run on that network. Thus the network makes the implemented application program self synchronizing self coordinating and self scheduling.

All synchronization and coordination methods used in TICC Ppde are unique to TICC Ppde and new to programming technology.

Here p stands for f g i . The first port with a delivery signal is chosen in a left to right scan of alternates in the guard. The cases have to be mutually exclusive if the alternates included a functionPort or an interruptPort. Otherwise message received at a functionPort or an interruptPort may not be responded to. As we mentioned earlier this is not allowed.

In the TIP 5.14 let us assume C.p C.p which is one of the alternate ports in the guard receives its input message from B.g. ALLEOP of 5.14 will then have the form with alternate causal chains of activities 

One may also have a synchronous guard C.p C.p C.p C.p . . . C.p C.p mR . In this case scanning of the guard is repeated until one port with a delivery signal is found. It is possible for this to succeed since messages are delivered to ports of a cell in parallel with cell operations. This type of synchronous guard is used in the Ornamental Garden solution OG solution in Section 7.1. Other existential guards have the form 

Function Computed at a Port Every cell has its own internal memory. It is the memory of the CPU that is assigned to that cell. The cell uses this memory to execute pthreads defined in the cell and to store its local state. For every port C.f when C executes the TIP body C.f tip the pthread it executes may compute the function 1 5.17 

where mis the nmessage received by port C.f residing in the virtualMemory C.f.vM S f n 1 is the state of C relative to its port C.f at the end of execution of the n 1 message at C.f m is the nresponse message sent via port C.f and S f n is the state of C relative to C.f after processing the nmessage. We will use Pto denote the set of predicates defined on port p and Pto denote the set of predicates defined on cell C p q p qP P p P P . S f n P P will contain the true predicates in P P . The values associated with these predicates are kept in the local memories of the cell and the virtualMemory C.f.vM. In 5.17 C.p tip can change the values of only the predicates in P P .

Independent Ports Every port that computes a function of the form 5.17 is an independent port of cell C if S f n Pwith the proviso cannot change the predicates in Pand cannot change predicates defined on any other port of cell C. A cell in TICC Ppde may have more than one such independent port. If C.f is an independent port of C then it is possible to move C.f together with the pathway connected to C.f to a new duplicate cell C where C .f receives the same messages that C.f receives and C .f has the same functionality as C.f. In this case all ports that are dependent on C.f see 5.18 below should be moved to C . One may assign multiple independent ports to a cell C in order to keep the CPU assigned to C from becoming idle.

InterruptPorts are always independent ports but they cannot be moved to another cell since computations in a cell are started stopped suspended resumed or the ordering of ports in the cell changed based on messages received through its interruptPorts.

where S f n 1 is the state of C relative to another port C.fof the same cell. In this case the port C.fis said to be dependent on port C.f. may use the predicates in Pbut cannot change any of them. This kind of port dependency is enforced by the TIP at C.fwith the following nested form . . 5.19 

Here immediately after responding to a message at C.f the cell waits at C.fto receive a message there and responds to it. One may have arbitrary number of such nesting in a TIP. It is possible that C.fand C.fare mutually dependent on each other. In this case the TIP has the form . . 5.20 

Here C.fresponds to its message first using the initial states relative to C.fand C.f and then C.ffollows suit. Next time C.fresponds to its message it makes use of the updated states relative to both C.fand C.fand this cycle of interaction repeats itself in the polling cycles of cell C. Clearly ports C.fand C.fin 5.19 and 5.20 are cycle synchronized. In both cases C.f tip is executed only inside C.f tip . Thus C.fis not polled in polling cycles of cell C.

Moving Dependent Ports In in the cell marked original C.fis dependent on C.fas in 5.18 . In the modified version the pathway at C.fhas been moved to port C .fof another cell c which contains the port vector C . C .f C .f . The original port C.f is converted to a generalPort C.g and a pathway is set up between C.g and C .f. The following TIPs at C.f and the port vector C .f C .f may be used to account for the dependency between C.fand C.f . 5.21 . 5.22 

Here C.fwrites a message in C.g.vM and sends it out to C .f. Clearly C.fand C .f C .f are cycle synchronized. It does not pay to separate mutually dependent ports.

The possibility of moving dependent and independent ports to new cells in this manner gives rise to the concept of canonical networks where each cell contains only one independent functionPort or functionPort vector and all other functionPorts are dependent on it.

Computations Dependent on Cell State The function computed by C.f tip may also have the form. 11 5.23 

where Sis the state of the cell C and Sis the state of port C.f. Here all the ports of C that share the state of the common parent cell are dependent on each other but they are not cycle synchronized. As before C.f tip may only change the predicates in P P . In the Dining Philosophers solution in Section 7.4 all functionPorts of butler are dependent on the state of the butler. In this case the output messages produced by a cell are dependent on the order in which the input messages are processed. Since in any one polling cycle of a cell not all of its ports may have messages delivered to them and message sensing is not synchronized with message deliveries this is a source of non determinism in TICC Ppde. As mentioned earlier it is intrinsic to parallel computations in TICC Ppde.

A functionPort f and a generalPort g of a cell may be mutually dependent on each other as in the spawning TIPs 5.2 and 5.3 . Here port f leads the dependency since g can have a message delivered to it only after it has spawned a computation which it may do only in f tip . A cell may use the generalPort dedicated to one of its functionPorts to get data from a database or from the internet. A cell may also use its generalPorts not dedicated to any functionPorts to gather data for later use as in the Produce Consumer example in Section 7.3.

TIP forms introduced in Sections 2 3 and 5 are the only forms of TIPs used in TICC Ppde. There are a total of 12 TIP forms five of them synchronous and five asynchronous. A TIP may have other TIPs embedded in its body and each TIP sends out zero or more messages. Let us refer to TIPs at the ports of a cell that are polled by the cell in its polling cycles are the polled TIPs and polled ports and the rest embedded TIPs and embedded ports. At any given time in all cases each cell executes only one polled TIP together with all its embedded TIPs. A cell executes its next polled TIP only after completing the execution of the current polled TIP or after performing a programmed suspension of the current polled TIP. Polled TIP executions are mutually exclusive Each port vector C. has one common TIP C tip defined for all the ports in the vector and one common state S n defined for all of them. C tip can change any of the predicates in P or P P depending on its functionality.

In all cases the number of TIPs simultaneously executed in parallel by cells in a TICC network and the number of messages simultaneously exchanged in parallel may be only as large as the number of active cells in the network.

It is instructive to contrast system organization in TICC Ppde with conventional system organization. illustrates the conventional architecture for concurrent parallel thread process executions in coarse grained parallel programming. Libraries provided by MPI 25 26 PVM 27 and networks provided by Ethernet 22 or Myrinet 28 are used for communications. Actor systems assume this architecture. There are significant overheads for scheduling communication synchronization and coordination and process and thread management in these systems with attendant loss of efficiency. TICC Ppde does not waste time on scheduling coordination synchronization and pthread management.

Real Time Performance There are only three kinds of operations that any cell in TICC Ppde performs i polling and ordering ports ii pthread execution and iii protocol execution. It takes only 15 50 nanoseconds to poll and sort a port in TICC Ppde with a 2 gigahertz computer. Message exchanges are self scheduling self coordinating and self synchronizing. Pthreads and cell activations are self scheduled as well. They are automatically activated when delivered messages are sensed or when a p tip is executed in the order specified by sorted ports list see 2.1 . As shown in no operating system is needed to perform these operations. All messages are sent as soon as they are ready to be sent. Every cell may send a message in parallel with every other cell at any time it is ready.

We call this real time performance since all available real time is used for performing computations in an application and no time is wasted on scheduling coordination and synchronization sessions or any other kind of overhead. No sequential buffers are ever used. The virtualMemory organization minimizes memory interference in shared memory operations Sections 7.2 and 10.2 . These allow for efficient execution of parallel programs in TICC Ppde. Conventional organizations shown in do not provide this kind of real time performance.

Predictability Established speed up technologies like multiple instruction stream executions 29 look ahead scheduling 30 pipe lined processing 31 and cached executions 32 2199 make it impossible to predict thread activation and execution times and message dispatch and delivery times Lee et al 33 36 . These techniques are not needed in TICC Ppde in order to get high throughputs. High throughputs may be achieved in TICC Ppde through arbitrary scaling of low grain sized computations. We have predictable message exchange latencies and pthread execution times in TICC Ppde. Pthread activation times are predictable with in bounded time limits. Timing is built into the event based TICC Ppde models of computation.

Synchronization Coordination TICC Ppde provides novel methods for coordination and temporal synchronization of events in an application without need to use monitors semaphores or rendezvous 10 12 23 24 . These are illustrated in the examples in Sections 3 and 7 and discussed in Section 7.6 and are unique to TICC Ppde.

Event Based Models As we saw in Section 3 and shall see more in Sections 7 8 the most important characteristic of TICC Ppde is that it automatically generates event based models of computations from implementation specifications and these models are used for static verification of the system through symbolic evaluations and also used for dynamic self monitoring by SMS. These features are unique to TICC Ppde.

Event based semantics make TICC Ppde well suited for building real time cyber physical systems and embedded systems using multi core chips with precisely timed operations if cache memories and other speed up ornamentations are avoided. These simplify CPU design in multicore chips.

Before we proceed with examples that illustrate methods used to construct ALLEOP proofs it is useful to define the nature of computation and communication in TICC Ppde events and causal relations OO organization and the notation. This we do in the next section.

We begin with a finite set of names. Names are concatenations of symbols in a finite alphabet. Let refer to this set of names. Each name in denotes something unique. Items denoted by names are called containers and objects. There are three sets here and . We use meta symbols x y etc. to refer to names in . We use meta symbols x y etc. to refer to containers denoted by x y etc. In this case we write x.denotes x and x.denotedBy x and say x E. We use meta symbols b c etc. to refer to b c etc. to refer to objects denoted by b c etc. We write b.denotes b b.value and b.denotedBy b b.valueOf b is used here since in general there could be more than one name denoting the same object. and . Denotation is defined by a many to 1 mapping . It is possible that b b or b c the value of an object name may be identical to the name itself or another object name. Thus c b b.value b c .

When several container names denote the same container x we will set one of those names say name z as the distinguished container name of that container and set x.denotedBy z. When several object names denote the same object b then we set b.denoteBy b.valueOf c c.value b. We define the following predicates for names x name x x container x.denotes which is the same as saying x x object x.denotes which is the same as saying x . We use three distinguished objects respectively called true false and with the property true true false false and is the empty object. These are called constants since the values of these object names may never be changed For any name x x constant x and x .

We assert x y iff the two names are identical to each other and assert x y if x y or x y i.e. x.denotes y.denotes. One may read x y as x congruentTo y . Two names x and y are distinct iff x y . For two sets of names Sand S S S x S y S x y S SS S S S . S Sand S Sare similarly defined. Notice use of congruent relation here.

Every container has the property that it can contain either an object or another container. We write x.contains b or x.contains y x y . Objects cannot contain anything x x.contains . We say an object x resides in a container y if y.contains x and write x.residesIn y. Every object has to reside in some container there are no free floating objects. Two objects that are identical to each other but reside in distinct containers are called copies of each other.

This definition of equality may be extended to define x X for a set x and x Y XY x Y XY and X Y for sets X and Y. Notice x y x eval is possible in 6.2 x y x y but the converse is not true.

One may think of containers x as memory cells and container names x as pointers addresses of those memory cells. One may think of each b as the encoding bit string that represents the object b and resides in a memory cell. A pointer points to an object only if the encoding of that object resides in the memory cell pointed to by that pointer. Objects in containers memory cells may be modified without having to change copies of those objects which may exist in other memory cells. We refer to the terms denotes valueOf and contains as attribute names and x attribute name as an attribute. Terms object constant and container as predicate names and x predicate name as a predicate. For any x attribute x attribute name is a predicate which is true iff x attribute eval name eval . Term eval is a method name and the term x eval is a method. We will be introducing more attributes predicates and methods defined for names as we encounter them in our discussion below.

Structures If b has an indexed structure and for a name x x eval b then x i b i b i for i in the range of indices of b else x i . However x i does not imply that i is out of the range of indices of b since it is possible that the value of b i is . An x i itself may have an indexed structure x i j . If b is a structure with attributes and b.atbt is defined for it and x eval b then x.atbt b.atbt b.atbt and x.atbt if b.atbt is not defined or b.atbt . It is possible that b atbt itself has an attribute b.atbt.atbt. Then x.atbt.atbt b.atbt.atbt b.atbt.atbt.

Groupings of Names Every name x has a method x names defined for it x names is the set of all names associated with x. It will include x all x attributes x predicate s and x method s defined for x and may in addition contain other names as well. Since x x names it is never empty. For two distinct names x and y it is possible that x names y names names . For any name x the closure of x names written as x names is names names names 6.4 

Typing of Names A name may have a type associated with it such as integer number truthValue string set structure class etc. is the set of all type names. The method x type is used to refer to the type of name x x type x type x eval type and b type b type type . Each type denotes a subset of names in type names x x type type . Clearly type type type type type.contains type set. Typeis a subtype of typeiff type type type.contains type.contains . Thus integer number holds. Typeand typeare distinct if type type . Two types neither of which is a subtype of the other should be distinct. We use the usual conventions for inheritance within a type subtype hierarchy abstract types etc. The OO structures of names associated with a system S is outlined below.

Let S cells denote the set of all cells in system S. For port C.p of cell C C.p.a is the unique agent tuned to C.p C.p.pathway is the unique pathway connected to C.p C.p.pathway.vM M C.p.vM C.p.a.vM Cp.a.vMs since a cell C may have many virtualMemories tuned to it one for each port attached to C. M is the unique virtualMemory of C.p.pathway that is tuned to C.p.M.a i is the iagent attached to M. M.ports i is the iport tuned to M a.ports i is the iport tuned to agent a C.ports i is the iport attached to cell C. C.p.ndFsm is the ndFSM embedded in C.p. C.p.a.ndFsm is the ndFSM embedded in C.p.a. C.vMs C.p.vM C.p attachedTo C . If C.p is connected to a dm pathway then C.p.pathway.vMs is the vector of all virtualMemories in the dm pathway C.q.vM C.q.pathway.vMs for every port C.q connected a dm pathway. Finally a.nxt i is the inext agent tuned to agent a. The vector M.ports M.a i .ports 0 i

Here C.p.vM names will contain all names defined in the messages predicates methods and attributes that reside in C.p.vM. Notice not all C.p names are in C.p.pathway names only C.p.ndFsm names are included.

For every port C.p attached to cell C C.p.ndFsm names C.p.pathway names 6.7 C.p.ndFsm names C.p names C names 6.8 

Thus C names and C.p names do not contain all the names in C.p.pathway names they only contain C.p.ndFsm names . At compile time the evaluator Eis given access to all names in C names . For any two pathways and distinct cells C C and any two ports p and q the following holds true 

where pq asserts that p and q are connected by a pathway. Notice the use of the congruent relation in 6.10 . Thus for two names x y x p.pathway names and y q.pathway names when pq is true it is possible that xy but x y i.e. they both denote the same container. In the case of 6.11 the pathways are distinct. Similarly 6.9 asserts that no two cells share any name that are congruent to each other. Distinct cells and distinct pathways never share containers. The invariant i.e. compile time OO structure of names in S names of a system S may now be defined as follows 

World states are compartmentalized into C names and C.p.pathway names which overlap with each other only at C.p.ndFsm names . This overlap together with access dynamically made available during protocol evaluation enables communication among ports connected by pathways details in Section 10.2 . A refinement of this structure is used to facilitate definition of methods. In the case of dm pathways ndFSMs in the pathway are connected to each other by signal lines and virtualMemories are connected by data lines. Signals and data are exchanged among containers in a dm pathway via these lines coordinated by CCPs in dm pathway protocols.

Conditions We use the term guard to refer to predicates and predicate expressions that test for signals or states of ports use state to refer to predicates and predicate expressions that describe states of ports cells and agents and use condition as a generic term to refer to all predicates and predicate expressions. A condition is any well defined first order expression containing predicates with logical connectives and quantifiers or it is a Boolean expression of predicates. Only individual predicates may be negated not entire predicate expressions. Quantifiers range over finite sets. All conditions end with the suffix . A condition is always evaluated in a world defined by the names in x names where x is a cell port agent virtualMemory or message.

CTL statements A CTL statement Causal Temporal Logic statement is a combination of conditions evaluations described later below and event instances with temporal modal operators always and eventually and causal connectives described below using quantifiers and with the usual syntax. ALLEOPs and traces we have seen so far are examples of simple CTL statements. More examples appear in later sections. Negations may appear only on individual predicates guards and event instances and not on evaluations and expressions as a whole. A negated event instance is interpreted as the event instance should not occur . Event instances have the status of both constants two event instances are equal to each other if and only if they are identical to each other and predicates. Quantified variables and may range over event instances virtual time points and other objects appearing in a CTL statement. Quantifiers always range over a priori known finite sets. We will not describe here the syntax of CTL statements.

Proofs Proofs do not involve making logical deductions on CTL statements but only involve symbolic evaluation of CTL statements over given ECT networks. We will see examples of ECT networks and proofs in Section 7.

Evaluators There is a structured constant called evaluator. A system may have arbitrary but finite number of evaluators E i for 0 i0. We will never encounter a need to refer to evaluators explicitly in our discussions. But the concept is important. In TICC Ppde there is an evaluator CPU associated with every cell and all evaluators operate in parallel interacting with each other only through message exchanges. Let Ebe the evaluator of cell C. Evaluators perform computations by creating destroying names containers objects and encodings modifying encodings placing encodings in containers placing containers in other containers moving objects containers from one container to another moving containers from one name to another and setting access rights to containers and accessing objects their encodings from world states. These are the action and access events. Computations performed by evaluators cause access and action events to occur. When evaluator Eaccesses a name x from W it will add the triplet x x x eval to E.accessedItems list. At the end of an evaluation it may use the elements in E.accessedItems to perform a consistent update of Wand then destroy its private E.accessedItemslist.

A name x is created destroyed in a world state W t by an evaluator if x t is true false but x t is false true in the immediate predecessor W t . The general convention is a predicate is true in W t if there is a t tsuch that the predicate is true in W t and there is no t t

Protocols The only difference between communication and computation is that communication protocols may not create destroy containers. They can modify signals and states of ndFSMs in a pathway as it happens in the protocols we have seen so far. As we shall see in Section 8 protocols may also modify certain a priori defined data associated with ports and agents in a pathway. These are the only data that protocols may modify. This is because protocols do not contain declarations. Protocols cannot modify messages or other data in virtualMemories. Thus communication is simply a restricted form of computation with the difference that communication transfers besides signals also access rights to evaluators.

Access Rights and Communications Consider an evaluator Eof cell C and a pathway C.p.pathway. Let E.hasAccessTo t specify the set of all names Ecan access at time t. E.hasAccessTo t at the time Eis executing C.p tip is 

Here E.hasAccessTo t is a function of time because the virtualMemory of C.q.pathway may contain different messages at different times and also the pathway and messages may change dynamically. Access rights for the names in C.q.pathway names 0 are transferred to Eonly when C.q is in state S. For any two cells C1 and C2 if C1.pC2.q is true and a message is being exchanged between C1.p and C2.q then exactly only one evaluator either Eor E will have access to C1.p.pathway names C2.q.pathway names since only one of them will be in state S and the evaluator of the cell that delivers message will have access to both C1.p.ndFsm names and C2.q.ndFsm names . This enables communication between the ports C1.p and C2.q.

Transfer of Access Rights As described in Tables 1 and 2 a port always changes its state to S when a signal is sensed and the port becomes ready to send out a message. Thus in TICC receipt of a message signal by a cell C automatically transfers access rights to evaluator E. Cell C begins execution of C.p tip at one of its ports C.p only after acquiring this access right. Access is revoked only when E completes execution of C.p tip Mechanisms for doing these are described in Section 10. Polling C.p accesses only the names defined in C.p.ndFsm names and access to these names are always made available to E. However delivering a message from port p to port q accesses both C.p.ndFsm names and C.q ndFsm names . Access to both of these becomes available to an evaluator at message exchange time. We use this property in Section 10.2 to propose a new shared memory organization that exploits virtualMemories.

Evaluations Evaluators have the property that they can evaluate actions events and names. Action is always a method protocol or condition or simply a statement in a programming language a declaration assignment conditional like if then else and selectOne or a while loop or a bit string manipulation statement. A declaration appearing in a method y A defined in a cell message port agent or virtualMemory y introduces triplets x x x eval into y.A world t for the declared name x. We use declarations also to destroy and remove names from y.A world t . In addition y.A world t contains x x x eval X X y names A names x X names y.A world t will also contain the compiled code for y A and will contain names that are dynamically created while y A is being executed. Protocols are actions with the difference that they do not contain declarations and string manipulation statements but do contain CCPs. Thus protocols do not dynamically create or destroy containers or manipulate strings. Methods usually do not contain CCPs.

Applying an evaluator to a name x action x A or condition x C may cause new events described below to occur which may in turn cause other evaluations and occurrences of other events. For this reason we refer and as causal relations. They are irreflexive asymmetric and transitive. Evaluators not only cause events to occur but they may also evaluate communicationEvents as described later below.

Note on Time Instances Every event has a time instance associated with it. It is possible that two time instances tand tare incomparable because they are measured in local clocks of different evaluators which are not synchronized to each other. But every clock time has a unique 1 1 mapping to a global time. We use x.t y.tto refer to local time points associated with two different objects x and y. Inequality x.t

Access Evaluation As mentioned earlier notation x t is used to denote the event where an evaluator got hold of the triplet x x x eval from the world W t . Clearly an evaluator E may access x only if it had the access right for it i.e x E.hasAccessTo t . When evaluator thus accesses x it would then have access to all names in the closure x names . In the following we define evaluators and . When necessary we write and to explicitly refer to the evaluator E that does the evaluations. Access evaluation may now be defined as follows 

It always takes some time 0 to complete an access. If access is successful then it causes the event x t to become true. Access action does not change the world state W only the local state of the evaluator E changes. Once x is accessed at time t x x x eval gets into E.accessedItems at time t and E gets access rights to all names in the closure x names t . If the pre condition in 6.17 is not satisfied then the access attempt will return . Since we use the convention that predicates in world states always maintain their truth values unless changed it is not necessary to specify the frame statement W t W t in 6.17 . We assume here that local states of evaluators are distinct from world states thus the triplets appearing in E.accessedItems will never occur in world states even though components in the triplets form relational structures in the world states as described earlier.

Here X.A preC is one part of the pre condition for x A it may include in it characterization of messages processed by x A . The other part of the pre condition is that it must have accessed all needed names in x.A world . Similarly x.A pstC is one part of the post condition for the action. It specifies changes to the world state W produced by the execution of x A. The other part of the post condition is x.A output which is the characterization of outputs produced by x A . It could be or it could be an output message. The condition x.A preC and all specified accesses in the pre conditions should be true in order for the evaluation of x A to succeed. Evaluation is correct if it succeeds and the post conditions hold true in the world state W t . Since occurrences of access events and condition checking do not change the world evaluation may be performed in the same world in which the pre conditions are true. The context of evaluation for this action is the subset S of x.A world t .

Hereafter we will omit the prefix superscript E and subscripts a and e in and and simply write the evaluation as assuming is subsumed in . For a constant c c c c c c at all times. We will not hereafter have occasion to refer to access evaluations .

Pthreads and Methods Pthreads are methods a subset of actions. Methods are defined using five kinds of programming statements Declarations Assignments Conditionals like if then else and SelectOne While loops and bit string manipulation statements. Declarations create destroy containers and objects may set contents of newly created containers and cause triplets x x x eval to be introduced into or removed from method world at compile execution time. Other statements in a method definition may cause objects and containers to be modified contents moved from one container to another or denotations of names changed. During its execution a method changes only the local state in method world . At the end of its execution the evaluator may use this local state to perform a consistent update of the world state W t . Since W t is compartmentalized as defined in 6.11 cell isolation Section 4.2 guarantees that multiple parallel updates to W t may be done by different cells operating in parallel without mutual interference. Semantics of program statements that appear in method definition may be easily defined. We use program statements informally here assuming reader would know the intended meanings. Characterizations of CCPs used in protocols were presented in Tables 1 and 2. For most statements used in pthreads and protocols TICC Ppde can automatically generate the associated pre and post conditions in given contexts but user interaction may be necessary to define certain pre conditions and loop invariants.

Events We saw in Section 3 examples of action and communication events that occur in ALLEOPs and traces. In the following we use symbols x Y Z . . . for ActionEvent classes and symbols X T . . . Y T . . . Z T . . . . . . for CommunicationEvent classes. These event classes refer to ALLEOP nodes. They are subclasses of the top level class Event. We use symbols x t y t z t . . . to denote event instances x t specifies that the instance x occurred at time t see . If x t is an instance of the CommunicationEvent subclass X T then t T virtual time points x .t refers to individual time instances at which instances of x T occur in a trace .t T see for example ALLEOP in 3.11 and its trace in 3.21 . In a run of an application multiple instances of the communicationEvent subclass x T may occur in a causalnet. The set of time points at which those instances occur in that causalnet constitute the sequence of strictly increasing time points .t T for that run of the application see .

CommunicationEvents We introduce below the forward variation p f of send command p s for a port p q f g i p q.

Forwarding transmits a received message may be with some modifications and sending transmits a newly created message. We will see the precise distinctions in Section 7.2. In the following p t refers to start of an occurrence of an instance of pin a message sending forwarding process at port p at time t p t refers to the ending of that event occurrence at time t t

CommunicationEvent Evaluations 1 There are two kinds of communicationEvent evaluations. The first kind occurs during protocol evaluations. They are described below 

The above statements describe what happens at the beginning and ending of a protocol execution and what happens when delivery signals are sensed. Lines 1 and 2 specify that in the beginning the completion signal C I f is sent to port g f or i if the ports are ready to respectively sendlforward a message i.e. p mR or p pR is true . As mentioned earlier evaluation of p mR or p pR is called sensing or polling. As shown in lines 4 through 7 port p moves to state S after successful sensing. Thus always port p will be in state is S when it is ready to send out a signal. Immediately after the completion signal c f is sent the state of ports changes to R as shown in 1 and 2 . Thus after sending out a completion signal port p cannot immediately send out a second signal. Similarly line 3 describes what happens at the time of message delivery in a protocol execution Here p t is the delivery event at port p. It begins at time tand ends at the time when p.input s becomes true. Lines 4 5 6 7 describe what happens when an already delivered signal at port p is later sensed. Notice lines 6 7 g.input is reset to . Thus a delivered signal may be sensed only once at port g. As mentioned earlier this resetting of g.input will not occur for the subclass of generalPorts that belong to a generalPort vector.

In all cases after sensing a signal ports move to state S. A port p gives access to its parent cell to the virtualMemory p.vM only when p.state S. No port will ever give access to p.vM to any cell other than its parent cell. Once a port is ready to send out a signal it continues to be ready till a signal is sent out as defined in lines 1 and 2 .

CommunicationEvent Evaluations 2 The second kind of communicationEvent evaluations occur in SMS Section 8 which uses event evaluations to install instances of ALLEOP nodes in a growing causalnet of an application while the application is running. This is defined below in 6.21 and 6.22 . shows an Event Builder cell eb. When eb applies the evaluator to a communicationEvent it produces an instance of that event at a specific time point and installs it into the causalnet. Every communicationEvent has two time points associated with it One is the time when the event itself occurred this is important and the other is the time when its instance was installed in a causalnet this is not important . Use of these two time points is explained below.

In 6.21 and 6.22 below eb.f eb.f is a port vector of the Event Builder cell eb in C.gand D.fare ports that exchange message 0 i0 and 0 j0. Ports D.fcould be interruptPorts D.i. We use symbol f here to denote both functionPorts and interruptPorts since interruptPorts constitute a subclass of functionPorts. The cells Cevaluate C.g.protocol respectively in parallel to send message and deliver it to ports D.f. These protocol executions are coordinated by agents in the group to group pathway in as explained in Section 8. Protocol executions trigger evaluation of the communicationEvents C.g t and D.f t where tis the time message sending forwarding started and tis the time when message delivery completed. Evaluation of the above communicationEvents to install instances of these two events in the causalnet is defined as follows For 0 i

During protocol execution signals are sent to ports eb.f eb.f to instruct the eb cell to create instances of the CommunicationEvents C.g t and D.f t . Signal f is sent to port eb.fif message is being forwarded and signal c is sent if message is being sent out. Signal s is sent to port eb.fin both cases. The way this happens is explained in Section 8. Here the guard eb.f mR for k 1 2 will return true if eb.f.input c f s . In 6.21 eb completes sensing of the signals received by both ports in eb.f eb.f at time t. This is also the time when eb begins its evaluation of C.g t D f t . This results in the installation of event instances c.g t d.f t in the causalnet at time t.

 6.22 describes events installed in the causalnet for reply message transmission. We will hereafter associate with communicationEvent instances only the time points at which the events occurred and not show the time points at which the instances were installed in the causalnet. This is consistent with the way we associate time points with action event instances.

Thus Event classes and event instance have the status of constants they are equal iff they are identical. However evaluation of Event X is different from evaluation of a constant. Also as mentioned earlier events have the status of predicates as well. Thus x t represents the fact that event x has occurred at time t.

Simultaneity and Parallelism Parallel evaluations of communicationEvents occur when ever multiple evaluators are used. For communicationEvent evaluations the following holds 

In 6.25 T . . . and T . . . are the two time maps of communicationEvents in two different evaluators. The evaluations started at the local time points c.tand c.t and were completed at c.tand c.t respectively c.t

Similar parallel evaluations may occur also for actionEvents. The only difference is no time maps are associated with actionEvents but virtual time points are associated with actionEvent instances. Any Event class may have multiple instances occurring at different virtual time points in strictly increasing order.

Causation In the following X and Y are Event subclasses. We use the evaluator symbol as the causation symbol in the following sense occurrence of an event instance may cause one or more other event instances to occur read X Y as X causes Y and X Y as X causes Y if condition C X Y is true 

No event may occur between x and Y in x Y in 6.30 . Thus the evaluation is indivisible it cannot be interrupted.

 operator should be assumed even if it is omitted as in 6.33 . It is possible that the causal chain or immediate causal chain of events in a pthread or protocol execution branches with alternates on either side of statements 6.31 and 6.33 leading to different terminal events as shown in 5.5 5.6 5.14 and 5.16 and 8.4 . When a fork occurs in a protocol execution the causal chain will contain parallel branches which may eventually join at a single common communicationEvent as illustrated in the diagrams in . This holds true for all refinements introduced below. For simplicity we use linear immediate causal chains in our presentation below. It should be assumed that causal chains may contain branches with alternates and or parallel forks in all cases.

A refinement of X Y is an immediate causal chain e e . . . e such that X Y X e e . . . e Y . If we use to refer to the immediate causal chain e e . . . efor then the general cases would be for n 0 

where for are immediate causal chains the symbol specifies alternates and the symbol separates parallel causal chains. Forms 6.34a and 6.34b may occur together in interleaved combinations.

Refinements of Pthreads and Protocols The delivery events caused by a protocol are always uniquely determined by signals exchanged during protocol execution. A refinement of message transport from a port p to a port q has the form linear refinements are assumed in all statements below only for simplicity 

This is the uninterruptible sequence of CCP and other actionEvents in the protocol at port p. The refinement of a pthread that is executed after a delivered message is sensed and before a response message is sent out by a cell C will have the form 

This is also an uninterruptible sequence of actionEvents. It occurs during pthread execution. The refinement of

Synchronization Synchronized parallel forks occur in the following Instances of communicationEvents. Events Zand Zoccur simultaneously in 6.39 

Generalization of Coordination Here Event Z T . . . occurs iff all events X X . . . Xhad already occurred. X T . . . X T . . . . . . X T . . . Z T . . . 6.42 

Generalization of Coordination Synchronization Events Z Z . . . Zall occur simultaneously after Events X X . . . Xhave all occurred. X T . . . X T . . . . . . X T . . . Z Z . . . Z T . . . 6.43 

Event Alternates X Y either X or Y occurs. Generalized Alternates X X . . . X 6.44 where each xcould be a causal chain. Choices in an Event alternate expressions should always be pair wise mutually exclusive.

Guards and Polling Guards were defined in Tables 1 and 2 and in statements 4 through 7 in 6.20 . Polling involves evaluation of guards and evaluation of guards changes the state of a port. This is an exception to the general rule that condition evaluations do not change the state of the world. We have seen several examples of polling. The following restriction on TICC Ppde operation pertains to polling 

Consistency of world state Every world state W t represents the state of a computation at time t. At any time point t the world state W t is consistent. The proof system maintains and updates world states at postulated time points during ECT evaluations. If it detects a contradiction between a CTL assertion and the ECTs during ECT evaluation illustrated in Section 7 then the assertion is not valid. Such contradictions would indicate design or implementation errors. Contradictions with ALLEOPs encountered during causalnet generation by SMS indicate errors in system operation.

Condition Migration over We refer to the format C X where X is a Communication or Action Event as ALLEOP format and format pre output pst as the trace format. The latter describes the semantics of C X. Execution is between the time points in the semi closed interval t t and X is the maximum permissible delay. In the following it has been assumed that condition evaluation will not change the world guards excepted and action is evaluated in the same world at time tin which the pre conditions are true. The context x and y below in 6.46 are either a cell C or a port C.p. All condition checking and action evaluations take place in the context of x.A names t C names t A names holds. This context will include in it local execution stacks of variables maintained by an evaluator during a method evaluation.

As mentioned earlier an action evaluation is undefined if its x pre C is false and is skipped if x C is false. While executing two successive actions x A and y A linked by execution of y A begins at the same time as execution of x A terminates and in addition the world state in which the post condition of x.A is true logically implies the pre condition of y A . There is usually a small delay between the time when Aterminates and the time when Astarts. But during this delay the world of cell C does not change since no other action may occur in cell C between two such actions and actions occurring in other cells cannot affect the state of cell C because of cell isolation section 4.2 . Thus this delay is ignored.

Polling Cycles In polling cycles we used specifications of the form C.f i mR C.f j mR for i j. This is interpreted as C.f i mR . . . C.f j mR in the following sense 

In other words servicing of C.f i and C.f j occur in the semi closed intervals t t and t t such that t t t t with the restriction C.f j mR t i.e. evaluation of C.f j mR begins at time point twhen C.f i tip ends. In 6.47 servicing of C.f j will occur only if C.f i mR t evaluates to true else the port will be skipped and polling will proceed immediately to C.f j . Here we have assumed p tip at port p is executed immediately if polling succeeds at p. Statement 6.47 may be suitably modified for the case where polled ports are sorted before their associated tip s are executed.

Thus polling cycles specify only the order of polling but not the order in which polled ports are serviced. Parallel triggering of TIPs that follow each other in different cells because of communications was described in the examples in Section 3 here the only requirement is that conditions that characterize messages at the time they are sent remain invariant until they are delivered and the delivered messages are sensed and used.

Let us now proceed to consider examples that illustrate simple ALLEOP proofs. In all proofs we assume that implementations of all pthreads and conditions would have been already individually verified. This is possible since pthreads are mutually independent dependent pthreads are jointly verified and all conditions are always local to a cell. We begin with a solution to a generalized version of the Ornamental Garden Problem introduced in Magee Kramer 13 . Formal ALLEOP proofs are presented for mutual exclusion and condition synchronization terms used in Magee Kramer 13 in this example. The solution applies also for the Car Park problem in Magee Kramer 13 .

Our objective here is to display the structure of ECT networks and show how they are used by the system to generate proofs. See Maggie Kramer 13 for the FSP specification for the Ornamental Garden problem. The problem is the following An ornamental garden park has several gates each with a turnstile. As in Magee and Kramer we assume two entrance gates at two ends of the park but unlike Magee and Kramer we also assume two exit gates. Gates are opened when the park is opened and closed when the park is closed after all people who entered the park had left. At any time the park is open people are allowed to enter through any entrance gate and exit through any exit gate. It is necessary to keep an accurate count of number of people who are in the garden at any time and never allow that number to exceed a preset max.

The TICC network is shown in . It has two entrance turnstiles Et 0 and Et 1 2842 and two exit turnstiles Xt 0 and Xt 1 . There is one environment E which opens and closes the gates of the park based on external interrupts. There is one counter. We assume when a person arrives at entrance or exit turnstiles Et j or Xt j for j 0 1 sensors Se j and Sx j detect persons at turnstiles. Each turnstile together with its sensor is an encapsulated cell. They are shown separately in for convenience. On detecting a person sensors signal ports Et j .for Xt j .f subscript for turnstile for j 0 1 via Se j .gEt i .for Sx j .gXt j .f as the case may be. Pathways Se j .gEt j .fand Sx j .gXt j .fare internal to the encapsulation.

Predicates Et j personEntering and Xt j personLeaving become true when Et j and Xt j respectively detect signals at ports Et j .fand Xt j .f. See Appendix I for definitions of these predicates. The following TIPs are executed by the sensors internal to the encapsulation when they detect persons 

Here Se j .g pR and Sx j .g pR wait for response at the generalPort for the previous sensor signal sent to the entrance and exist turnstiles respectively. Thus a new person is recognized only after the previous person has been processed. The counter has five functionPorts C.f j 0 j

For j 0 1 On sensing the signals at ports Et j .f the turnstiles signal the counter through pathways Et j .gC.f j see . When counter C senses the signal at C.f j for 0 j 1 it does the following i C increments the count by one if counter.count

In order to either allow or not allow a person to enter Et j performs synchronous non deterministic polling at its ports Et j .g and Et j .f by evaluating the guard p p Et j .g Et j .f p mR . Et j thus waits for response from the counter at any one of these two ports and takes appropriate action.

For j 2 3 The exit turnstiles Xt j .g for j 0 1 signal the counter via Xt j .gC.f j 2 . On sensing signal at C.f j 2 the counter decrements the count by one and signals back via C.f j 2 Xt j .g in order to unlock the turnstile and let the person at leave Xt j waits at Xt j .g for this response by performing synchronous polling Xt j .g mR .

For j 4 the port C.f 4 is used by the counter to receive and respond to requests from the display unit to send the current value of counter.count. The display unit sends the request for count based on an external interrupt from a user see .

Multiple people may enter and leave simultaneously in parallel using multiple turnstiles. However each turnstile will allow only one person to enter or leave at a time. The program is self scheduling self coordinating and self synchronizing. The TICC network and TIPs determine signal exchanges and execution control structure. It should be clear the OG solution in Appendix I applies also to the Car Park example defined in Magee Kramer 13 with multiple Car Park entrances and exits with the difference parking fee has to be paid before a car leaves.

The time taken for signal exchanges and counting should be far less than a millisecond assuming 5 kilometers long 1 Gigabits sec signal transmission lines and 2 gigahertz CPUs. Thus one may have practically unlimited number of entrance and exit turnstiles. The CIPs ALLEOPs and traces for the TICC Ppde implementation based on this network are presented in Appendix I. We refer to this as the OG Solution.

To complete the implementation shown in Appendix I one has to define the following personAtGate personEntering personLeaving denyEntry letPersonIn letPersonLeave personlnPark and displayCount . With that the ALLEOPs and traces in Appendix I would model the completed implementation. The implementation does not require monitors semaphores rendezvous 10 12 23 24 locks schedulers or any other synchronization or coordination control primitives.

It should be clear that in this organization no two counter activities invoked by the turnstiles will interfere with each other since the counter services a second functionPort only after completing the service at the first one. It should also be clear that the number of people in the park could never exceed max since permission to enter is granted only if counter.count

User defines the following interpretations for Stmt 1 and Stmt 2 above as CTL statements Events in CTL statements are specified either by predicates or actions. Quantifications in CTL statements 7.2 and 7.3 below range over postulated time points and events that occur in the statements.

In the CTL statement 7.2 ctl.tis the time at which the invocation of counter instance A1 terminates and in 7.3 ctl.tis the time when invocation of A2 begins. The restriction ctl.t

We have here assumed that each invocation of counter increments the count by 1 and each invocation of counter decrements the count by 1. Thus 7.2 and 7.3 assert a person at gate should be allowed to enter the park only after the counter had been incremented by 1 exactly once and allowed to leave the park only after the counter had been decremented by 1 exactly once and the two invocations of the counter should not overlap. The starting and ending events in 7.2 and 7.3 are 

Notice the pair of time points ctl.t ctl.t at which starting events terminate in 7.2 and 7.3 are incomparable. So also the time points ctl.t ctl.t at which ending events begin are incomparable. They occur in parallel. Thus persons may enter and exit simultaneously or in any order. For this example replacing the second ellipse . . . in 7.2 and 7.3 by 0 will not change the meaning of the statements since in each case there is only one way of reaching the ending event from the starting event. The problem to prove is Traces EnteringGarden CountedOnce LeavingGarden CountedOnce 7.4 

where Traces is the set of all traces for the implementation and is the logical consequence relation. At this point the CTL assertions above do not state how many entrances and exits are in the garden. This is something to be discovered by analyzing the implementation.

The network in Table 5 shows interactions between the various ECT blocks Block 5a through Block 5g at the entrance turnstiles Et j . Contents of Block 5a though Block 5g are shown in Tables 5.1 though Table 5.3. The task performed by the events in each block is summarized inside the block in Table 5. Each block contains a list of events numbered in the order they occur with virtual time points associated with each event. Thus the sensor block Block 5a in Table 5 whose details are shown in Table 5.1 has seven events. These are the events that occur in the port trace Se j .f port Trace Se j .t as indicated by the header of Block 5a in Tables 5 and 5.1.

In all blocks signal delivery event and signal sensing event are declared separately thus in Table 5.1 the signal delivered to Se j .f in 5b 1 block 5b and line 1 is sensed in 5b 2 block 5b and line 2 . This is because delivery and sensing may not both happen synchronously unless a port is waiting for the signal at the time signal was delivered. If the port is not waiting for the signal sensing of delivered signal may not occur immediately. However in 5a 6 and 5a 7 sensing occurs immediately as indicated by the common virtual time point Se j .t since port Se j .g is waiting for the signal at the time signal is delivered as indicated by the in 5a 7 .

Block 5a activates Block 5b through a signal sent to 5b 1 shown by a solid directed branch marked personEntering in Table 5 that links the two blocks. Here the sensor Se j Block 5a sends a signal to entrance gate Et j via pathway Se j .g Et j .f as shown 5a 4 and 5a 5 indicating that a person is entering. When Et j senses the signal delivered to Et j .fby Se j .g it will activate response activities in Et j . We call this parallel activation because Se j and Et j run in parallel. Details of this parallel activation are shown in 5a 4 5a 5 in Table 5.1 and 5b 1 5b 2 in Table 5.2. The comment to 5b 2 in row 5a 5 in Table 5.1 indicates that the signal is being sent to 5b 2 in Table 5.2.

Always signal sensing requires coincidence of two activations i parallel activation through signal delivery and ii sequential activation through flow of execution control. A signal delivered to a port is sensed only when that port is polled by its parent cell. All parallel activations require coincidence of both activations. Reader may verify that this holds true in Table 5 where sequential activations between blocks are shown by directed branches with broken lines and parallel activations by solid directed branches. The ellipse . . . occurs in a parallel activation branch for example in the branch on the left going from Block 5b Et j to Block 5e Counter in Table 5 marked ask counter can enter . This indicates sensing may not occur at the time of signal delivery.

Here sequential activation of the port C j .f j is controlled by the polling cycle of the counter as indicated by branch with broken lines going into Block 5e from bottom left of Table 5 marked 1 with annotation i C.f i port ECT cf i .t and the branches with broken lines going out at the bottom center of Block 5e in Table 5 marked 2 with annotation i C.f i port ECT cf i .t . The angle brackets in 1 indicate that activation is at the end of C.f i port ECT cf i .t execution and absence of angle brackets in 2 indicate that activation begins the

port ECT. It is possible that index i in the existential quantifications in 1 and 2 is equal to the j appearing in the header of Block 5e in Table 5 since it is possible that the counter services a second person entering through the same gate Et j in the polling cycle following the one in which the first person was serviced with no intervening services at any other gate. In all other parallel activations in Table 5 there are no ellipses because ports to which signals are being sent would be waiting for them. Inside each block sequential activations occur in the order events occur in the block.

When the turnstile Et j senses personEntering by sensing delivery signal at its port Et j .f shown in 5b 2 of Table 5.2 Et j begins to respond to the received message. It asks the counter for entry permit and depending on the response received from the counter either lets the person enter or displays sign PARK FULL . It is worth noticing the sequential branching at the bottom of Block 5b in Table 5. This occurs as a result of non deterministic polling shown in 5b 5 in Table 5.2. System picks out from the ETC networks in Tables 5.1 through 5.3 and Tables 6.1 and 6.2 events needed to prove the CTL assertions 7.2 and 7.3 as described in the subsection 7.1.2.

Summary Sequential activations between ECT blocks in Tables 5 and 6 represent Execution orderings of events in the network. These are determined by polling cycles and order in which TIPs in cells are executed. We refer to sequential ordering caused by TIP executions as causal ordering. Thus orderings inside ECT blocks are causal orderings. The network in Table 5 shows the series parallel composition of port ECTs that are consistent with port ALLEOPs and polling cycle definitions in Appendix I. Let us now consider the structure of ALLEOP proofs developed by the system.

The proof system searches the ECT network i to identify matching correspondences between time points postulated in CTL assertions and virtual time points in ECT blocks ii to find causal chains in ECT networks from starting events in CTL assertions to ending events and iii analyze the causal chains to verify that claims in CTL assertions are satisfied by the causal chains. In this example searches are simple. They do not show complexities that may arise due to multiple choice points multiple parallel activations forks and iterations. Some of the complexities that appear in such searches arise in the DP Solution in Section 7.4.

The following matching time points between those specified in the CTL statements and the virtual time points in the ECTs in Tables 5.1 through 5.3 and Tables 6.1 and 6.2 are displayed by the proof system 

There are two possible starting ending events one for j 0 and the other for j 1 as shown in 7.5 and 7.6 that match with the events in 7.2 and 7.3 respectively. The system displays the following causal chains between starting and ending events in the ECTs that correspond to 7.5 and 7.6 for j 0 1. Causal chains derived from ECT tables are put in trace format.

As the system constructs traces it marks events in ECT networks that occur in the traces and keeps track of the events and their virtual time points. We refer to this process as symbolic evaluation of CTL statements over ECT networks. Reader may verify that traces 7.7 and 7.8 follow from Tables 5.1 5.3 and 6.1 6.2. During trace construction conditions are enclosed in chain brackets gathering together all conditions that occur at the same virtual time point into one conjunction. Action events are enclosed with in square brackets with the evaluation sign .

At this point user notices that there is incomplete specification of requirements. In 7.7 the counter is active during the semi closed intervals cf j .t cf j .t for j 0 1. In 7.8 it is active during the intervals cf j 2 .t cf j 2 .t . It has not been specified that non intersection of time periods during which the counter is active should hold true for all intervals corresponding to all values of j 0 1. User clarifies the situation here by specifying that it should hold for all j at both entrance and exit turnstiles. System has to now analyze the traces in 7.7 and 7.8 to verify that the updated CTL assertions 7.2 and 7.3 hold true for all j j 0 1 both for entrance and exit gates.

There are three general requirements that should be satisfied by all ECT networks in order to guarantee progress 

GR 2. Every port receiving a delivery signal should have two activations one is sequential activation and the other is parallel activation.

GR 3. Every port with synchronous polling whether polled in a polling cycle or polled in an embedded TIP should have a signal delivered to it eventually through parallel activation.

All the above three requirements are satisfied for the networks in Tables I and II. In this example there are two additional requirements a the counting event should occur only once in each causal chain and b no two counting invocations should overlap. Even when counter appears only once in each causal chain it is possible for two counter invocations to overlap because of parallel executions of causal chains. Immediate causal chains of events in 7.7 and 7.8 indicate that for ports c.f j 0 j

We validate Stmt 3 by proving that the total number of people in the park is always less than or equal to max. This corresponds to condition synchronization in Maggie Kramer 13 . This is a NFSP proof and requires induction of the following kind 

System validates these by using definitions of personEntering and personLeaving given in Appendix I and evaluating 7.10 and 7.11 over the ECTs in Tables 5.1 through 5.3 and 6.1 through 6.2 for all possible orderings of pairs of turnstiles since the starting and ending time points in each pair e j .t

It should be clear that the system organizes information in traces and polling cycles in to a network of ECT blocks in a form that is convenient for finding time points that match with those in given CTL statements and build traces that match the starting and ending events in the CTL statements. Causal chains identified in ECT networks are easily transformed to trace formats.

The claims proven here are properties of the implementation since ALLEOPs and traces were automatically derived from the implementation. It may be noted as parallel activations transfer control from one cell to another symbolic evaluation of CTL statements over the ECTs may be done in parallel since we may have a CPU assigned to each cell. In this example the ECTs are simple and parallel evaluation is not needed. Only sequential compositions occur here since for each entry and exit the turnstile waits until the counter has completed its task and servicing of each entry and exit through any one gate is done sequentially by the counter. The only logical inferences needed here were for the incorporation of definitions in I.4 and I.11 given above. Since pthreads are pair wise independent and may be proven correct independently proving CTL statements will only involve chasing causal sequences in ECT networks of implementations making propositional inferences to make selections at choice points when needed and analyzing causal chains to verity conditions in CTL assertions.

Causal chains that satisfy CTL assertions validate those assertions. If a CTL assertion is not valid this proof method may provide a counter example. If an ending event is not reachable and the ALLEOP is a finite ALLEOP then proof will terminate with a counter example. For non finite ALLEOPs proofs may not terminate user intervention may be necessary. After finding the needed causal chains the system analyzes sequential and parallel activations to ascertain mutual exclusion properties and partial orderings of events. Proof method is interactive. At each stage of proof system presents its findings to users and gives opportunities for users either to modify given CTL statements based on the findings or provide new assertions that may guide proof search. In this example identification of matching time points and causal chains were simple. A more complicated proof involving tracking of states of cells occurs in the DP solution in Section 7.4. In all cases user has the responsibility to choose the set of CTL statements whose validity verifies correctness of an implementation as discussed in Section 7.5. For complex implementations this may be a non trivial problem.

This example used only point to point signal exchanges without virtualMemories. The remaining examples use virtualMemories in their pathways. So we introduce first the structure of virtualMemory and operations associated with it.

If cells in a cell group use the same virtualMemory M then each cell in the group will have a port which belongs to a port group and all ports in that port group will be tuned to the same agent attached to M as shown in . Cells in such cell groups will use the scratchpad SP of M to exchange data during parallel pthread executions in the environment provided by the executionMemory of M. Data from a database or a main memory may be shared by a cell group only after they have been copied into virtualMemories.

As mentioned earlier each port p is tuned to a virtualMemory M by being connected through a branch to an agent attached to M. VirtualMemory of p refers to the virtualMemory p.vM M that has been so tuned to p. We write p.rd p.vM.rd p.wr p.vM.wr p.sp p.vM.sp p.ex p.vM.ex and p.sm p.vM.sm to respectively refer to the read write scratchpad execution and signal memories of p.vM. We write p.wr wR msg to write a blank instance of the message subclass msg called the container for msg into the writeMemory of M may be with some default data values. We use p.rd wR msg to similarly write a container for msg into the readMemory of p.vM similarly for other components of M. We write p.rd msg p msg and p.wr msg to respectively refer to the messages in the read and write memories of M. We use p make msg to write an instance of msg with the specified data into the writeMemory p.wr of p if a container is not already present in p.wr. If a container is present in the virtualMemory then the make command fills it with the specified data p.rd make msg does the same for the readMemory. Similar make and write methods are assumed to be defined in the Read Write Scratchpad Execution Signal memory components of VirtualMemories.

In most applications containers for needed message subclasses are installed into virtualMemories at the time of initialization. Thus normally only the make command is used. Compiled codes for message subclasses and methods defined in them are held in the executionMemory of the virtualMemory. Thus all methods and data defined in message subclasses and installed in virtualMemories will be available to parent cells of ports tuned to those virtualMemories when those ports are in state S and only when the ports are in state S. It is possible that more than one virtualMemory contains codes for the same message subclass.

We use p msg empty to check whether message in the readMemory of port p is empty i.e. does not contain any data and use p.wr msg empty to check the same for message in the writeMemory of port p. Similarly p msg .attribute empty and p.wr msg .attribute empty are used to check whether the specified attribute of messages is empty in read and write memories of p.vM. We use p.rd empty and p.wr empty to check whether the indicated memories are empty i.e. no containers are present. We use p.vM clear to clear the contents of all memories of p.vM. Similarly p.rd clear and p.wr clear to clear the read or write memories of p.vM respectively. Similar assertions are defined for the scratchpad execution and signal memories as well.

Coordination of such simultaneous parallel executions of pthreads by parent cells of ports in port groups using the same virtualMemory M is facilitated by the following i facilities for simultaneous read access to shared data in the virtualMemory ii facilities to use pthread locks where needed to coordinate data updates when pthread locks are used they would apply only to the cells in the cell group that use M and iii facilities to communicate through commonly shared scratchpad memory during parallel executions in order to coordinate computations. Communications via the scratchpad may occur using the CSM 10 12 mode of message passing.

Possibility for memory contention is limited by limiting the number of cells in cell groups. We estimate in practice the number of cells in a cell group is likely to range from 1 through 4 and never exceed 16. To prevent data overwriting and to protect data the area of virtualMemory into which a cell in a cell group may write is restricted. Ports in a port group that are tuned to the same virtualMemory may hold addresses of non overlapping memory areas into which parent cells of those ports may write data. These facilities may be used to effectively minimize memory contention. We present in Section 10 a memory organization for shared memory multiprocessors using SMMs Shared Memory Modules which exploits the virtualMemory organization of software in TICC Ppde to dramatically reduce memory contention and increase data protection and security.

At this point we introduce rules for condition migration over communication events In the case of message sending using p s the message characterizing conditions get switched between read write memories. In the case of message forwarding using p f the conditions do not get switched 

Next two subsections present PC Solution Produce Consumer and DP Solution and ALLEOP proofs associated with them. Solutions are implemented without having to use semaphores Dijkstra 23 24 monitors 12 rendezvous or sequential buffers. We have said this several times but we believe it is worth repeating since semaphores rendezvous and monitors are well entrenched mechanisms in programming technology and are considered indispensable. They have been in use for more than four decades now 

Our objective here is to illustrate use of parallel buffers. The network for the PC solution is shown in and the solution is presented in Appendix II. It has n producers P i 0 i

CTL assertions for the above two statements are Stmt 1 j x x P j produceProduct D.g msg .content x 7.14 Stmt 2 j C j .g C j .hasProduct 7.15 

In 7.14 P j produces a product and distributor eventually receives it at its port D.g. In 7.15 consumer C j sends in a request for a product by executing C j .gand eventually gets the product.

The first task performed by the system is to transform 7.14 and 7.15 by eliminating modal operators and using rule 6.32 in Section 6 ECT Network in Table 7 and event characterizations in Tables 7.1 through 7.3. Universal instantiations of j to j and x to product eliminates quantifiers Finally virtual time points are postulated. The resultant CTL statements are shown in 7.16 and 7.17 . This task is simplified in this example since there is only one unique causal chain for each j.

The ECT network for the PC Solution is shown in Table 7 and the ECT blocks are shown in Tables 7.1 through 7.3. Reader should be able to follow information provided in these tables through analogy with ECT tables presented in OG Solution. The system picks information it needs from these tables during proof construction. The general requirements GR 1 and GR 2 mentioned in Section 7.1 are satisfied for the ECT networks in Tables 7 and Tables 7.1 7.3. However satisfaction of GR 3 does not follow immediately. We have to prove that the search for a delivered product performed by k 0 k

System identifies flow of events in the ECT network in Tables 7.1 through 7.3 that correspond to the flow of events in the CTL statements and puts them into trace formats. These are shown below Trace 7.20 shows the flow of events from the time producer P i senses an order for a new product to the time when the product is delivered to the distributor port D.g i . Trace 7.20 specifies the following On sensing receipt of a message at its port P i .f P i produces a product puts it into the writeMemory of P j .f and sends it off to D.g i which uses it some time later from its readMemory. This validates 7.16 . Notice the two time points dg k t.t p i f.t in 7.20 are incomparable. Thus product deliveries and search for products are not synchronized.

The trace 7.21 displays the causal chain of events from the time consumer C j puts in a request for a product to the time C j has the product. Flow of events in 7.21 is guaranteed only if the search k 0 k

The induction proof goes as follows The search will succeed for the very first customer because of orders put in by the distributor D during its initialization see 7c 5 . Suppose it succeeds in the Nattempt. It will succeed in the N 1 attempt because after the product is used up in the Nattempt say at a port D.g k a new order is put in to producer P k see 7d 10 . Since search continues till a product is found it will certainly succeed when P k responds to that order. It is also possible that the search found an as yet unused product at some other port D.g j . System proves this interactively by validating assertions provided by the user. We will not present the details here. This satisfies requirement GR 3 in Section 7.1. Therefore as per 7.21 every consumer receives the requested product. However to guarantee progress it is necessary to assume the following Axiom i t C i .g t 7.22 

i.e. there is always a customer with a request for product which is the same as saying there will always be new orders for products to be produced. Otherwise business stops and the distributor will just keep spinning around its empty ports executing its polling cycles. Also if there is not enough demand for products then it is possible that some producers just remain spinning. One may redefine the producer CIP to suspend the producer if it keeps spinning for more than a specified amount of time. It will automatically resume operations if demand picks up and an order is later delivered to it.

Comments One of the problems we face in proof construction is we have to resort to proof by induction in situations where a simple Star Operation in a regular expression of an FSP description could validate a requirement. This happens not only because we have no states but also because of essential asynchrony in parallel operations. In most cases the induction proofs are quite trivial and hopefully it would be possible to devise strategies for a system to construct the proofs automatically.

The DP solution network is shown in . There is an environment cell not shown in the figure which starts and stops the game. There is a butler btlr marked B in who distributes forks on request and keeps the food supplied. There are five philosophers P 0 through P 4 . A philosopher can start eating only after he she gets two forks from the btlr. There are only 5 forks on the table btlr.frk j for 0 j

Philosopher P j sends in a request for forks by sending an empty message to the functionPort btlr.f j via P j .gbtlr.f j . If both forks btlr.frk j and btlr.frk j 1 are available then btlr packs the forks into a container in the writeMemory of btlr.f j and sends them off. Once this is done forks will not be available for P j 1 and P j 4 until P j has finished eating and returns the forks. If philosopher P j 4 was eating or P j 1 was eating at the time P j requested the forks or P j 1 was waiting for forks having put his her left fork btlr.frk j 1 on reserve then forks will not be available for P j . In this case btlr puts P j s left fork btlr.frk j on reserve and philosopher P j waits until both forks become available. Once btlr.frk j is put on reserve P j 4 cannot start eating again before P j had eaten. Btlr.frk j is released from reserve only at the time forks are sent to P j .

Every philosopher P j always returns forks after he she finishes eating and goes into his her thinking state T j . After thinking for a while he she gets hungry again and puts in an order for forks. Btlr keeps serving the philosophers in cyclic order P 0 P 1 P 2 P 3 P 4 P 0 . . . until the game ends.

At any point in the game P j can be in one of three possible states E j eating T j thinking or W j waiting for forks . Game starts with all philosophers in state T j with all forks on the table and available to any philosopher and food ready. Philosopher P j who has sent in a request for forks and whose request is sensed first by btlr is served first by the btlr and gets the forks first even if all the philosophers had sent requests for forks at the same time. After P j gets the forks P j 2 may get the forks next if he she had requested them. Then both may begin to eat and go to states E j and E j 2 respectively. Others for k j and k j 2 will wait for forks if they had ordered them and thus go to state W k or just keep thinking if they had not ordered any forks.

The CIPs TIPs ALLEOPs are given in Appendix III. The ECT networks and ECT blocks are shown in Tables 8 8.1 9 9.1 and 9.2. The game satisfies the following two axioms which guarantee progress 

 7.23 says every eating philosopher always eventually returns the forks and goes into thinking state. 7.24 says every thinking philosopher eventually gets hungry. The states E j T j and W j are defined as follows 

Notice the starting and ending timings of actions in the above statements. W j is a composite state of P j and btlr.f j . The initial state for the game is 

 j W j is the only deadlock state here since for any j P j 4 can start eating only after P j has finished eating for 0 j

One may think of states described below as being true at the end or beginning of a polling cycle of btlr. We refer to such states as configurations. Thus j T j and j W j are configurations. User formulates the following CTL statements in terms of the states T j W j and E j using the notation in 7.29 

Assertion 7.30 characterizes the deadlock configuration. In 7.31 eventually either one or two philosophers are eating or all philosophers are thinking. In 7.32 every waiting philosopher eventually eats. As we shall see searches here do not involve finding matching time points but involve chasing the states of philosophers. The ECT networks and ECT blocks in Tables 8 8.1 9 9.1 and 9.2 are used in the proofs below. They are obtained from the traces derived from the ALLEOPs in Appendix III. Here each ECT network has a block which defines the initial state of the network. This specifies truth values of predicates when symbolic evaluation begins. This will change as evaluations proceed from one port TIP to another. If a predicate at a choice point in Table 9 is not specified in the initial state or is not among the predicates evaluated earlier in ECT evaluations or cannot be inferred from definitions then all causal chains emanating from that choice point are included as possible alternates in ECT evaluations. Before the start of ECT evaluation corresponding to any polled TIP the system updates the initial state using results of evaluation made up to that point using definitions of distinguished predicates given in Appendix III III.35 and other definitions supplied by user in the appendix. The convention in ECT evaluation is predicates maintain their truth values until they are changed.

As shown in Table 9 butler ECTs have several choice points and parallel activations but they do not have parallel activation forks. Since all philosophers and the butler run in parallel symbolic evaluation of their ECTs may be conducted in parallel when needed. Let us begin with assertion 7.30 which is the simplest one to prove.

instead of the one shown in Table 9. The predicates appearing in 7.33 have been declared as distinguished predicates they are used to specify initial states and to summarize configurations at the end of TIP evaluations. These initial conditions appear towards the end of the ECT Block 9n in lines 9n 3 5 in Table 9.1. This is the only ECT block in which W j occurs. If there is more than one ECT block with W j then the system should verify given assertions starting from each such W j . After setting the initial state to predicates in 7.33 evaluations of the ECT blocks in Table 9 leads again to W j following the evaluation path containing blocks 9b 9d 9f 9k 9n 9r in Table 9. Block 9n goes to 9r directly without sending any message.

Thus one gets j W j . . . W j since nothing changes. Thus the configuration never changes. System recognizes this after going through evaluations corresponding to one complete polling cycle starting at btlr.f j and ending at btlr.f j 4 . Notice in state W j the btlr does not send any response message back to P j in the ECT block 9n and neither does P j sends message to btlr. As per definitions of guards given in Tables 1 and 2 btlr.f j mR evaluates to true in every polling cycle since no response message is sent back. This proves 7.30 .

Let us now consider the proof of 7.31 . In the following we use z to refer to a configuration at the end of a polling cycle. Applying rule 7.32 CTL assertion 7.31 is converted to z j T j . . . Z Z EZ 7.35 

where one or two philosophers are eating or all of them are thinking. The first task is to find out what the configuration z could be after one polling cycle of the butler starting from the initial state and updating the initial state of btlr.f j port ECT for each j before its evaluation and following all alternate causal chains at each choice point in Table 9 where predicate values are not available. The system quickly finds out that Z EZ as follows In Table 8.1 Block 8b for 0 j

The only requirement here is that message deliveries should occur before message sensing in order for delivered messages to be sensed. If a philosopher P j happens to have sent in a request before btlr polls its port btlr.f j then btlr will sense the message receipt at that port else it will not. It is possible that all philosophers send requests simultaneously none of them send requests during a polling cycle of the butler or some do and some do not. Since operations of the butler and philosophers are not synchronized while btlr polls its functionPorts it may sense a message receipt at some of its ports some times or may not sense any message in a polling cycle or sense messages at all of the ports in a polling cycle. Thus it makes sense to include all possible alternate causal chains that emanate from each choice point in Table 9. In the case of the predicate btlr.f j msg empty appearing in ECT blocks 9f and 9g in Table 9 user supplies the following definition 

System verifies this definition using the ECT blocks in Tables 8 and 9 and uses this definition to determine the branch to be taken at the choice point with the condition btlr.f j msg empty . System uses distinguished predicates given by users to update initial states where necessary. Typically the need for making logical inferences arises in ECT evaluations only while evaluating predicates or while updating initial states.

Assertions 7.35 and 7.36 do not give any criteria for selecting causal chains at choice points in Table 9. Thus the system analyzes all possible causal chains that are consistent with the predicates in the initial state and given definitions at each choice point in Table 9 and finds out that z in 7.35 is equal to EZ in 7.36 . This is summarized by the tree in where a possible configuration after a polling cycle of butler is specified by the states in any one of the branches in the tree. Reader may notice that every branch in satisfies the pattern in EZ either all philosophers are thinking or one or two of them are eating. Thus the configuration after the first poling cycle starting from the initial state satisfies j T j . . . EZ . 7.38 

Therefore in order to prove 7.35 the system attempts to find a configuration Z1 such that EZ . . . Z1 7.39 

holds true by doing the following It firsts creates an existential instantiation of the variable i in 7.36 by setting i j and proceeds as follows The possible initial configurations are

The state j T j is discounted since it has been already considered in 7.38 . Substituting for the negated states in 7.40 as per definitions given in 7.29 results in 2 2 possible initial configurations. For each initial configuration the system finds the initial conditions that should be true for that configuration from the ECTs and definition of distinguished predicates given by user and includes them in the block of initial conditions in Table 9 where appropriate. After doing this for each initial state it evaluates the ECT blocks following all possible causal chains that are consistent with given initial conditions and finds that Z1 EZ holds true for Z1 in 7.39 and EZ in 7.36 for all initial conditions and EZ j W j . This proves 7.35 7.36 and 7.31 .

Notice by doing this the system effectively builds the state diagram for the dining philosophers solution starting from its implementation. Here we did not have to search for matching time points but only for possible configurations reached in polling cycles. Let us now state a Lemma which follows from the state diagram computed by the system. This lemma is useful to prove 7.32 .

This specifies what the states of philosophers P j 4 and P j 1 could be if P j was in state W j . When states are substituted to expand the notation in 7.41 we get 8 possible distinct triplets. The triplets are 

The system easily verifies that the specified triplets are consistent from the state diagram it has already constructed. If the state diagram has not been constructed then the system can verify each triplet by setting up appropriate initial states for W j and evaluating the ECT blocks in Tables 8 and 9 for an arbitrarily chosen j. For each triplet in 7.42 the states not specified in 7.42 can be any state that is consistent with the specified triplet.

The proof of 7.32 follows from the fact that every eating philosopher returns the forks from 7.24 every thinking philosopher eventually gets hungry from 7.25 and when P j is waiting P j 4 cannot start eating because btlr.frk j has been reserved by P j . If P j 4 was already eating while P j was waiting then after P j 4 finishes eating in the first polling cycle that immediately follows the cycle in which P j 1 returns the forks P j will get his her chance to eat. If P j had to wait over several polling cycles of butler because P j 4 was eating for a long time then by Ax 1 7.24 it is possible that P j 1 may begin to eat again after returning the forks This may happen several times before P j gets his her forks. But eventually P j will get his her forks since P j 4 cannot start eating again until P j has finished eating. This is illustrated in . Here the argumentation is similar to FSP argumentation using regular expressions.

Let us consider the cases for T j 4 W j T j 1 and w j 4 W j W j 1 in 7.42 . Assume polling starts at btlr.f j . In the case of T j 4 W j T j 1 the only possibility is that it changes to E j 4 E j E j 1 . Here P j has begun to eat and so the proof ends. In the case of W j 4 W j W j 1 the following holds it follows from 7.35 and 7.36 that there should always be at least one eating philosopher. User provides the assertion 

This assertion is easily validated through evaluations using 7.36 7.39 and the configurations in . In the case of the first possibility on the right of in 7.43 namely W j W j 1 E j 2 by Ax 2 7.25 it has to lead to the following sequence of transitions W j W j 1 E j 2 W j W j 1 T j 2 W j E j 1 T j 2 E j T j 1 j 2 . A similar argument holds for the other possibility on the right of 7.43 . Therefore P j eventually eats. The transitions above are all verified by the system.

For each case the system evaluates ECTs going through successive polling cycles starting with the appropriate initial states until the state E j is obtained in a polling cycle as the inevitable only possible state for P j . In each polling cycle the initial states are updated before btlr.f j port ECT evaluation for each j. This is similar to state search in an FSP. In this particular problem the system may stop repeating its polling cycles when configurations that were reached earlier occur again. This search succeeds in every case. But there are difficulties in this kind of search.

If E j is not reachable then for non finite ALLEOPs it is possible that the system may never terminate unless user specifies appropriate termination conditions or system encounters a contradiction or user stops the system and examines the traces.

Remarks ALLEOP proofs are constructed by deriving ALLEOPs and ECT networks from implementations and by evaluating given CTL assertions over the ECT networks and analyzing the resultant causal chains. The system presents the causal chains it finds in the ECT network in the form of traces. Proof construction is interactive. In all cases user provides CTL assertions to be validated and assertions that may guide causal chain trace analysis. System validates each assertion provided by user and uses already validated assertions to find new traces when appropriate. We have illustrated this proof process above for a few simple examples. To simplify the presentation we did not present for the DP solution the traces discovered by the system during its searches.

There are five kinds of inter related activities in ECT evaluations i Setting up starting and ending configurations that are consistent with given CTL assertions ii finding matching time points between CTL assertions and ECTs when needed iii finding truth values of conditions at choice points in an ECT network iv finding all traces that lead to ending configurations from starting configurations and v analyzing the traces to validate claims in CTL assertions. In the case of finite ALLEOPs user intervention may be needed only for item v above. In the case of non finite ALLEOPs it may be needed for both for iv and v .

The proof theory for these proofs is not a complete proof theory in the sense that the system cannot by itself conclusively proof all provable CTL assertions. This is because of dependence on user interactions in items iv and v above. As we gain more experience it should be possible to automate proof construction to progressively greater extents by identifying ALLEOP patterns that are typical or by establishing correspondences between FSP structures and finite ALLEOP structures where possible. We could not state the proof theory independent of how TICC Ppde is organized how it operates and the computational significance of what is being proven. Before defining the proof theory we define the denotational fixed point semantics for TICC Ppde programming system. This defines the computational significance of what is being proven.

The next subsection introduces criteria that should guide a user to generate CTL assertions to be validated for a given Ap implementation .

Let Ap Requirements Ap Pthreads Ap ALLEOPs Ap ECTs and Ap CausalNet respectively denote the requirements pthreads ALLEOPs ECTs and causalnet of application Ap in an implementation of Ap. The causalnet is automatically generated by Ap SMS as described in Section 8. The pthreads in Ap Pthreads are defined by user. They are pair wise mutually independent except when some pthreads are executed in parallel by cells belonging to a cell group using the same virtualMemory. Also each pthread is a short sequential program containing only the basic programming statements. These make it possible to prove correctness independently for the pthreads. Designers and implementers have the responsibility to provide pthread characterizations. The ALLEOPs and ECTs are generated automatically by the system from implementation specifications.

Let us write Ap CausalNet satisfies Ap ALLEOPs if the causalnet generated for Ap during its run does not violate the event patterns and partial ordering in Ap ALLEOPs and all events in Ap CausalNet occur within specified time limits. SMS described in Section 8 performs this monitoring constantly to check whether Ap CausalNet satisfies Ap ALLEOPs holds true while Ap is running.

Correctness of transactions and the concept of two ports connected by a pathway being well matched were defined in Section 2.3.2. Ap Correct is valid iff and only if all pairs of ports in Ap that are connected by pathways in application Ap are well matched. Ap Requirements are the design requirements for application Ap that were developed before design began and updated since then at every stage of refinement. Definitions of correctness of transactions in Ap definitions of Ap Requirements and specifications of time limits for transaction completions may all be interactively developed by designers and implementers using TICC Ppde. It is of course possible that Ap CausalNet satisfies Ap ALLEOPs holds for an implementation in a given run but the implementation is not correct. To avoid this possibility we would like the following validation criterion to hold true for an implementation 

Clearly truth of 7.44 depends on the set of CTL assertions in Ap Requirements that were validated for Ap implementation . Thus 7.44 and the concept of correctness defined above specify a validation criterion in the sense that it may be used to choose the set of CTL assertions that should be validated for a given implementation. The CTL assertions we validated for the simple examples we presented do satisfy 7.44 for those implementations. Identifying the set of CTL assertions whose validity establishes the correctness of an implementation Ap is guided by 7.44 and definition of Ap Correct . We have assumed here that designers will do this. Eventually it may be possible to complete Ap Requirements at the end of an implementation from definitions of Ap Correct and 7.44 . This is a significant topic for research.

Clearly if validation of an implementation of a system is such that it satisfies 7.44 then it makes good sense to use SMS to verify correctness of performance of that system through dynamic monitoring. In this case it may be possible to use validated assertions as guides to specify strategies to diagnose errors that may occur at run time and may be also use the validated assertions to specify strategies for self correction. These are also significant topics for future research.

The unique feature of TICC Ppde is that it automatically provides the SMS that is needed to dynamically monitor system performance throughout its life time and provides methods to validate system implementations through CTL assertions. Since all validations and correctness checks ultimately depend on ALLEOPs we refer to the proofs presented here as ALLEOP proofs.

During the validation process while finding matching time points the system may identify events that are incomparable as per ALLEOPs but should be either synchronized occur at the same time or coordinated one of the events should always occur before another as per CTL assertions. A pair of events should be candidates for such synchronization or coordination only if synchronization and coordination do not negate any of the validated CTL assertions in which the events appear. We introduce in the next subsection ad hoc synchronization and coordination methods that may be used in TICC Ppde to introduce needed synchronization and coordination into an already completed implementation when necessary with no need for reprogramming.

The principal task of system implementation in TICC Ppde is not programming. Programming pthreads and conditions are relatively trivial mechanical tasks. The principal tasks that are difficult are i setting up the TICC network ii defining TIPs iii characterizing the needed pthreads and iv identifying the CTL assertions that should be validated. The structure of TICC networks provides a medium in which alternate organizations may be tested and explored. The TICC paradigm shifts the nature of the art of system design and implementation from the art of programming to the art of system decomposition i.e. identifying needed subsystems and specifying interactions among them and the art of proving correctness.

Limit Testing Branching trees of ECTs and partial orderings of time points may be used to validate varieties of useful system properties. One useful property to prove in real time systems is that the required partial orderings of time points is always preserved in spite of variations in TIP execution times. This is done through limit testing.

For the TIP at a port C.p define time bounds is the minimum time interval needed to complete execution of the TIP at p starting from the time message was delivered to p and is the maximum time interval that might be needed 

Suppose there were two traces one leading to port C.p and another leading to port D.q and cells C and D were not connected by any causal chain. Let it be required that occurrence of a pair of events xP tP and xq tq at ports C.p and D.q respectively should always be such that t

Ad hoc Coordination Let us now assume that condition 7.45 was not satisfied. How may it be enforced without having to do extensive reprogramming To be specific let us postulate two cells Cand Cthat have ports C.fand C.fthat are not connected to each other by a causal chain in the ALLEOPs of an implementation. Suppose correct operation of the system required that the TIP at C.fshould be executed only after the TIP at C.fhad been executed. Let us write this requirement as

Install two other ports C.g and C.f define C.f C.f as a port vector and install a branch connecting C.g to C.f as shown in . Now Cmay service a message at C.fonly after C.fhas received a signal from C.g. C.g sends this signal after executing C.f tip . The TIPs at C.fand C.fwill have the forms 

With this C fand C fwill be cycle synchronized and the requirement will be always satisfied. Indeed this arrangement may be used to coordinate not just pairs of ports but to cycle synchronize group to group interactions as well as in

using group to group signal exchange described in Section 8. Here the only modifications needed in the implementation in order to incorporate cycle synchronization are i setting up the needed group to group pathway and ii changing the TIP definitions. The rest of the implementation remains unchanged. Arrangement here is very similar to the way time signals are used in asynchronous hardware systems to coordinate subsystem activities.

Ad hoc Synchronization In TICC Ppde polling cycles of different cells are not synchronized to each other. Yet at times it may be necessary to synchronize servicing of ports not connected to each other by pathway chains and not in a cell group. We will call them isolated cells. Thus one may wish to enforce the synchronization C.f tip . . . C tip t 7.48 

Here each cell C.g transmits a signal to itself through the self loop pathway as soon as it receives a message via C.f. A synchronized signal is delivered to all C.g for 0 j

Synchronization and coordination are done here as an after thought. These kinds of ad hoc synchronization and coordination cannot be done in calculus in Actor systems in CSP or any other currently available parallel programming paradigm without having to do extensive reprogramming. We will conclude this section with some comments on NFSP ALLEOPs that may contain an arbitrary number of nodes.

A simple network for this is shown in . It has n 3 cells. Each cell C i for 0 i n is connected to a csm Communications System Manager . When a cell is installed a private pathway to its associated csm is automatically set up from a designated csmPort subclass of generalPort of the cell. Any cell that needs to dynamically install new cells or pathways will send service request messages to its associated csm by invoking the appropriate cell installCell . . . and cell installPathway . . . methods. These methods are provided by the TICC Ppde system. A cell Y may also send a request to its csm to destroy Y or destroy a pathway. Cells use csm to install other cells and pathways because these are expensive operations taking 100 to 250 microseconds. After sending a request to csm via its csmPort a cell may proceed to service its other ports and get back to csmPort in an ensuing polling cycle to receive the response from csm and take appropriate actions. The csm services a request only if the requesting cell has the appropriate privileges. In any case the csm sends back to the requesting cell a response message.

When application starts the network in contains only the cells C 0 X and csm. X activates C 0 by sending a message to its functionPort C 0 .f. Initially the csmPort of C 0 is tuned to agent a1 as shown in . When activated as part of its initialization C 0 requests its csm to install C 1 and connect its port C 0 .g to C 1 .f via a pathway. When C 0 gets a response from the csm that the task has been completed it disconnects C 0 .csmPort from agent a1 sends a message via C 0 .gC 1 .f see and then suspends itself thereby releasing its assigned CPU. The message sent to C 1 .f will contain a condition which is used by C 1 as described below.

The message sent to C 1 .f activates C 1 to run in one of the available CPUs. When activated C 1 in turn does the same thing tuning its csmPort to agent a1 installing and activating the next cell C 2 then disconnecting C 1 .csmPort from a1 and then suspending itself unless the condition in the received message stops it from doing so. Thus each newly installed cell continues to install and activate yet another cell and suspends itself unless the received condition prevents it. This causes the network to grow until the condition stops it.

When the condition stops the growth say at cell C n for some n 1 instead of installing a new cell C n responds to the message it received at its port C n .f by sending a reply to C n 1 .g and then destroys itself thus releasing its assigned CPU and destroying the pathway C n 1 .gC n .f. At the time the response message from C n .f is sensed by C n 1 .g C n 1 resumes its suspended operation in one of the available CPUs repeating what C n just did. Thus each newly installed cell completes its transaction and destroys itself one by one until C 0 X and csm are the only cells remaining in the network. At that point C 0 responds via C 0 .gX.g to the service request it initially received from X.g and thus completes the transaction.

It is not important to show details of definitions in this example namely facilities for dynamic creation and destruction of cells and pathways TIPs ALLEOPs and traces. It is sufficient to note that the following causal sequence would occur in the trace. It starts with the message sent by X.g to C 0 .f continues up to C n .f and then begins the reverse process. The causal chain is shown below 

Communication events during progressive completion of transactions with new cells destroying themselves

Thus ALLEOP for this would clearly not be a finite ALLEOP yet it would have a finite description. In general the ALLEOP associated with a dynamic network can be general recursive.

We now proceed to present the group to group message transfer protocol that includes i SMS facilities for generating a dynamically growing causalnet for an application while running in parallel with the application ii facilities for data dependent security checks where a message is delivered only to ports that satisfy a priori specified security requirements and iii facilities for automatic synchronization and coordination.

CTL assertions contain causal chains of events with quantifiers V for all and 9 there exists which may range over event instances and virtual time points contain modal operators always and eventually logical connectives parallel operators and alternate operators and causal connectives causes immediately causes . . . causal chain and . . . immediate causal chain . An event x t may be a condition state that became true occurred at time t x t being a condition state that became false did not occur at time t or a t signifying that execution of action a was completed at time t or a t signifying that execution of action a started at time t or a t signifying that execution of action a was not completed at time t or a t signifying that execution of action a did not start at time t where action can be any condition programming statement or any program or a communication event of the form p t signifying that port p started to send a message at time t or p t signifying that a message was delivered to port p at time t it being possible for communication events also to appear with negations.

When a CTL assertion is given to the ALLEOP proof system it first determines the set of starting events and the set of ending events in the CTL assertion. Then it specifies initial conditions for the appropriate ECT network it should search for causal chains that match with the CTL assertion. It searches the ECT network with specified initial conditions to find all causal chains that match with the starting intermediate and ending events in the CTL assertions setting up correspondences between the timings of the starting events as stated in the CTL assertion and the virtual time points specified in the ECT network and displays the matching causal chains found in the ECT network to users as trace statements as illustrated in the examples discussed in this section. This search simply involves pattern matching between events specified in the CTL assertion and events in the ECT network. In the case of finite ALLEOPs either the search will succeed or will fail. If it is fails it will be possible to find out why it failed.

At this point it has to be verified whether the matching causal chains so found satisfy all conditions specified in the CTL assertion. Here also user intervention may be necessary to guide the system in the verification process. The conditions in CTL assertion may specify mutual exclusion coordination ordering of events synchronization timing uniqueness and or guaranteed occurrence of events. These proofs are called FSP proofs.

Non FSP Proofs These proofs are needed if the ALLEOP is not a finite ALLOP or the proof pertains to values of variables occurring in a program. In the case of non finite ALLEOPs user intervention may be necessary to stop the search for matching causal chains if it does not succeed after a sufficient amount of time. Also non FSP ALLEOP proofs may require mathematical induction to be used to construct proofs. Some examples of proofs by induction were shown in this section.

It may be noted ALLEOP proofs do not involve inferences on CTL assertions but only symbolic evaluation of CTL assertions over ECT networks. ALLEOP proofs may require inferences in simple propositional logic to determine truth values of predicates occurring at choice points in ECT networks using initial conditions and predicates already found to be true in the search for causal chains. It is this feature that enables computers to be effectively used to interactively build ALLEOP proofs for CTL assertions.

Proving Connectness of Pthreads Proving logical characterization of pthreads will also require inference in propositional logic. Since pthreads are likely to be short programs with no ornamentation for coordination and synchronization specifications and no message exchanges in pthread definitions it is possible to prove correctness of pthreads interactively. Pthreads that are executed by cells in a cell group in parallel in the same virtualMemory may contain mutual exclusion locks and data exchanges through scratchpad. These pthreads should be proven jointly and are a little bit more difficult to prove.

Using ALLEOP models to prove CTL assertion through ECT evaluations and the built in facility for the Self Monitoring System SMS are integral parts of TICC Ppde. They are unique to TICC Ppde. Without discussing how the infrastructure for SMS is integrated with message exchange protocols this presentation will be incomplete. We do this in this section taking a variant of the group to group Das pathway as an example.

For dm pathways group to group message exchange delivers a joint service request from parent cells of generalPorts in a port group in one multiprocessor of a computing grid to different port groups of functionPorts in different other multiprocessors in the grid . Response messages are sent in sequence by the functionPort groups in a multiplexed mode. Response messages are gathered together by the generalPort group that sent the service request with the provision if received messages were not consistent with each other then a re computation may be requested. Each multiprocessor in a grid dynamically constructs the SMS causalnet that pertains only to cells operating in that multiprocessor. Dm pathways use 4 state hardware agents 4 state software ports and use hardware routers and switches as well. Thus the protocol is more complex than the one described here.

We have provided for three types of completion signals for three modes of message transmission in sm pathways s for send mode f for forward mode and h for halt mode for halting computations. The halt mode is used only by generalPorts. In the halt mode no service request message is sent and the pathway may be dismantled. Cells in a cell group coordinate types of signals they send by exchanging information through the scratchpad of the virtualMemory M in .

In shared memory environments as mentioned earlier the read write memories of the virtualMemory of the pathway are switched in the send mode and not switched in the forward mode. The choice between sending and forwarding is determined by the TIP. In distributed memory message exchanges there is no forward mode or halt mode instead there are end of data signal e and abort signal a to dismantle a pathway and cause the network routers and switches to go to their active states waiting for new signals to start a new dm pathway establishment process.

The modified Das pathway for group to group message passing is shown in . Message is exchanged between a group of generalPorts G g g . . . g and a group of functionPorts F f f . . . f . The pathway has four agents a0 a1 a2 and a3. They are connected to each other by h branches as shown in the figure. All the four agents are attached to the virtualMemory M. To make the diagram clear a2 and a3 are shown in in an offset attached to M. Think of M as a three dimensional object. The agent a0 is tuned to port group G a1 is tuned to port group F a2 is tuned to the functionPort eb.fand a3 is tuned to the functionPort eb.fof the eb cell which is the EventBuilder cell. Agent a0.nxt a1 a2 and a1.nxt a0 a3 . The functionPort vector eb eb.f is attached to the eb cell. We will soon see the task performed by this cell. Each eb cell may service several distinct pathways connected to each pathway through a separate pair of ports in a functionPort vector and associated agents like the ports eb.f eb.f and agents a2 and a3 in . An application may have several such eb cells. Each eb cell communicates with a small collection of ea cells EventAnalyzer cells associated with it.

Each port in port groups G and F has associated with it the protocol that is needed to transport a message from one end of the pathway shown in to its other end. When a parent cell of a port in a port group either G or F completes its computation and is ready to transmit a message the cell begins executing the protocol associated with that port. G and F cannot both transmit messages at the same time. Thus all parent cells of ports in a port group will begin to evaluate the protocols at their respective ports in parallel at time points which are mutually incomparable. Agents on the pathway coordinate message transmission.

Agents ai for i 0 1 in have each three attributes defined for it one is ai.selectedPort which could be any port tuned to ai the second one is a Boolean attribute ai.dC dC for deliveryComplete which is initialized to false the third is a vector called completion signals Vector ai.csV which has one vector element for each port that is tuned to ai to store signal received from that port and one element for signal received from ai.nxt 1 . Each element assumes one of four possible values 0 ai.csV j c f h ignore 0 c c for completion signal used to send a message f for forwarding a message and h for halt for 0 j

GeneralPorts in G send a joint service request to functionPorts in F. The generalPort group is G C.g 0 i

When a parent cell Cis ready to send a message it immediately executes C.g prefix in parallel with the parent cells of other ports in group G. This parallel execution is not synchronized different parent cells Cmay do this at different times. While executing C.g prefix Cfirst sets a0.selectedPort C.gif it has not been already set then initializes the vectors a0.csV and a1.csV if they have not been already initialized the last elements of these vectors are not initialized. Cthen sets a1.dC false if it is not already false. It is possible that two or more cells Cperform the same initialization simultaneously. There will be no mutual interference no pthread lock is needed here.

After initialization each cell sends one of three possible completion signals x c f h 0 to its port C.gand the port forwards this signal to a0. After this Cevaluates the expression a0.selectedPort C.g a1 dC . This causes all cells Cother than the parent cell of a0.selectedPort to wait until a1 dC becomes true thus they stop executing the protocol any further. When a1.dC becomes true each cell Cmay begin to process its next port in its servicing order. Meanwhile before a1.dC becomes true while all the other cells are waiting for a1 dC to become true the parent cell Cof a0.selectedPort begins to execute C.g suffix this will be the only cell executing C.g suffix .

The agent a0 will expect to receive signals x 0 from each C.g G for which a0.csV j ignore and one signal c x 0 for a0.csV n 1 from a0.nxt 1 a2. When a0 receives signal x 0 from port C.g it will know that cell Chas completed its computation. When it receives signal c 0 from a2 it will know whatever cell eb did during the previous message exchange through the same pathway has been completed. These signals become the arguments of the agreement protocol function AP1 in the guard a0 AP1 a0.csv 0 . . . n 1 in 8.2b . Cexecutes this guard since it is the only cell still continuing to execute the protocol. The guard evaluates to true only when all its elements are 0 i.e. after it has received all the expected signals. It is executed repeatedly until it becomes true. When it becomes true the parent cell cof a0.selectedPort executes C.g suffix body . The suffix body is the same for all generalPorts C.g in G. So it does not matter which generalPort is chosen as the selectedPort. We will soon see what this suffix body does. Before defining g suffix body we have to define some more variables and methods. They are all associated with agents and ports in the sm pathway we do this now.

TICC Ppde has two default security definitions In one every port in F receives message. In this case there is no security check. In the other a security level M.security a security mode M.rd msg .mode and for each f F a security level f.security are defined. A message in M is delivered to port f if and only if M.security f.security M.rd msg .mode . Messages may thus be delivered to less secure ports by setting the M.rd msg .mode high. Cells have privileges. A cell may request other cells or pathways to be dynamically installed only if it had the requisite privileges. A cell may temporarily delegate its privileges to another cell. A cell may also temporarily delegate the security status at one of its ports to a port of another cell if both cells had appropriate privileges to do so the delegated security status being associated with a condition that specifies when the delegated security should be automatically revoked. The condition could be based on the number of messages exchanged using the delegated security status. This security system is built into the prototype TICC and TICC Ppde.

Other Pathway Variables and methods The variable a0.ccS holds the value of the composite completion Signal computed by the second agreement protocol method AP2 used in 8.4 i below. AP2 is defined in 8.3 . The method a0 resetPathway is used in 8.4 to reset the sm pathway in which a0 appears to its initial state. The method exception f issues an exception at port feF to warn users about security failure at port f. The method a0 swMem switches the read write memories of a0. The method p timeStamp sets the time stamp at a port p in the local time of the parent cell of p indicating when the delivery signal was delivered to p. The condition p active checks whether the parent cell of p is already running in a CPU the method p activate activates the parent cell of p in an available CPU. As mentioned earlier TICC Ppde itself manages all CPU assignments and cell activations.

We are now ready to define g suffix body It uses the second Agreement Protocol function a0 AP2 a0 csV 0 . . . n 2 . Notice this does not include in it the signal a0 csV n 1 received from agent a2. It only examines the completion signals that a0 has received from the generalPorts in G and sets the composite completion Signal a0.ccS a0 AP2 a0.csV 0 . . . n 2 where

Associating the same suffix body with every g G simplifies coordination of dynamic changes to the port group G ports may be added to or deleted from G dynamically before new transactions begin. Let us now consider what g suffix body does 

 8.4 i If a0.ccS h then the pathway is reset and a1.dC is set to true. In this case no message is sent. If a0 ccS h then Cbegins to execute the rest of the protocol starting with 8.4 ii and at the end of this execution sets a1.dC true. The following happens 

 8.4 ii Security check is first performed and the vector a1.csV is updated with ignore signals for insecure functionPorts and exceptions messages notifying the security failure are generated for the insecure ports. If all functionPorts are insecure then protocol execution is abandoned. Else it continues.

 8.4 iii First resets the signals in a0 csV n 1 and a1 csV m 1 that were previously received from agents a2 and a3. Agent a0 then does the following If a0.ccS c see 8.3 then the read write memories are switched and a start signal s is sent to a1 and signal c is delivered to eb.f1 via a2 else the read write memories are not switched and a forward signal f is delivered to eb.f and signal s is sent to a1. In either case a signal delivery time stamp is set at eb.fin the local time of eb. This time stamp is interpreted by the eb cell as the time of message dispatch. It is referred to by eb.tin 8.6 below. Since all eb cells are synchronized to a standardized qlobal time this message dispatch time will be a global time.

 8.4 iv The protocol first checks whether for each secure functionPort f j F whether its parent cell has been already activated. If not it activates the parent cell. Cell activation in TICC Ppde is relatively expensive. It takes about 2.5 to 3.0 microseconds to activate a cell in a 2 gigaHertz computer. The TICC subsystem that manages process and pthread activation was implemented by Mr. Rajesh Khumantham. This is the reason the statement describing this operation has been separated out in 8.3 iv . Normally activation is done only once the first time a signal is delivered to a port. Separating this part out enables delivery signals to be sent to all secure ports in quick succession. After sending delivery signals to all secure ports agent a1 delivers signal s to port eb.fvia agent a3 with a time stamp and then sets a1 dC to true eb interprets this time stamp as the message delivery time denoted by eb.tin 8.6 .

If CCPs are implemented as machine instructions and hardware assist is available to set time stamps as discussed in Section 10.1 then signals may be delivered to secure ports with less than 3 nanoseconds separation between successive ports in a 2 gigahertz CPU estimated . For each secure functionPort f the signal delivery time stamp set at port f is the local time of its parent cell which may not be synchronized to the standardized global time. When message delivery is completed to all secure ports or if protocol execution is abandoned a1.dC is set to true. One may organize processing of the delivered message by parent cells of functionPorts to begin only after a1 dC becomes true i.e. after message has been delivered to all secure functionPorts. This may be implemented by modifying f mR and g pR as follows 

Meanwhile when eb senses signal c f at eb.fand signal s at eb.f at local times eb.tand eb.t respectively it installs the following communicationEvents associated with the group to group message delivery into a growing causalnet for 0 and for 0 8.6 

as specified in equation 8.21 and after integrating them with the causalnet sends back completion signal c to both a0 and a1 by executing the protocols shown below at eb.fand eb.f respectively eb.f c a2 c a0 and eb.f c a3 c a1 . 8.7 

All of this is done while parent cells of functionPorts D.f in are processing the response to the service request that was just delivered to them. Since no two eb cells install communicationEvents at the same place in a growing causalnet there will be no mutual interference among different eb cells when they perform their activities in parallel.

Since the eb cell has access to the virtualMemory it could access a1.csV and identify the functionPorts to which message was delivered. Using the ALLEOPs it could determine the location in the growing causalnet where event instances should be installed. Using these data the eb cell installs communicationEvents into the causalnet.

The causalnet fragment that is so installed into the causalnet is shown in . Here dispatch times for gfor 0 i

It may be noted the message sending and message delivery event instances would have all been anticipated by the eb cell from its knowledge of the ALLEOPs. Indeed if anticipated event nodes do not appear with in a priori specified time limits then an ea cell EventAnalyzer cell described below that constantly monitors the growing causalnet in parallel with the eb cells would issue an error report to observers about a possible system failure. Since the eb cell has access to the virtualMemory of the pathway tuned to eb.fand eb.f while installing the event instances it could even check conditions that should hold true in the message sending and receiving cells to verify that the relation R srm rm defined in Section 2.3.2 holds true in the just completed transaction. However this may unduly delay message transmissions and may not be practical at run time. But this can be done in a test mode.

When parent cells of functionPorts in F which received a service request sense message delivery signal at the functionPorts f they execute the associated f tip to send back a response message by sending a c f signal to a1. At this point a1 would be expecting signals only from port eb.fand from all the secure functionPorts since ignore signals had been already set in a1.csV for the insecure ports. Protocol for sending forwarding back the reply message is similar to the protocol shown in 8.1 8.2a 8.2b and 8.4 with the following differences a1 selectedPort is set to the first secure port in a1.csV i.e. the first port f F for which a1.csV j ignore. No security checks are done for delivering the response to the generalPorts in G every port in G receives the response.

During transport of the response message a1 sends signal s to a0 and signal c f to a3 only after it had received completion signals from all secure ports D.fand completion signal from a3 as described in 8.7 . Agent a3 forwards signal c f to eb.f to inform eb that the response message is being dispatched to the generalPorts in G. After delivering the response message to the generalPorts a0 sends signal s to a2 which forwards it to eb.f to inform eb that the response message has been delivered back to the generalPorts in G. When eb senses signals at both ports eb.fand eb.f it installs the communicationEvent instances shown in for each secure f at appropriate places in the growing causalnet. After completing this installation eb sends a completion signal c via eb.fand eb.fto agents a0 and a1 using protocols shown in 8.7 . The combined causalnet fragment of is shown in .

We have already discussed ndFSMs for agents a0 a1 and ports g and f see . All agents and ports in sm pathways are identical 2 state ndFSMs. Clearly the protocol is simpler for point to point communications since there are no selected ports and ai.csV for i 0 1 will each have only two elements. The protocol uses at most 6 m 1 CCPs where m 1 is the number of ports in F. This does not count the n 1 CCPs executed in parallel by the parent cells of C.gto send completion signals to a0. Group to group communications are relatively expensive but still far cheaper than conventional group to group communications.

The SMS network Event Builder eb and Event Analyzer ea cells As we said earlier an application may have several eb cells in its SMS network. No two eb cells will service the same sm pathway. Each eb cell may service several distinct pathways updating portions of causalnet stored in virtualMemories Mlike the one in . One pair of agents attached to Min is shown in an offset think of Mas a three dimensional object. There are two non intersecting pathways here that share the same virtualMemory M. This violates pathway rules. However it is permissible here because these two pathways will never work simultaneously in parallel and also ea cells will only read contents of M never write into it. Thus ea cells will not send back reply messages to eb cells but will only send back acknowledgement signals. They will send back acknowledgement for receipt of delivery signals immediately after sensing the delivery signals at their functionPorts. Since eb cells service only one functionPort vector at any given time and ea cells service only one functionPort at any given time there will be no interference. Of course there will be several groups of ea cells each collaborating with a different eb cell. A given ea cell may simultaneously use several distinct causalnet virtualMemories M s through functionPort vectors attached to it.

The two pairs of agents one pair in each pathway containing the virtualMemory Min do not communicate with each other but communicate with distinct functionPorts of the two ea cells in that figure. When the ea cells receive delivery signals at their functionPorts they examine newly written contents of M written there by the eb cell after first acknowledging receipt of delivery signals. Other agents may similarly be attached to M in order to communicate with cells that are used to display contents of M. These display cells will again only read Mand not write into it. Agents on Mconnected to the display cells will be tuned to ports of the display cells thereby enabling parent cells of the ports to read contents of M but they may not be used to transmit signals to any other agent on Mor any other port. Thus they will not be used for communications via M.

The ea cells check for consistency of the growing causalnet with the ALLEOPs and look for occurrences of a priori specified event patterns in the causalnet to alert observers regarding those occurrences every time Mis updated. It is possible that consistency checks are performed by eb cells themselves before event installations in the causal net and only recognition of event patterns is done by the ea cells. In most cases the watched for event patterns could be specified by regular expressions that use ALLEOP nodes as terminal symbols.

Comments This kind of use of TICC Ppde calls for a practically unlimited supply of processing units CPUs . Eb and ea cells are however specialized cells. Eb and ea cells do not perform general computations and ea cells do not need time stamping at signal delivery times. They only check causalnets against ALLEOPs. CPUs for the eb and ea cell may be simpler than other general purpose CPUs. With the advent of multicore chips and nanotechnology all needed CPUs should soon become easily available. TICC Ppde not only provides a natural environment for using arbitrary numbers of processing units but also effectively makes use of available processing units to build automatically the Self Monitoring System SMS network of ea and eb cells for each application without interfering with efficiency of parallel program execution. It is possible to automate organization of SMS network needed for an application based on its design specifications. We have not does this as yet.

ALLEOPs specify event patterns that may occur when an application is running. Deviations from specified patterns are construed as errors by SMS. It is of course possible that event patterns in the causalnet could be correct while computed values are wrong. However this possibility is precluded by the correctness proofs generated during and after implementation as discussed in Section 7.5.

So far we have used the convention that replies are sent through the same pathways through which service requests were sent. At times this may contribute to complicating the pthreads and increasing the number of ports attached to a cell when different sequential computation are spawned by one cell in different other cells. It may also contribute to decreasing the efficiency of sequential computations. The modified Das pathway in avoids this problem pathway augmentations for SMS using eb and ea cells are not shown in this figure in order to keep the figure simple .

Here the ports in the generalPort group G in send their joint service request message to ports in the functionPort group F. When G does this its ports get reset to receive a reply. It will receive this reply from the ports in F. Ports in F receive the request sent by ports in G and send their joint reply which could be viewed as another service request to ports in F. When F does this its ports get reset to receive the next service request message from G. This clockwise passing of messages proceeds through the pathway loop in until at the end ports in G receive reply from ports in F. G may send its next service request to F only after it had received this reply from F. One may attach arbitrary numbers of agents to the virtualMemory in . We refer to the modified Das pathway in as ring pathway since it has one virtualMemory and several agents associated with it organized into a ring. This arrangement is useful to execute sequential computations in a parallel network. Cells in any one group around the compound pathway work in parallel when they process received messages.

It should be clear that the simple pathways in cannot communicate with SMS while transmitting signals via the pathways. The structure of these pathways for enabling them to communicate with SMS is shown in where the object marked S is the signalMemory used by the communicating ports. This signalMemory may also contain compiled codes for protocols used by the communicating ports. Agents a0 and a1 play the same roles as the agents in and agents a2 and a3 play the same roles as corresponding agents in . Similar modification also applied to the pathway in . Thus there are no pathways without some memory embedded in it.

One may define a top level Sm Pathway class and define protocol for the Sm Pathway class as a parameterized macro which is used to compile a distinct protocol for each port p connected to a Sm Pathway instance smP after substituting the parameters that define the sm pathway smP for the corresponding arguments as in a macro definition. For example parameters for any point to point or group to group sm pathway at cell Cand generalPort gfor 1 i n shown in will then be 012 1 8.8 where S is the name of the security function and a1 a2 are the agents tuned to a0 eb.f1 is tuned to a2 and a1 sends delivery signals to the functionPorts f. Parameters for the protocol from a cell Dwith port fshown in will be 103 1. 8.9 The protocol definitions shown in 8.1 8.2a 8.2b and 8.4 i through 8.4 iii may all be combined into one definition with appropriate arguments for the parameters.

For any sm pathway smP the compiled protocol code for each port p connected to smP is installed in the signalMemory component of the virtualMemory of smP at the time the Sm Pathway instance smP is installed in a TICC network and the attribute p.protocol is set to the starting address of this compiled code in the signalMemory. One may then use the eval instruction defined in Section 10.2 to invoke and execute this compiled code by using eval p.protocol . It may be noticed no dynamic state checking or signal checking are necessary for the components in such pathways since all components that exchange signals are always tuned to each other.

This parameterized protocol definition will define protocols for all sm pathways whether it is a point to point or group to group pathway. The same parametrized protocol definition may also be used for all ports connected to the one way ring pathway shown in . Thus TICC Ppde defines protocols for all sm pathways. Similar parameterized protocol definitions are also used for dm pathways but the protocols are a bit more complex. We will not discuss the details here.

It may be noted TICC Ppde pathways are different from RESTCLK pathways Das 19 and also different from the original TICC pathways U.S. Pat. No. 7 210 145 B2 even though at an abstract level they all look the same. The two important differences are i change in protocol execution mechanism and ii SMS mechanism embeddings in pathways.

Differences between RESTCLK Das 19 and TICC Ppde pathways RESTCLK pathways have no communication protocols defined for them and do not use CCPs for signal exchange. Mechanisms used to transmit signals over RESTCLK pathways are more complex than those used in TICC Ppde. RESTCLK does not guarantee message deliveries and RESTCLK message delivery latencies are several orders of magnitude higher than in TICC Ppde. Also RESTCLK pathways cannot be used to perform ad hoc synchronization and coordination with predictable timings or be extended from shared memory to distributed memory communications without using a conventional local area network.

These differences make guaranteed parallel simultaneous message exchanges and efficient reliable parallel program executions impossible in RESTCLCK. Lack of predictable timings of events makes it impossible to embed SMS mechanisms into RESTCLK pathways to achieve results similar to those in TICC Ppde.

Differences between Original TICC and TICC Ppde pathways In TICC Ppde each cell executes is own pathway protocols immediately after a message becomes ready. There are no message scheduling delays. In the original TICC pathway protocols are executed by specially installed dedicated communication processors. Cells send requests to communication processors to send messages and these requests wait in an input queue until the processors attend to them in the order they are received. This can increase message exchange latency in the original TICC to values as high as 6 microseconds and unfortunately this makes latencies unpredictable even though message deliveries are guaranteed. In TICC Ppde message exchange latencies are always precisely predictable and are always as low as a few hundred nanoseconds.

Even though differences between the original TICC pathways and TICC Ppde pathways are quite small their consequences to parallel programming are extremely significant both for realizing high execution efficiencies and for adding new and dramatic self monitorinq capability to parallel programs.

For these reasons TICC Ppde pathways and protocols are being claimed here as a new invention. There are no other communication mechanisms in published literature or in patent literature with capabilities similar to those of TICC Ppde communication pathways.

It is possible that some day we might implement software systems that understand what they do. We speculate here capabilities such a software system should have in the context of SMS in TICC paradigm. This will require that we incorporate into Event Analyzer cells ea cells a general capability to learn patterns of causal chains that occur in causalnets and are of interest based on a set of general seed patterns that are built into them. Learning will specialize and refine the seed patterns. Ea cells may do this through interactions with their environments and interaction with applications themselves. Ea cells also of course need a capability to represent learned patterns. They may use for this purpose the same kind of grammar that was used to define the seed patterns. These grammars will use ALLEOP nodes as non terminal symbols. One may think of these patterns as abstractions of causalnets that specify activities that occur in an application and are of interest. One may even have an abstraction hierarchy of patterns of patterns. When a system recognizes occurrences of these patterns uses them to communicate and direct its own computations and refines them a system behavior might manifest that is akin to understanding . Capabilities of this kind are necessary to build systems that can diagnose and repair themselves. In the long run they may lead to self understanding software systems. The SMS in TICC paradigm provides a context to investigate problems in the design of such systems.

We would like to hypothesize that our cerebral cortex does this kind of dynamic pattern analysis in our brains. Evolution has endowed us with certain innate seed patterns built into us Patterns for face recognition voice recognition odor recognition motion recognition finger coordination vibration sensing hand eye coordination and leg body coordination are examples of such seed patterns. Recognized patterns dynamically govern the behavior of organisms both internal and external and also govern how the patterns themselves are refined. Biologists would agree these innate capabilities even in primitive forms have had enormous influence on species survival. They are wide spread in varieties of insect and animal species. With learning these innate capabilities are improved and specialized and give rise to bewildering multitudes of manifestations we see in Nature. Capacity to learn varies from species to species. When a human sees an image events occur all over the human brain. We posit recognition of the image seen is a continuing process which occurs as a result of dynamic identifications by the cerebral cortex of on going patterns of causal chains of events in the brain while the image is being seen. Here the identified patterns influence and direct the on going recognition processes in parallel with those processes. These kinds of recognition processes cannot be described in terms of combinatorial aggregations of events or patterns as many pattern recognition works have approached this problem 47 .

As discussed in Section 3.3 TICC network together with CIPs TIPs and polling cycles defines the abstract design for an application. Once the abstract design is obtained for an application performing CIP and TIP refinements and message subclass definitions needed to complete the implementation of the application is relatively straight forward.

The difficult tasks in getting an abstract design are i defining the TICC network for an application ii defining CTL assertions specifying requirements for the application and iii interactive validation of designs. As discussed in Section 3.3 one may design TICC network by postulating compound cells and network refining them iteratively. This has to be based on designers understanding of components that an application should have and what communication pathways they need to communicate with each other. There are no systematic methods that could specify how this might be done. TICC Ppde only provides facilities to represent specifications given by designers and use them for model construction and analysis. But facilities provided by TICC Ppde to document design through network refinement provides some help.

Consider for example the abstract design of a parallel software system to support manage and organize corporate affairs in a corporation. Let us call the application CAMS Corporate Affairs Management System CAMS for short. One may start system decomposition with the top level compound cell called CAMS with external ports CAMS.g CAMS.f and CAMS.i and decompose CAMS into its component compound cells CAMS PRESIDENT CEO CFO MM Marketing Manager PM Personnel Manager VP R D R D Lab Factories DC Distribution Centers CR Customer Relations CC Corporate Communications etc. 9.1 each such component coming with three ports attached to it just like CAMS had three ports. One may then specify communication pathways attaching as many additional ports to the component compound cells and to CAMS as needed. All ports attached to components in CAMS will be internal ports of CAMS and all ports attached to CAMS will be external ports. The pathways might be for example 

At this point one may unwrap the encapsulation of CAMS by removing all of its external ports and removing the wrapping allowing its internal ports to be directly connected to ports to which the external ports might have been later connected. After unwrapping one may iterate network refinement and unwrapping for each component compound cell of CAMS and continue this network refinement process until all compound cells have been fully refined to networks of simple cells. A simple cell being one which cannot be further network refined. This would specify the TICC network for CAMS. One may retain encapsulation for compound cells which may be used more than once or used later in other systems. During network refinement designers may define port vectors and port groups as needed. Let us call the resultant TICC network CAMS network .

While doing this designers should begin specifying CTL assertions that characterize requirements that this network should satisfy. It is not possible to specify design methods for any of these steps since design would depend on designers understanding of what is needed in CAMS and how networks are interpreted in TICC Ppde. Let us call the requirements CAMS requirements .

The resulting CAMS network is something like an organization chart for the corporation but specifying information on synchronizations coordination scheduling forks and joins etc. One may specify CAMS pollingCycles and CAMS priorityList at this point if known. Let us use CAMS cells CAMS ports CAMS pathways to refer to the cells ports and pathways in the CAMS network .

TICC Ppde maintains a name space of all components defined in CAMS network and TICC Gui maintains documentation of all network refinements and can display any part of the resultant network anchored on any component on demand and also display known properties of the components. Each simple cell C in CAMS network will automatically have the default CIP in 2.1 assigned to it as its C CIP .

At this point simple cells C in CAMS network may be classified according to number of ports of each kind C has and the initialization routine it should have for its C CIP all cells having the same number of ports of any given kind and the same initialization routine belonging to the same subclass. Let us use the letter C to refer to the subclass of a cell C.

Designers may now define an abstract TIP C.p TIP for each port C.p defined for subclass C. Ports C.p CAMS ports will inherit C.p TIP . Designers will define C.p TIP by selecting and defining the Tip guard and Tip body for the selected kind of TIP selection being done from one of 12 kinds of TIPs TICC Ppde offers and defining the TIP. No guidance can be given to designers for such TIP selections and definitions. Designers should have a good understanding of what each kind of TIP does and functionalities associated with ports in CAMS ports . Once TIPs are defined designers may update CAMS requirements by adding more CTL assertions as needed. For each TIP designers should specify an upper bound for estimated time it might take for the TIP to be executed. These upper bounds will automatically determine upper bounds for transaction completion times for ports connected by pathways.

At this point TICC Ppde will automatically derive port ALLEOPs and port Traces associated with each port in CAMS ports 0 as described in Section 3. System will also use port Traces to automatically construct ECT networks like the ones illustrated and discussed in Section 7. TICC Ppde may now interactively formally verify CTL assertions in CAMS requirements using the ECT networks as discussed in Section 7. This may call for design revisions and or updating of CAMS requirements . Formal validation of all CTL assertions in CAMS requirements will complete the abstract design of CAMS. Let us call it CAMS design .

It may be noted no programming considerations were involved in CAMS design or in finalizing CAMS design only system decomposition and requirements specifications. All of these are specified not in a programming language but in abstract terms which are not executable by computers but which may be analyzed and used for formal proof constructions. Programming begins only after CAMS design has been completed.

Designers may at this point analyze CAMS design based on patterns of interactions and tentative timing bounds. Objective of this analysis might be to ascertain whether the design is capable of satisfying given performance criteria. Criteria might specify conditions for optimal and or satisfising performance of the design. Analysis methods may be based on postulated interaction efficiencies in CAMS design and CAMS ALLEOPS postulated data on products of the corporation product development distribution marketing and re cycling times costs and benefits cost and timing cycles for production of products and development of future products projected customer satisfaction surveys projected demands for products production capabilities to meet the demand administrative efficiencies and projected economic well being of the corporation over given number of years.

ALLEOP proof methods would not be sufficient to perform this analysis. It is quite possible that methods of analysis used here are based on economic theories of optimal and satisfising performance. It is possible to develop such analysis methods using information in CAMS design CAMS ALLEOPS and information listed above. Need for such analysis is clear. But at this time we do not have any formalized analysis methods of this kind that we could use. Hopefully they will emerge in the future.

Programming begins at this time. Before programming pthreads in TIPs and defining message subclasses designers should specify input output logical characterizations for the pthreads to be programmed. Programmers are usually not trained to do this. Designers must do this. Pthreads jointly executed in parallel by cells in cell groups in same virtualMemories should be jointly implemented. After each pthread and its associated message subclasses have been implemented it should be formally verified that each pthread satisfies its specified characterization and each TIP execution is likely to satisfy its specified upper bound.

At this point designers may specify relations R defined in Section 2.3.2 specifying the well matched property of ports p q connected by pathways and interactively verify whether timing upper bounds specified for transactions are likely to be satisfied. As TIPs and CIPs are refined TICC Ppde will automatically update port TIPs port ALLEOPs port Traces and ECT networks. Implementers may verify whether CTL assertions in CAMS requirements are satisfied using TICC Ppde. This may call for revision of pthread implementation or their characterizations or estimated timing upper bounds associated with them or may even call of revision of CAMS design .

This TIP and CIP refinement process is iterated until a fully validated CAMS implementation is obtained. At this point designers should verify whether statement 7.44 characterizing satisfactory validation of CAMS holds true. This may call for more iterations of design refinement and validation steps. Eventually this process will yield completed CAMS implementation .

SMS network Design After doing all of these designers may specify organization of eb and ea cells in CAMS SMS using already postulated eb cells embedded in the pathways of CAMS TICC network . Design of SMS involves assigning to each eb cell all pathways in CAMS pathways that it should service assigning ea cells with which each eb cell should communicate and setting up specialized pathways for communications between eb and ea cells. We refer to this as SMS network design. This may be done by designers interactively with TICC Ppde. It is even possible to fully automate this process. We have not done this yet. SMS network design will result in elimination of many eb cells initially postulated by TICC Ppde since TICC Ppde initially assigned one eb cell for each pathway and in the final design each eb cell will service several pathways.

Run time Validation Once CAMS design CAMS implementation and their validation and CAMS SMS design are completed the fully refined and validated system may be dynamically tested by running it and examining the causalnets generated by SMS. At this point it is not likely that dynamic run time testing might call for recycling of design refinement and validation processes. But it is possible 

Focus Shift in TICC Paradigm for building Software Systems The design and implementation procedure outlined above shifts the focus of system design and implementation from programming to system decomposition analysis and validation. TIP refinements begin only after system design has been completed. This guarantees that programming considerations would not influence system decomposition contrary to current practices in software engineering where system design is highly influenced by programming considerations. Our software engineering methodologies are highly influenced by available programming technologies. In TICC paradigm there is a clear demarcation between system design programming and validation and TICC paradigm relegates programming to a lower level clerical operation elevating verifying operations to a higher level.

TICC Paradigm Sets New Basis for Software Engineering As described above system design and implementation using the TICC paradigm does not require much programming expertise but requires considerable expertise in network refinement system analysis logical characterization of systems and formal validation techniques. Expertise in programming will not help in these tasks. System designers software engineers and implementers have to be trained differently to effectively use TICC paradigm to build formally verified parallel software. They have to be trained in system decomposition interaction analysis formal requirements specifications logical input output characterization of pthreads and formal validation techniques. This will dramatically change the nature of software engineering from what it is today.

Examples presented in this disclosure Implementation specifications for examples discussed in this disclosure specify abstract designs for those examples in different stages of refinements. Implementations in Appendices I through III specify logical characterizations of most actions and conditions appearing in implementations but they do not specify computer programs for all of them. All proofs presented here are proofs of CTL assertions on implementations in different stages of refinements. Thus ALLEOP proof methods may be used to validate characteristics of both designs and implementations at every stage of refinement.

TICC CPUs We present in the next section special facilities that computing units used to execute TICC Ppde parallel programs should have in order to facilitate efficient program execution and automatically provide all needed data and system security to validated implementations. We refer to the computing units with requisite special facilities as TICC CPUs.

TICC CPU Requirements TICC Ppde simplifies designs for TICC CPUs by eliminating the need for cache memories and the need to use speed up techniques as explained in Section 5.6. However TICC Ppde requires each TICC CPU to provide some special facilities to run cells and execute communication protocols. These special facilities pertain to the following In the following we use C.cpu to refer to the TICC CPU assigned to run a cell C.

 i Time Stamping Each C.cpu should contain a hardware clock to enable time stamping of message deliveries to ports C.p attached to C time stamping being done at times when other CPUs C .cpus deliver messages to ports of C messages being delivered in parallel to the ports of C by the other cells C . Messages may be simultaneously delivered to multiple ports of C by different C .cpus. Therefore in order to set time stamps it should be possible for multiple message delivering C .cpus to simultaneously interrogate the hardware clock of C.cpu.

Since this facility was not available at the time of implementation of prototype TICC and TICC Ppde no time stamping was used in the prototypes. Thus SMS infrastructure in the prototypes is not tested.

 ii CCP Machine Instruction Each C.cpu should implement CCP Causal Communication Primitive as a hardware machine instruction. State of the art methods for implementing CCP as a machine instruction are quite straight forward since they just require programmed implementation of sequential machine state transitions implemented as a hardware instruction and therefore are not described here. CCP was implemented in software in the prototypes.

 iii Interrupt Handling Each C.cpu should contain interrupt handling facilities to communicate directly with interruptPorts of C C.cpu responding to detected interrupt signals only between successive TIP executions by C. This was also implemented in software in the prototypes. Operating system cannot interrupt any cell in the prototypes only other cells or human users may interrupt cell activities.

 iv Memory Allocation Each virtualMemory should have its own dynamic memory allocation software associated with it this software being run by CPUs assigned to cells that are tuned to that virtualMemory as and when needed. Dynamic memory allocation was done in the prototypes using the LINUX operating system in the shared memory environment of PROLIANT 760 multiprocessor. Input output and secondary memory accesses were also handled by the operating system.

 v Shared Memory Organization Each DMP Distributed Memory multi Processor with SMPs Shared Memory multi Processors as its computing nodes may contain a TICCNET interconnecting the SMPs. If DMP is integrated in a multi core chip then the TICCNET may also be integrated in the chip. However it is possible to dispense with the need for TICCNET in multi core SMP chips if the shared memory organization described below that exploits virtualMemories is used. Prototypes were implemented in a conventional shared memory multiprocessor. So issues raised here did not arise.

Above requirements do not complicate CPU designs but do complicate chip designs. Simplified CPU designs increase achievable CPU densities in multi core chips.

Organization described here facilitates time stamping of multiple simultaneous message deliveries to multiple ports of a cell C R for Receipt by message delivering CPUs C.cpus SD for Delivery using local times of the clock of c.cpu. The described organization facilitates simultaneous polling of the clock time by multiple message delivering C.cpus.

Signal Memory Data For each port C.p tuned to virtualMemory C.p.vM let C.p.clock and C.p.delivery be two distinguished time registers associated with C.p C.p.clock C.p.sm.clock and C.p.delivery C.p.sm.delivery where C.p.sm C.p.vM.sm is the signalMemory component of C.p.vM. These registers are thus in C.p.sm. Let C.cpu be the CPU that runs cell C. C.cpu broadcasts its clock time to time registers C.p.clock for 0 i

Time Stamping Let us now suppose port D.q of cell D is delivering a message to port C.p of cell C via pathway D.qC.p. Then D.q.vM C.p.vM and D.q.protocol for message delivery will be executed by D.cpu. Suppose D.cpu was delivering the message to ports in a port group G C.p 0 j

Shared memory organization described below for TICC CPUs in multi core chips uses virtualMemories to minimize memory interference provide increased data security increased execution efficiencies and eliminate the need for TICCNET in integrated multi core processors.

Private Memories of CPUs and SMMs Each CPU in a multi core chip will contain a small private memory of no more than 16 mega words. This private memory is intended to store the state of the cell that is run by that CPU state of the CPU and methods and conditions defined in that cell. Other than this private memory the CPU will have no dedicated main memory attached to it. However each CPU will have the capability to dynamically connect to a subset of a collection of independent hardware memory modules called Shared Memory Modules SMMs using programmable logic networks. The SMMs are kept in a pool of such hardware memory devices associated with the chip. SMMs in the pool have varying memory capacities ranging from 10 kilo words to a few giga words. Dynamic connections between the CPUs and SMMs are controlled by ports as described later below.

SMMs Assigned to VirtualMemories by TICC Ppde Each virtualMemory in an application will have a unique SMM assigned to it by TICC Ppde this assignment being done at compile time or run time no two distinct virtualMemories having the same SMM assigned to them. The SMM assigned to a virtualMemory is never changed. The maximum number of CPUs serviced by an SMM will be equal to the maximum number of cells that a cell group may have. This is because cells in a cell group are all tuned to the same virtualMemory and thus all CPUs that run those cells will use the same SMM. We assume here the maximum number of cells serviced by an SMM is likely to be no more than 16 which is the maximum likely size of a cell group. In practice cell group sizes are likely to be in the range of 1 to 4.

Machine Instructions for setting up connections between CPUs and SMMs Let C.p.smm be the SMM assigned to the virtualMemory C.p.vM. We introduce two machine instructions Connect C.ports and Disconnect C.ports where C.ports is the set of all ports attached to cell C which are polled by C in its polling cycles. These are the ports with non embedded TIPs. Connect C.ports connects C.cpu to C.q.smm for every port C.q C.ports and Disconnect C.ports disconnects C.cpu from C.q.smm for every port C.q C.ports. When C.cpu is assigned to C Connect C.ports is executed. When C releases C.cpu Disconnect C.ports is executed. One may implement connect and disconnect operations between CPUs and SMMs through a suitable crossbar switch.

Machine Instructions for granting and revoking access to SMMs We introduce two additional machine instructions GiveAccess Ports and DenyAccess Ports where Ports is a subset of ports appearing in a C.p tip . Of course all ports in this subset would be attached to C. The instruction GiveAccess Ports gives C.cpu access to data messages and methods in C.q.smm for ports C.q Ports only if C.q.state S and DenyAccess Ports removes access rights to data in C.q.smm already given to C.cpu for every port C.q Ports. C giveAccess Ports and C denyAccess Ports are here implemented as hardware instructions in C.cpu. These instructions work in the context of connections already established between C.cpu and C.q.smm for C.q Ports. These instructions have to set and reset just one bit in order to give and deny access through an already established connection. Thus giving and denying access to a CPU for an SMM can be performed at high speeds.

Before proceeding to discuss how dynamic access control for CPUs to access SMMs is used to drive a TICC CPU it is necessary to consider the instruction execution protocol of TICC CPU.

Instruction Execution Protocol of TICC CPU As before let us use C.cpu to refer to a generic TICC CPU assigned to cell C. The instruction address register of C.cpu is a stack of address registers. We will use C.cpu.iar to refer to this stack and use C.cpu.iar j for j 0 1 . . . to refer to the address register at level j of this stack C.cpu.iar 0 being the top of the stack. Eval is a machine instruction in C.cpu that sets and modifies C.cpu.iar. It is used only by the compiler when it compiles programs written by application programmers. Eval takes a vector of two addresses as its argument. We will use Adrs to refer to this vector of two addresses Adrs Adrs 0 Adrs 1 . Adrs 0 is the beginning address of an area of memory in which compiled binary code for a program is stored. Adrs 1 is the address to which program execution control returns after executing the binary program code that starts at Adrs 0 .

Eval Instruction Execution When eval Adrs is executed if Adrs 1 then C.cpu sets C.cpu.iar 0 eval next which is the address of the next instruction following eval in the program currently being executed. If Adrs 1 then C.cpu first sets C.cpu.iar 0 Adrs 1 . After setting C.cpu.iar 0 C.cpu pushes Adrs 0 onto C.cpu.iar by performing C.cpu.iar push Adrs 0 . This sets C.cpu.iar 0 Adrs 0 and C.cpu.iar 1 Adrs 1 or eval next. This completes execution of eval.

Instruction Execution Cycle After executing eval C.cpu continues its instruction execution cycle as follows Instruction at address C.cpu.iar 0 is retrieved and executed. After instruction execution if the executed instruction did not itself reset C.cpu.iar 0 or change cpu.iar through a push or pop operation then C.cpu updates C.cpu.iar 0 to the address of the next instruction to be executed in the program that is being currently executed without popping cpu.iar and continues in this manner until the current program execution is completed. Completion of this program execution will always cause C.cpu.iar pop to be executed there by transferring execution control to Adrs 1 or eval next thus resuming the earlier program in which the just executed program was started.

Push and pop operations are thus respectively done on cpu.iar only when a program program segment is invoked through eval and the invoked program program segment terminates. Eval is the only instruction that can push a new address onto C.cpu.iar. For every push there should be a corresponding pop in order to keep C.cpu.iar in sync with programs being executed in cell C.

Protocol Executions Notice eval C.p.protocol will simply set C.cpu.iar 0 C.p.protocol and C.cpu.iar 1 eval next. This will cause C.cpu to begin executing C.p.protocol. At the end of protocol execution C.cpu.iar pop will be executed. This will cause the instruction at eval next to be executed next. There will always be an eval next because every compiled program ends with C.cpu.iar pop . If the instruction at eval next is C.cpu.iar pop then it will again pop C.cpu.iar and this will result in terminating C.p tip as we shall see below else it will continue executing the remaining portion of C.p tip starting at eval next. C.p s and C.p f appearing in C.p tip are simply compiled to eval C.p.protocol . We refer to eval X as inline invocation of X.

TIP Executions For each C.p we use eval together with C.p tip invocation and C.p tip termination protocols to execute C.p tip . These protocols give dynamic access to C.cpu for SMMs assigned to virtualMemories that are needed to evaluate C.p tip and revoke given access permissions at the end of C.p tip execution. These invocations and revocations are done at the level of executions performed by a computing machine without having to invoke an operating system or any other process that is external to cell C.

Invocation Termination Protocols for C.p tip s for external ports C.p Let C.p.tipStart C.p.tipEnd C.p.tipInvoke C.p.beginningPorts C.p.endingPorts and C.p.stack be attributes defined on C.p. C.p.tipStart holds the beginning address of the memory area in which the compiled binary code for C.p tip is stored. This binary code for C.p tip is normally kept in the execution memory C.p.vM.ex of the virtualMemory C.p.vM. For port vectors c. it is kept in the local memory of C.cpu C.cpu.rM rM for real Memory . C.p.tipInvoke holds the beginning address of the memory area in C.cpu.rM in which compiled binary code of the invocation protocol C.p invocation is stored. C.p.tipEnd holds the beginning address of the memory area in C.cpu.rM in which compiled binary code of the termination protocol C.p termination is stored.

C.p.beginningPorts specifies the subset of ports appearing in C.p tip such that for every C.q C.p.beginningPorts. C.cpu should have access to C.q.smm before it can begin to execute C.p tip . C.p.endingPorts specifies the set of all ports such that for every C.q C.p.endingPorts C.cpu should be denied access to C.q.smm when execution of C.p tip terminates. C.p.tipStart C.p.beginningPorts and C.p.endingPorts are all set during compile time of C.p tip . Finally C.p.stack is a stack of length two that holds a vector of two memory addresses pointers at each level 0 C.p.stack j 1 for j 0 1. 10.1 

where is read as beginning address of the compiled code of . Reason for the pop in 10.3 will become clear later below.

Using C.p.stack Normally C.p.stack 0 C.p.tipInvoke C.p.CIP resume where C.p.CIP resume is the address at which C.cpu should resume execution when C.p tip execution terminates. C.p.CIP resume will be an address in C.cpu.rM in which compiled binary code for C CIP is kept. Intention here is C.cpu should resume execution of C CIP starting at C.p.CIP resume after executing C.p tip. Value of C.p.CIP resume is fixed at the time of compilation of C CIP for every port C.p of cell C whose TIP is not an embedded TIP and C.p.stack 0 1 C.p.CIP resume is set. After the state of C.p changes to S and when c CIP is ready to execute C.p tip C.cpu will simply execute eval C.p.stack 0 . This will cause the following to happen 

Evaluating C.p.stack Eval C.p.stack 0 first sets C.cpu.iar 0 C.p.CIP resume C.p.stack 0 1 . After doing this eval C.p.stack 0 performs C.cpu.iar push C.p.stack 0 0 making the new C.cpu.iar 0 C.p.tipInvoke and C.cpu.iar 1 C.p.CIP resume. This will cause C.cpu to begin executing C.p invocation in 10.2 which will first give access to C.cpu to all virtualMemories that are needed in order to begin executing C.p tip . After access has been given eval C.p.tipStart C.p.tipEnd appearing in 10.2 will set C.cpu.iar 0 C.p.tipStart C.cpu.iar 1 C.p.tipEnd and C.cpu.iar 2 C.p. CIP resume. This will cause execution of C.p tip to begin. Compiled code for C.p tip will always end with C.cpu.iar pop which will cause C.p termination 0 to be executed starting at the address C.p.tipEnd at the end of C.p tip execution. This termination protocol revokes all accesses given to C.cpu during C.p tip execution and then pops C.cpu.iar which will cause execution control to be returned back to C CIP at address C.p.CIP resume.

TIP Compilation For TIPs that are not embedded in other TIPs compiled codes for program segments shown on the right side of 10.2 and 10.3 will be kept in the executionMemory C.p.vM.ex of port C.p at compile time and C.p.tipInvoke and C.p.tipEnd will be set to the beginning addresses of their respective compiled codes in C.p.vM.ex. Similarly C.p.tipStart will be set to the beginning address of the compiled code for C.p tip . These addresses pointers are also saved in C.p.vM.ex by setting C.p.vM.ex.tipStart C.p.tipStart C.p.vM.ex.tipInvoke C.p.tipInvoke and C.p.vM.ex.tipEnd C.p.tipEnd. Of course C.p.stack 0 0 C.p.tipInvoke will also be set. C.p.stack 0 1 is set to C.p.CIP resume while compiling C CIP . All of these are thus done at compile time and all the compiled codes and pointers will reside in C.p.smm.ex where C.p.smm C.p.vM.

When C is activated in C.cpu the compiled codes for program segments C.p invocation and C.p termination in 10.2 and 10.3 will be copied into C.cpu.rM the real Memory local to C.cpu from C.p.smm.ex and C.p.tipInvoke and C.p.tipEnd will be suitably reset to their respective new addresses in C.cpu.rM. This is done for every port C.p of cell C whose TIP is not an embedded TIP. This would be a part of cell activation at run time. Thus cell activation can be an expensive process taking 2.5 to 5 microseconds to complete. But it is usually done only once.

Embedded TIPs If C.p TIP is an embedded TIP then let C.q tip be the TIP in which C.p TIP is embedded. In this case 

will be compiled in line with C.q tip . Here C.p.tipInvoke C.p.tipStart C.p.tipEnd and C.p.stack are set to since they are not needed but C.p.beginningPorts and C.p.endingPorts will be set to their respective values.

Activations in Cell Groups It is possible that C.p is just one of the ports in a port group G C.p C.p . . . C.p . C.p C.p. Parent cells of ports in G constitute a cell group. Let C C C . . . C be this cell group. All the ports in G are tuned to the same virtualMemory C.p.vM. Let G.vM C.p.vM and G.smm C.p.smm. Each port C.p gives access to its parent cell Cto the virtualMemory G.vM after C.p.state S becomes true. C.cpu will get this access when eval C.p.stack 0 is executed and access will get revoked when C.p.tipEnd is evaluated. Access to G.smm and revocation of this access may not happen at the same time for all the CPUs in the set C.cpu c C since activities of cells in cell group C may not be synchronized to each other. Eventually all CPUs in C.cpu Ci C will access the same G.smm while each is executing C.p tip in parallel.

Programmed Suspension of C.p tip Execution It is possible to have a programmed suspension of C.p tip execution in the middle and resume from where it was left off. Notice there is a distinction between programmed suspension and suspension caused by an interrupt message In programmed suspension cell is not suspended only C.p tip execution is suspended. The method C.p suspendTip C.p.TIP resume is used for programmed suspensions of C.p tip where C.p.TIP resume is the address in the compiled code of C.p tip at which execution of C.p tip should be resumed. Code for C.p suspendTip C.p.TIP resume should be embedded in line into a pthread in C.p tip it cannot be activated through an interrupt message. The value of C.p.TIP resume gets set at compile time. Suspension of C.p tip execution will be based on conditions evaluated at run time that will depend on the state of cell C and its ports.

Additional C.p Attributes We introduce two new attributes for C.p C.p.resumeStart and C.p.resumingPorts. The value of C.p.resumeStart is the address at which C.p tip should resume operations. The value of C.p.resumingPorts is a set of ports such that for every port C.q C.p.resumingPorts C.cpu has access to C.q.smm at the time C.p tip is suspended. C.cpu should reacquire access to C.q.smm for every C.q in C.p.resumingPorts before it resumes execution of C.p tip hence the name C.p.resumingPorts. Both C.p.resumingPorts and C.p.resumeStart are set at run time when C.p suspendTip C.p.TIP resume is executed.

C.p suspendTIP resume Method Definition of C.p suspendTip C.p.TIP resume is given below. In the following this refers to the instance of Port in whose tip suspendTip C.p.TIP resume is being executed. Suspend TIP is always compiled in line with the code of the pthread in which it occurs.

Programmed Suspension of C.p tip When a programmed suspension of C.p tip occurs C.cpu is not suspended and released but C.cpu simply proceeds to service the next port in C CIP after executing C.p suspendTip C.p.TIP resume . When C.p is polled in an ensuing polling cycle of C CIP it will evaluate to true since C.p.input s has been set in 10.8 . When this happens C.cpu will simply execute eval C.p.stack 0 . At this point C.p.stack 0 will hold C.p.tipResume C.p.CIP resume and therefore cause C.p.tipResume to be executed which in turn will cause C.p.stack to pop as shown in 10.10 returning C.p.stack 0 to its normal value shown in 10.9b then give access to C.cpu to all C.q.vM for every C.q in C.p.resumingPorts and then evaluate eval C.p.resumeStart C.p tipEnd . This will cause C.p tip to resume operations starting at C.p.resumeStart and execute C.p.tipEnd at the end of C.p tip execution which in turn will cause control to be returned to C CIP at C.p.CIP resume. Or may be C.p tip may get suspended again.

Comment It may be noted C.p suspendTip C.p.TIP resume could be a source of possible deadlock in an application. Thus for every use of c p suspendTip C.p.TIP resume it should be shown that eventually when computation resumes at C.p tip it will complete the transaction at port C.p.

System and Data Security In the above described scheme access to SMMs is given to TICC CPUs dynamically based on computational contingencies that arise in parallel computations at run time. The number of C.cpus that may simultaneously access a SMM has been assumed to be at most 16 but as mentioned earlier in most cases it will be between 1 through 4 since cell group sizes are likely to be no more than 4. This reduces memory interference in shared memory operations. This also dramatically improves data protection and security because i for each port C.p message in virtualMemory C.p.vM is delivered to port C.p only if C.p and the message satisfy a priori specified security requirements ii each port C.p gives access to C.p.vM only to its parent cell C and iii only at times after C.p.state has moved to S.

All methods pthreads and processes are automatically activated in each cell only through message deliveries. A cell may get activated and access and respond to a received message in a virtualMemory only if a priori defined security requirements are satisfied. Enforcement of this security restriction does not require intervention by an operating system. It is intrinsic to TICC Ppde execution mechanisms. Giving and revoking access rights to data in SMMs are built into hardware at its innermost level.

Cell activations are done at message delivery times when needed by CPUs that that deliver messages see statement 8.4 iv . There are no method or process activation directories there are no monitors to schedule activations and no Dynamic Link Libraries DLLs. Thus there is no way for an unauthorized intruder to enter an application and interfere with method and process activations there is no way to find out which CPU is executing which pthread at what times and what messages are being exchanged by cells at any given time unless intruder gets access to causal net generated by SMS and access to ALLEOPs stored in an application. Even if an intruder gets access to the causalnet he she it can find out about events that occurred only after they have already occurred. There is no way for an intruder to interfere with occurrences of on going events unless intruder tricks the system acquires access to ALLEOPs and changes them which can be made impossible to do. It is of course possible that the intruder is a spy who already had access to the system. Preventing that is a human administrative problem not a problem for the software application.

Data and system security thus becomes an intrinsic built in feature of TICC Ppde at its innermost level in the shared memory system with SMMs and not a feature added on to an application using an operating system to enforce it. These characteristics erect practically impenetrable barriers against data theft and system intrusions.

Designing a Security System for an application Problems in designing and implementing secure TICC based systems are not in efficient secure and reliable implementations of such systems but in designing and defining a consistent set of message attributes port attributes virtualMemory attributes security functions and security delegation revocation protocols where one port temporarily delegates its security status to another port which guarantee application security. The problems here are no different from the usual problems encountered in security system definition but problems of reliable and correct implementation of a defined security system are totally eliminated. Defined attributes and security functions are automatically invoked at the time of message delivery by communication protocols built into TICC Ppde see security specifications in Section 8 . Thus efficient secure implementation of a defined security system is automatic.

Comments The SMM scheme complicates memory implementation since it requires use of multiple shared memory buses one for each SMM multiple memory access networks in each CPU and programmable logic networks in the form of a cross bar switch to efficiently set up connections between CPUs and SMMs and dynamically change access rights. The scheme however simplifies CPU designs since CPUs do not have cache memories or any other speed up ornamentation. Most importantly the scheme contributes intrinsically to greater efficiency software security privacy and protection.

It is possible to use TICC Ppde for designing refining and formally verifying asynchronous hardware systems that run with automatic SMS Self Monitoring System . Registers in hardware systems would become virtualMemories. Hardware subsystems may be encapsulated into compound cells as illustrated in the example in Section 3.2 the compound cells hiding encapsulated components from other components in a hardware system and each compound cell having its own SMS. Such compound cells may be used as hardware components that are plugged into larger hardware systems in contexts where the external ports of the compound cells are well matched as defined in Section 2.3.2 to ports of the larger system in to which they are plugged.

Abstractions 1 Cell Pathway These abstractions are not new but their particular incarnations in TICC Ppde are new. They integrate computation and communication while at the same time isolating and protecting computations performed by each CPU in a multi core chip and preventing mutual interference among computations performed simultaneously in parallel by distinct shared memory CPUs in the chip. Pathways isolate protect and preserve messages and prevent mutual interference among asynchronous messages exchanged simultaneously in parallel between distinct groups of CPUs in a chip.

Abstractions 2 Attachment Tuning Port Agent Attachment and tuning as programming abstractions are new to programming. Only attached or mutually tuned hardware software components may share each others methods and data and exchange signals between each other. This restriction facilitates high speed message exchanges cell isolation self synchronization and self coordination. Attachments and tunings are performed automatically by TICC Ppde when instances of cell and pathway subclasses are installed ports are installed on cells pathways are connected to ports of cells ports are connected to agents and agents are installed on virtualMemories. Implementers do not have to write programs to implement attachments and tunings. They are automatic built in features of TICC Ppde.

The concept of software ports and agents is not new. However the particular characteristics of ports and agents in TICC Ppde are unique to TICC Ppde. Subclasses of pathways agents and ports likely to be used in any parallel programming application are predefined in TICC Ppde. Implementers have to define only unusual pathway agent and port subclasses not already defined in TICC Ppde following appropriate subclass definition formats.

Abstraction 3 VirtualMemory It is common in computing systems to associate dedicated hardware memories with hardware systems. But the concept of using dedicated virtualMemories as software abstractions of hardware memories used in software systems is new. This concept was first introduced by Gopinath 21 . It was adapted by this author with some enhancements for parallel program development and execution in TICC Ppde. The way virtualMemories are defined and used in TICC is new. Real memory areas or real SMMs Shared Memory Modules are allotted to virtualMemories during compile or run time.

VirtualMemories simplify parallel programming with multi core chips and provide opportunities to implement new shared memory organizations with SMMs in multi core chip designs. They introduce intrinsically enhanced execution efficiency data isolation and data protection and contribute to system security. Subclasses of virtualMemories likely to be used in any parallel programming application are predefined in TICC Ppde. Implementers have to define only unusual virtualMemories subclasses not already defined in TICC Ppde following appropriate subclass definition formats.

Abstractions 4 CCP and Protocol The most significant abstraction in TICC Ppde which in fact makes integration of all other abstractions possible is CCP Causal Communication Primitive which is an abstraction of signal exchange between software hardware components. They are used in TICC Ppde to define communication protocols which when executed cause signals to travel over pathways associated with those protocols. They enable hardware software components to exchange signals dynamically and programmatically thus isolating them and yet enabling them to collaborate with each other. CCP induced signal exchanges synchronize coordinate and manage asynchronous software hardware components very much like start completion signals synchronize coordinate and manage asynchronous hardware components.

Communication protocols define a restricted class of computations containing no declarations but containing CCPs. They not only deliver signals and messages but also control access rights to delivered messages. Using CCP as a basic programming language primitive is new to programming technology and implementing it as a machine instruction is new to design of CPUs. Protocols likely to be used in any parallel programming application are predefined in TICC Ppde. Implementers have to define only unusual protocols not already defined in TICC Ppde following appropriate definition formats.

Abstraction 5 TIP TIPs are Thread Interaction Protocols. Each port C.p attached to a cell C has a TIP C.p TIP defined for it. TIPs perform the following functions i facilitate software development through abstract specifications of interactions among ports in an application and progressive refinements of abstract specifications to final implementations ii isolate communications from message processing and message building computations in each cell iii Isolate parallel computations performed by different cells iv allow automatic derivation of modularized event based port ALLEOPs from implementations at various stages of refinements v enable flexible use of port ALLEOPs for formal verification of an implemented system at various stages of refinement and vi enable SMS Self Monitoring System organization. As a programming abstraction TIPs are new to programming technology. There are a total of 10 different kinds of TIPs five synchronous and five asynchronous.

Abstraction 6 Synchronizations There are two kinds of synchronizations cycle synchronization and temporal synchronization. Cycle synchronization imposes coordination ordering of activities in an application. Two TIPs p tip and q tip associated with any two distinct ports p and q in an application are cycle synchronized if evaluation of q tip always begins after the evaluation of p tip has been completed and the next evaluation of p tip begins only after the completion of the previous evaluation of q tip . Ports p and q may belong to any two cells in the application they may even belong to the same cell. Two TIPs C.p tip and C.q tip belonging to ports of any two distinct cells Cand Care temporally synchronized if their evaluation always begins at the same time possibly separated by a few nanoseconds picoseconds or femtoseconds depending on the technology.

TICC Ppde provides systematic methods to introduce cycle synchronization and temporal synchronization into a design or implementation through installations of predefined pathways and specifications of appropriate TIPs. TICC Ppde totally eliminates need for using semaphores or rendezvous methods. This relieves programmers from having to ever embed synchronization and coordination methods into object codes of software components.

Ad hoc synchronization and Coordination TICC Ppde provides methods to introduce synchronizations and coordination in to an implementation as an after thought at any stage of refinement of the implementation with no need to change any of the refinements done up to that point Section 7.6 . We call them ad hoc synchronization and coordination methods.

All synchronization and coordination methods used in TICC Ppde are new to programming technology and unique to TICC Ppde.

Abstraction 7 CIP CIPs are Cell Interaction Processes. Each CIP defines a unique process that runs in a unique CPU in parallel with all other processes in a parallel processing system. C CIP executes cyclically TIPs at the ports of cell C that have messages delivered to them or C sends out messages through those ports. C continues its operations until it is terminated or suspended. CIP processes are the only processes in TICC Ppde parallel program execution. Their scheduling activation in a CPU suspension resumption synchronization and coordination are all managed entirely by TICC Ppde without need to use an operating system and without need for implementers to embed any object code into any of the application programs. All needed synchronizations and coordination in an application are implicitly defined by the TICC network of that application.

Using polling to recognize receipt of service requests and responding to them in some order is not new. It is widely used in all software systems. But the particular incarnation of this service in CIPs is unique to TICC Ppde.

Abstraction 8 TICC Network This specifies in a graphical form cells used in an implementation and pathway interconnections among ports attached to the cells. TICC network specifies the control structure of parallel computations in an application. It implicitly specifies and enforces all forks joins and synchronization and coordination of parallel computing activities that occur in an application. Implementer has responsibility to specify the TICC network for an application. Once this is done implementers are totally relieved of all responsibility to schedule control or monitor activities in parallel processes or perform synchronization and coordination of those activities. The system becomes self scheduling self monitoring self synchronizing and self coordinating.

Just as data structure abstraction makes it possible to run the same sequential program with different data structure definitions as long as the structure of the sequential program matches with structure of the data structure the TICC network makes it possible to run the same set of parallel application programs pthreads with different TICC networks as long as initialization routines in each C CIP in an application and TIPs defined at ports in that application match with the structure of TICC network.

Using a graphical representation to capture the control structure of interactions among components of a system is not new. But the specific incarnation of TICC network with its unique interpretation in TICC based parallel software systems is new.

Abstractions 9 ALLEOP Trace and ECT The manners in which these abstractions are derived from implementations and used are new and unique to TICC Ppde. TICC Ppde provides tools to derive ALLEOPs from implementations and use them to interactively validate software systems. The concept of a trace is not new. The term trace is used to refer to a description of what happens in a particular run of a program. Different programming disciplines use different syntactic structures or graphical tools to specify traces. TICC Ppde traces have the unique characteristic that they not only specify all of what may happen in a particular run of an application but also define the logical semantics of computations. Traces are derived automatically from ALLEOPs and logical input output characterizations of actions. TICC Ppde provides methods that use ECT networks Event Characterization Table networks automatically derived from traces to validate properties of implementations.

Abstractions 10 SMS Causalnet Eb Cell Causalnets are abstractions of traces they contain only causal chains of communication events that occur in traces. Causalnet for an application Ap is built by the SMS Self Monitoring System of TICC Ppde while Ap is running in parallel with the running of Ap. Agents in each pathway P in application Ap send signals to specialized Event Builder cells eb cells connected to P while signals are traveling over P. Each P is serviced by a unique dedicated eb cell. A given eb cell may service several pathways. Signals received by the eb cell of P instruct the eb cell to install into a growing causalnet of the application message dispatch and delivery events occurring in P.

Signaling of eb cell occurs during signal transmission over a pathway and dispatch and delivery event installations occur in parallel with message processing done by the message receiving cells in a manner that prevents interference between timings of SMS events and timings of application events. There are four activities that run in parallel while a growing causalnet is being built by the eb cells in SMS i activities of all cells that run in the application ii activities of agents in pathways signaling eb cells in SMS iii activities of eb cells while they update the growing causalnet with new message dispatch and delivery events and iv activities of ea cells of SMS that analyze the growing causalnet see Abstractions 11 below .

The times at which signals are delivered to an eb cell specify the time instances at which message in the virtualMemory of the pathway connected to that eb cell is either dispatched or delivered. These time instances are specified in the local time of eb.cpu that runs that eb cell. Since local times of all CPUs that run eb cells are synchronized to a standardized global clock all timings associated by eb cells with event instances in the causalnet would be synchronized to the same global clock. CPUs that run other cells in the application may use different local clocks not synchronized either to the global clock or to each other.

Each pathway in TICC Ppde is connected to the SMS components needed for that pathway. Thus when an application is defined its associated SMS structures get automatically defined. The defined SMS structures are automatically invoked and used to dynamically monitor every run of that application. Application implementers do not have to write any programs to facilitate this. Each SMP Shared Memory multi Processor X in a distributed memory computing grid interconnected by a TICCNET will have its own unique local SMS X SMS . The causalnet built by X SMS will reside in a local shared memory of X. TICC Ppde can integrate the causalnets in different SMPs of a distributed memory computing grid and display any portion of it centered on given cells or ports in an application using TICC GUI Graphical User Interface as and when needed.

Application programmers do not have to write programs for any component of SMS. SMS is an automatic built in feature of all parallel program executions in TICC Ppde.

Abstractions 11 SMS Ea Cell SMS uses specialized Event Analyzer cells ea cells to monitor a growing causalnet while it is being created during each run of an application. The objective is to identify and report errors and pending errors in the growing causalnet. Ea cells also monitor the causalnet to identify occurrences of a priori defined event patterns in the causalnet and issue alerts. They may use the recognized event patterns also to modify behavior of an application. As technology advances this may be used for general complex pattern recognition for incorporating self diagnosis self repair and learning capabilities into applications. It is a built in part of TICC Ppde parallel program communication mechanism.

Comments All of the above programming abstractions and methods used in TICC Ppde parallel program development validation execution and self monitoring are unique to TICC Ppde. The most important feature of TICC Ppde organization is security and protection of data and error monitoring. These are built into the system at its innermost level with no need for application programmers to embed any of the security and protection features or error monitoring features into application programs except for defining needed data security attributes and security functions specific to pathways attached to ports in an application and defining event patterns that are significant to the application the defined attributes functions and event patterns being automatically invoked and used by built in protocols and SMS of TICC Ppde.

Feature 1 Integrated Environment TICC Ppde performs CPU assignments to cells cell activations in assigned CPUs parallel process management pthread parallel thread management communications scheduling interrupt management security enforcement synchronization and coordination without having to invoke an operating system or any other software to perform any part of these services. In the current shared memory prototype implementation TICC Ppde uses operating system only for memory management cache management access to secondary storage devices input output and internet access. As mentioned in Feature 4 cache memories and all other kinds of speed up techniques commonly used in CPU designs can be totally dispensed with in SMMCs Shared Memory Multi core Chips used to run TICC Ppde programs. All services currently provided by an operating system to TICC Ppde may then be incorporated with in TICC Ppde itself. Thus TICC Ppde provides an integrated parallel program design development verification execution and run time monitoring environment that is ideally well suited to develop validate run and monitor parallel programs in SMMC or in a computing grid consisting of several SMMCs interconnected by a TICCNET .

Feature 2 TICC GUI This displays graphical representations of segments of TICC networks anchored at given cells and segments of ALLEOPs anchored at given ports or cells and segments of causalnets anchored at given ports or cells. Examples of TICC network displays appear in this paper since these are the only ones implemented in the existing prototype implementations. TICC GUI should provide facilities to examine the state of any cell in an application while it is running at time points at which the GUI polls for cell states in response to received service requests. It is practically impossible to display the state of a cell at time points which precisely coincide with the times when display requests were made. However one could set break points see Srinivasan 48 in TIP bodies and have the states displayed when certain events occur. A rudimentary version of this is available in the prototype TICC Ppde and was used to debug parallel programs. Introducing such break points into an application Ap will however alter timings of events occurring in Ap. Thus break points may be used only in a testing mode. GUI is useful both to document system implementation and for dynamic system monitoring. TICC GUI is an integral part of TICC Ppde.

Feature 3 Arbitrary Scalability As long as interaction overhead caused by scaling is small when compared to program execution times parallel programs in TICC Ppde are arbitrarily scalable. What is unique to TICC Ppde parallel programs is that interaction overhead may be defined precisely relative to the structure of a TICC network. Let N be a TICC Network of cells and pathways and n N C be the maximum number of messages exchanged by cell C in N in any one of its polling cycles. Let n N be the maximum of all n N C for C in N n N Maximumn N C C N. Let v N be the number of cells in network N and let N be the scaled up version of N with v N cells. Then the requirement for arbitrary scalability is n N should be independent of the scaling factor v N v N . The value of could run into millions if this condition is satisfied. This essentially says that communication and coordination overhead per cell should not increase in proportion to the scaling factor.

Feature 4 Eliminating Cache Memories and Speed up Techniques Cache memories may be dispensed with for running TICC Ppde parallel programs. In our prototype implementations we found cache memories more of a nuisance. It took us a long time to realize inexplicable crashes were happening in our parallel programs because of cache incoherence. We had to update data in main memories in order to avoid cache incoherence. With small grain size executions too much time was wasted in cache replenishments and cache incoherence was an annoying problem. Cache memories are not needed for high throughput program executions in TICC Ppde. High throughputs may be realized by arbitrary scaling of low grain size parallel program executions in cells. Indeed none of the usual speed up techniques such as multiple instruction stream executions 29 look ahead scheduling 30 pipe lined processing 31 and cached executions 32 are needed for high efficiency and high throughput in TICC Ppde.

In TICC Ppde each CPU is dedicated to servicing only one cell using only the virtualMemories associated with that cell. Each cell may execute only one TIP at any given time and TIP executions are uninterruptible by any external agent. The time taken to execute a TIP including both computation and communication may be as small as 1 to 100 microseconds. There are no synchronization coordination scheduling and monitoring overheads. Thus there is no natural context in TICC Ppde to profitably employ any of the speed up techniques. This enables prediction of event timings with in tightly specified bounds.

Feature 5 Ideal Environment for Validated Cyber physical Real time Systems with Self Monitoring Software execution with predictable timings within given bounds is a necessary and important requirement for building cyber physical real time systems. TICC Ppde provides the ideal environment to design implement and validate cyber physical systems with automatic self monitoring using SMS. This is useful to design and implement systems like auto pilot of an aircraft or a space craft system automated multi sensor reactive systems automated systems for defensive offensive coordination of military vehicles automated factories robots or any other time critical reactive system.

TICC Ppde may also be used to build secure information systems like medical information systems or intelligence information systems or data base or knowledge based systems. A significant most widely used application for TICC Ppde is likely to be however in SMP based personal computer systems using SMM Shared Memory Module memory architecture that guarantee privacy and protection against unauthorized intrusions.

Feature 6 Dynamic Flexibility and Mobility TICC Ppde parallel programs may be dynamically modified and updated by changing pathway connections dynamically and by introducing dynamically new cells and pathways see in situ testing in Das 19 . Program mobility in distributed environments is achieved by transferring entire contents of a virtualMemory in one processor to other virtualMemories in other processors.

What has been accomplished We have introduced here a parallel programming paradigm which adapts and combines concepts from various other paradigms. TICC provides the necessary glue for all of them to work together in TICC Ppde. TICC Ppde provides methods to i define parallel processing TICC networks ii abstractly specify interactions among ports in the networks using TIPs Thread Interaction Protocols and interactions among cells in the networks using CIPs Cell Interaction Processes iii methods to refine compound cells to sub networks of cells and pathways and encapsulate the sub networks iv complete implementations through successive refinements of abstract specifications v automatically derive ALLEOP models from TIPs TICC networks and refinements of TIPs vi automatically derive traces from ALLEOPs using action characterizations vii automatically build ECT networks Event Characterization Table networks from traces viii use ECT networks to produce interactive proofs of valid properties of implementations stated as CTL assertions both at the FSP and NFSP levels ix automatically incorporate run time SMS Self Monitoring System into every completed implementation x perform limit testing and ad hoc synchronization and coordination xi use arbitrarily large numbers of parallel processing units and xii provide abstractions needed to develop verify and run complex parallel programs in multi core chips.

On Communications and Computations TICC defines high speed computing mechanisms for communications. Computations performed by the communication mechanisms are integrated with parallel processing computations performed by cells. Mechanisms for scheduling synchronization coordination security enforcement and self monitoring are built into the communication mechanisms. For each message exchange one can predict within tight bounds when the message sending event might begin and when the message would be delivered based on the history of message exchanges available in the causalnet that is built by the SMS and knowledge of ALLEOPs. Similarly for each action event the time it might begin execution and the time it would complete execution are predictable within reasonably tight bounds based on the history in the causalnet and knowledge of ALLEOPs. It is not possible to do these in Actor systems or in calculus.

Asynchronous communication is integrated with computations in a manner that is analogous to the way CSP integrates synchronous communications with computations but with much greater flexibility and power. Message processing parallel computations and communication protocol evaluations are mutually isolated from each other even though both are performed by same cells. Mutual isolation is also enforced among asynchronous parallel cells that communicate with each other also in parallel. TICC Ppde programs are self scheduling self synchronizing self coordinating and self monitoring. They do not require monitors semaphores schedulers synchronizers rendezvous coordinators serializers or any other ornamentation to make them work correctly.

On Interaction Specifications A common feature of TICC Ppde and calculus is that they both specify parallel computations through interactions among computing components. This is essentially the only significant common feature between the two. The interaction and computational mechanisms are quite different.

Each calculus agent runs in parallel with other agents. The only computing operations performed by calculus agents are name substitutions for parameters defined in an agent exchanging names between pairs of agents via links dynamically establishing links between agents and hiding links. II calculus does not specify computing mechanisms needed for communicating names via links. Indeed the needed mechanisms cannot be specified in the calculus formalism. Communicating names via links is assumed as a given primitive. There is no concept of refinement but hiding should in principle enable encapsulation. It is not clear though what the criteria would be to find matching ports to plug in an encapsulated component into a larger system.

These features of calculus may be compared with the following features of TICC Ppde Each TICC Ppde cell runs in parallel with other cells. TIPs specify interactions among ports attached to cells. Interactions specified by TIPs describe two kinds of computations both conventional sequential computations i computations performed by a cell to process and build messages and ii computations performed by the same cell to send messages it builds to other cells through its ports. TIPs isolate the two computations. TIP computations may be specified at an abstract level and reduced to their final implementations through progressive refinements. Subsystems may be encapsulated into compound cells and used as plug in components and compound cells may be refined into encapsulated sub networks with a well defined criterion to connect with matching ports in a larger system. Of course besides all of these TICC Ppde also provides facilities for verification and self monitoring.

On Verification Model based verification of design specifications using FSP 15 and CTL 40 44 49 have played significant and important roles in system design. They are needed to verify designs and validate properties that implementations should satisfy. The problem with FSP is abstract FSP specifications cannot be directly reduced to implementations through successive refinements. This makes it necessary to verify implementations using different tools and this task is more complex than design verification.

Model based verification by Clark et al 38 40 41 verify synchronous hardware design specifications not hardware implementations because issues of coordination synchronization and race conditions do not seem to be a part of the verification system. Nevertheless verification methods introduced by Clark et al are widely used by hardware designers to validate designs. There are hardware description languages like GEZEL Schaumont et al 46 which allow design and verification of race free hardware systems. It is not however clear whether they are being widely used.

TICC Ppde specification methodology may be used to specify and verify implementations of race free asynchronous hardware systems. All timings synchronization and coordination requirements of an implementation are implicitly a part of specifications. They are taken into account during verification. The only restriction is components should interact asynchronously using CCPs. This may make TICC Ppde not suitable to verify clock pulse driven synchronous hardware designs.

Advantage of using TICC Ppde One advantage is that abstract specifications of intended computations look somewhat similar to FSP specifications of abstract designs and TICC Ppde provides a methodology to reduce the abstract designs directly to implementations through successive refinements. At any stage of refinement ad hoc synchronization and coordination may be introduced into implementations without having to change any of the refinements done up to that point. TICC Ppde makes it possible to use model based formal verification to validate implementations at any stage of refinement. Besides providing such verification capabilities the TICC paradigm automatically incorporates SMS into completed implementations to monitor correct performance throughout the life time of applications whether hardware or software as long as components interact asynchronously and use communication mechanisms based on CCP driven signal exchanges. Abstractions in TICC Ppde simplify and codify design implementation verification and run time monitoring.

On Abstractions in TICC Ppde Abstractions introduced by the TICC paradigm are not really programming abstractions even though we have used the phrase programming abstractions in this paper. TICC Network Cell Port Agent VirtualMemory and Pathway are abstractions of system components and pthread protocol TIP CIP ALLEOP trace ECT tables and Causalnet are process abstractions. TICC Ppde provides a programming framework for specifying these abstractions or deriving them from specifications. They are distinct from conventional programming abstractions such as variables blocks assignments declarations conditional statements while loops and data structures they are also distinct from conventional process abstractions like methods functions threads sub routines and co routines and finally they are distinct from conventional component abstractions such as class object and message. Conventional programming abstractions and conventional process abstractions do not directly identify and relate to system components and processes as TICC Ppde abstractions do. Conventional component abstractions do abstract system components but mapping classes to system components in implementations is a non trivial task.

On System Design and Implementation TICC Ppde shifts the focus of system development from programming to system decomposition interaction specification and verification. Programming through refinements becomes a trivial task once system organization and interaction specifications are in place and verification follows as a natural consequence of implementation. At present we do not have systematic methods for system decomposition. One faces this problem in the specification of any complex system software hardware physical or social systems. Perceived realizability conditions always influence system decomposition and design. Allowing realizability conditions that depend on programming idiosyncrasies to guide system decomposition and design is however not a good practice. By shifting the focus to system decomposition and interaction specification and delegating programming to successive refinements of an already defined design TICC Ppde attempts to avoid this problem.

Modes of interactions between software hardware components in the TICC paradigm are not the same as they are in conventional software systems time sliced concurrent software systems calculus framework or synchronous hardware systems. Designing TICC networks defining TIPs and CIPs developing logical characterizations of pthreads and identifying CTL assertions to be validated are important and difficult problems. Expertise in programming will not help solve these problems.

TICC paradigm calls for new approaches to the way system designers and programmers should be trained they should be trained in component interaction analysis logic and verification techniques. We hope methods for interaction analysis and concepts of optimal system designs expressed in terms of TICC networks and interactions will emerge. They are necessary.

TICC Ppde will radically change Software Engineering as we know it today and hopefully allow it to evolve as a discipline with scientific principles of system design providing further support to the already existing support it enjoys through an evolving set of sound but ad hoc current practices which have been mostly influenced by our programming technology.

Significance The goal of realizing a high quality secure and fully operational TICC Ppde is with in reach using only currently available technologies. There is no need to develop new technologies to realize this goal it can be realized with in three to five years if enough resources are devoted to it. Proof of concept prototype implementations of TICC and TICC Ppde substantiate this claim. They were implemented in two man years by this author with some assistance from Mr. Rajesh Khumanthem and Dr. Saeed Rajput. It took about four man years for this author to understand its significance and scope. The list below itemizes short term projects ST requiring 3 to 5 years to complete. All but the last one in the list have to be successfully completed in order to realize the above stated goal the last one being optional.

Realization of high quality secure and fully operational TICC Ppde is likely to profoundly impact the way individuals use their desk top and lap top computers and use supercomputer systems the way computers are used in scientific and technical applications the way social educational business governmental organizations use computers and the way software industries produce and market software. New regulatory standards for marketing validated software might emerge. Eventually we may produce complex validated secure self correcting software that operate independently in space based and terrestrial robotic systems as well as personal business governmental social scientific and educational computers in all cases providing guaranteed protection against data theft invasions of privacy and malicious attacks. Universally available gigantic computational resources unprecedented since the dawn of computer era will become common place being at the command of every individual who seeks them. The list of long term LT projects itemized below points to the scope of potential applications for TICC Ppde in the near future with in a period of ten years 

 iv developing TICC Ppde compatible principles of software hardware engineering and training of programmers 

 v using SMS for complex pattern recognition and learning based on dynamically recognized event patterns in a causalnet 

 vi using SMS to dynamically control behavior of an application based on recognized event patterns in a causalnet 

 viii building secure massive efficient self monitoring TICC based parallel applications in a variety of important areas possibly using TICC KB such as 

a medical information systems b intelligence information systems c business information systems d natural language systems e complex simulations f robotics g multi sensor reactive systems h cyber physical systems i weather prediction systems etc. LT 

We have introduced here a system architecture that sets a basis for a new era of computing technology and computer science to emerge and evolve whose long term consequences in the 21century and beyond is currently unpredictable.

When a person approaches a gate turnstile the sensor at the gate sets Se.g.personAtGate true. After letting a person into the park or after denying entry to the person because the park is full the person leaves the gate. At that point the functionPort Et j .f of the entrance turnstile sends back reply to Se.g. When sensor receives this reply it resets Se.g.personAtGate to false. It will become true again when the next person gets to the gate. Thus a second person may enter only after the first person has left the gate.

TRACES The traces are presented in the ECT Blocks in Tables 5.1 through 5.3 and Table 6.1 and 6.2. The corresponding ECT networks are presented in Tables 5 and 6. See discussion in Section 7.1.

Here we describe the implementation by defining the CIPs for all cell classes in the implementation. It is more convenient to do so in this example. It shows a different style of defining an implementation.

Traces Traces are presented in the ECT Blocks in through . and the ECT network is presented in Table 7.

Notice btlr services all philosophers with pending service requests in the polling cycle in which the interrupt signal was sensed. Terminates the game only after all forks are on the table and after receiving acknowledgement from all philosophers that they have terminated.

The loop invariant for the while loop in btlr BODY is j W j where W j means philosopher P j is waiting for forks. j W j is the deadlock state. This state is never reached during the game. The proof for this is given in Section 7.4. All actions and conditions characterized below are defined in the Btlr class. Implementations are not shown here for all actions. Their characterizations are given below.

As we have already mentioned btlr terminates operations only after all waiting philosophers have been serviced and all philosophers have stopped eating and returned the forks.

A waiting philosopher responds to the termination signal only after he she has eaten. Thus before game ends every philosopher would have been satiated.

The set of distinguished predicates is used to specify initial states before evaluation of ETC network begins. Generally speaking distinguished predicates include conditions that determine choices to be made at choice points in TIPs. Thus any non standard guards and status of messages in virtualMemories and states defined for cells will be included in this set. For example in this example the guard and status of message in a virtualMemory are included in this set if a service request at a functionPort is not responded to before execution of the next TIP begins. Rule for symbolic evaluation of ECTs is if a predicate determining the choice at a choice point is not specified in the initial state or among predicates used earlier in the ECT evaluation then all causal chains emanating from that choice point should be included as possible alternates in the symbolic evaluation.

The states of philosophers T j thinking P j W j waiting P j and E j eating P j are defined in Section 7.4. Axioms of the game and its initial conditions are also defined there. The proofs presented In Section 7.4 require only P g trace p j .g.t and btlr.f j trace bf j .t for 0 j

