---

title: Method, system and computer program product for batched virtual memory remapping for efficient garbage collection of large object areas
abstract: A method, system and computer program product for batched remapping of virtual memory addresses for garbage collection in a large object area. A mapping from a table having a first set of virtual memory addresses and sizes of non-contiguous, page-aligned large objects in a large object area to a remapping table having a second set of virtual memory addresses is determined. In a single batch, a request is received that includes the second set of virtual addresses and requests a remapping of the large objects to the second set of virtual memory addresses. The second set of virtual memory addresses is validated, and the large objects are remapped to the second set of virtual memory addresses according to the request. The remapping results in a compaction so that the large objects are contiguous in the large object area. The remapping does not require copying data in physical memory.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08327111&OS=08327111&RS=08327111
owner: International Business Machines Corporation
number: 08327111
owner_city: Armonk
owner_country: US
publication_date: 20090330
---
The present invention relates to automatic memory management of large object areas and more particularly to a method system and computer program product for performing garbage collection in large object areas by remapping virtual memory addresses.

Conventional compaction of free space in garbage collection that uses memory copying has a negative performance impact by requiring large amounts of memory to be shifted. These known memory copying compaction techniques are expensive and cause significant paging activity with associated memory thrashing. Other conventional compaction methods are inefficient including those that rely on virtual memory to exploit page faults to implement operating system supported read and write barriers. Furthermore a known compaction method uses virtual memory management to decommit free pages and commit uncommitted pages but the resulting number of pages needed the use of three types of pages i.e. free live and uncommitted and the intermingling of uncommitted pages with live pages indicate deficiencies in complexity effectiveness and efficiency e.g. additional management is required for the interspersed uncommitted pages and the need to reserve the uncommitted pages requires a reduction in the maximum heap size . Thus there exists a need to overcome at least one of the preceding deficiencies and limitations of the related art.

The present invention may provide a computer implemented method of batched remapping of virtual memory addresses for garbage collection in large object areas. The method comprises 

determining a mapping from a first table to a second table wherein the first table includes a plurality of identifiers of a plurality of page aligned large objects included in a large object area of a virtual memory a first plurality of virtual memory addresses to which the page aligned large objects are initially assigned and a plurality of virtual memory sizes of the page aligned large objects wherein the second table includes a second plurality of virtual memory addresses to which the page aligned large objects are assigned for a compaction of the plurality of page aligned large objects and wherein the page aligned large objects are not contiguous in the large object area 

receiving a request in a single batch wherein the request includes the second plurality of virtual memory addresses and requests a remapping of the plurality of page aligned large objects to the second plurality of virtual memory addresses 

remapping the plurality of page aligned large objects to the second plurality of virtual memory addresses according to the request wherein a result of the remapping is the compaction that includes the plurality of page aligned large objects being contiguous in the large object area and wherein the remapping is performed by a processor of a computer system.

A system and computer program product corresponding to the above summarized method are also described and claimed herein.

One or more embodiments of the present invention advantageously use virtual memory management to reduce fragmentation without requiring the copying of data in memory.

One or more embodiments of the present invention are directed to a compaction method system and computer program product that use virtual memory management to change virtual memory address ranges in a large object area to align contiguous locations of free virtual memory and to align contiguous locations of live virtual memory by adjusting virtual memory mapping on physical memory. Aligning free virtual memory as contiguous locations and aligning live virtual memory as contiguous locations may include using remapping operations to swap free and live pages. The compaction technique disclosed herein may reduce fragmentation without requiring the resource intensive copying of data in memory. One embodiment of the compaction method system and computer program product disclosed herein utilizes a kernel memory management driver also known as a.k.a. kernel driver or kernel mode driver that allows multiple virtual memory remappings to be performed in a single kernel transition so that page aligned large objects become contiguous in a large object area. As used herein a kernel transition is defined as a sequence of steps that are required for a thread executing in user mode space to transition to executing code in kernel mode space. The kernel driver may have direct access to underlying kernel application programming interfaces APIs .

System for Batched Remapping of Virtual Memory Addresses for Garbage Collection in Large Object Areas

Garbage collector performs automatic memory management that includes identifying objects in a program that cannot be accessed in the future by the program and reclaiming the memory used by the identified objects. Every object has a unique identifier and has a contiguous location in virtual memory. The number of bytes required by an object is arbitrary but the memory manager rounds up the allocation size to a multiple of the virtual memory page size. Therefore the virtual size of an object is always greater than or equal to the actual size of the object. A memory manager not shown page aligns large objects in a large object area LOA in preparation for a compaction phase of garbage collection that includes remapping virtual memory addresses of the large objects. As used herein a large object is defined as any object allocation that exceeds a predefined threshold value. For example MICROSOFT Common Language Runtime CLR defines a large object as any object allocation exceeding 85K bytes. As used herein a large object area is defined as a memory address space reserved for large objects. The LOA has a base virtual address. A LOA may be a portion of a heap or a portion of virtual memory in which large objects are stored and segregated from other objects that are not large objects. The boundaries of a large object area are specified by the garbage collector .

System also includes a kernel driver . Garbage collector sends a single batched remapping request to kernel driver to perform one or more remappings in a single kernel transition. Request specifies the virtual memory addresses of virtual memory pages on which large objects are aligned where the virtual memory addresses are to be remapped to perform the compaction of the large objects. Kernel driver validates the virtual memory addresses included in request and remaps the virtual memory pages i.e. remaps the virtual memory addresses so that the large objects are contiguous in the large object area. In one embodiment the remapping performed by kernel driver is facilitated by the kernel driver s direct access to underlying kernel APIs e.g. ZwMapViewOfSection ZwOpenSection ZwUnmapViewOfSection and ZwClose which are routines in a kernel mode library that supports kernel mode drivers in the WINDOWS Driver Kit WDK offered by MICROSOFT Corporation located in Redmond Wash. . The functionality of the components of system is also described below relative to the discussion of .

Process of Batched Remapping of Virtual Memory Addresses for Garbage Collection in Large Object Areas

In step the garbage collector see determines a first set of one or more large objects that a program uses or will use and a second set of one or more large objects that the program is not using and will not use. The garbage collector see garbage collects the large object s that were determined to be in the aforementioned second set. The garbage collection of the large object s in step results in a fragmentation of virtual memory address space including a fragmentation of large object area see . That is the garbage collection in step results in large object area see including one or more free virtual memory pages a.k.a. free pages interspersed among the page aligned large objects.

In step the garbage collector see also identifies and collates the memory remapping that the garbage collector requires for a compaction of page aligned large objects e.g. large object in included in large object area see . Collating the memory remapping in step also includes determining a mapping from the aforementioned object size and address table to a new layout of large objects in the LOA so that the ranges of virtual memory addresses of the large objects are contiguous in the LOA. In one embodiment the garbage collector executes the algorithm presented below to accumulate virtual addresses to determine the mapping in step .

The Assign step in the algorithm presented above re assigns large objects from previously assigned virtual addresses i.e. the virtual addresses associated with the large objects by the object size and address table to the virtual addresses determined by the algorithm. Furthermore the garbage collector may store the virtual addresses assigned by the algorithm in a second table a.k.a. a remapping table . In step the garbage collector see defines a remapping between the large objects in the aforementioned object size and address table and the virtual addresses assigned by the algorithm presented above e.g. by mapping large objects identified in the object size and address table to the virtual addresses in the remapping table .

In step garbage collector see sends batched remapping request see in a single batch to kernel driver see . Batched remapping request see indicates virtual memory addresses of virtual memory pages that are to be remapped in the large object area see according to the remapping defined in step . The remapping of the virtual memory addresses ensures that all large objects in the large object area become contiguous i.e. the large objects are in contiguous virtual memory locations and all free pages in the large object area become contiguous. In one embodiment step includes the garbage collector see sending the aforementioned remapping table to the kernel driver see in a single call. The remapping table may include one or more objects that are no longer required by the program. In one embodiment the garbage collector omits from the remapping table one or more objects that do not need to be moved i.e. object s that were not re assigned to different virtual addresses in step .

In step kernel driver see validates virtual memory addresses of virtual memory pages included in batched remapping request see . The validation in step includes 1 verifying that there are no overlapping objects in the virtual memory address space and 2 verifying that the virtual memory address space of each large object has not changed.

In step kernel driver see remaps the virtual memory pages according to the batched remapping request see which results in the large objects in the large object area see being contiguous and the free pages in the large object area see being contiguous. Allocated to each large object are zero or more physical memory pages or locations in a page file if the large object has been paged out . Each resident physical page has a location in virtual memory. For a large object that is being moved according to the remapping request sent in step the kernel driver gives each resident physical page of the large object a different location in virtual memory by updating a virtual memory page table through one or more operating system calls.

In one embodiment the kernel driver see receives the remapping table in the single call in step and then makes all of the virtual memory page table changes in one operation. That is a single kernel transition is performed e.g. in step by loading and executing a kernel driver prior to the kernel driver performing a single operation that makes the multiple virtual memory page table changes in step .

In one embodiment a kernel transition is a sequence of steps that are required for a thread executing in user mode space see to transition to executing code in kernel mode space see . A kernel transition may be achieved through a special software interrupt. A kernel transition is relatively slow and therefore it is advantageous in a high performance system to perform as few kernel transitions as possible. Furthermore the facilities available to code running in kernel mode space see are more privileged than code running in user mode space see . For example it is not possible to manipulate virtual memory page tables in user mode space see . An application running in user mode space see that wants to perform a privileged operation such as manipulating virtual memory page tables in step must perform a kernel transition and then perform the privileged operation in kernel mode space see . The application that needs to perform a kernel transition loads and executes a set of code i.e. kernel driver in in kernel mode space see .

The large object area garbage collection that utilizes virtual memory address remapping ends at step .

The post compaction fix up phase of garbage collection is unaltered by the process of . The application memory must still be scanned to identify large object references that have moved position in memory. The process disclosed herein does not introduce any change to the performance characteristics of the fix up phase of garbage collection.

Table 1 presented below includes the virtual addresses actual sizes and virtual sizes of four large objects having the identifiers IDs and see the description of the object size and address table stored prior to step in .

Garbage collector see determines that objects having IDs and are in use by a program but that the object having ID is not in use and will not be in use by the program. Garbage collector see garbage collects the object having ID which results in virtual memory becoming fragmented as shown in the virtual memory on the left side of .

Virtual memory includes a large object area which stores large objects and . The arrows between physical memory locations and virtual memory indicate mappings of large object to large object large object to large object and large object to large object . For example the arrow from object to object indicates a mapping of a range of memory addresses of object to a range of virtual addresses of object . The left side of i.e. to the left of the arrow labeled Remap illustrates the mappings between physical memory locations and virtual memory prior to a remapping performed according to the process of . Virtual memory to the left of the arrow labeled Remap illustrates non contiguous live pages. For example there is a free i.e. unmapped range of virtual addresses between object and object thereby making the live pages of object non contiguous with the live pages of object i.e. virtual memory to the left of the Remap arrow is fragmented .

Before the remapping occurs the algorithm presented above in the discussion of is executed to perform the following re assignments and the re assigned virtual addresses are stored in the remapping table 

After the garbage collector see sends a batched remapping request to the kernel driver see in a single call where the remapping request specifies the large objects to be remapped according to the remapping table see step in and after the kernel driver validates the virtual memory addresses in the remapping table see step in then the kernel driver remaps the large objects by updating the virtual memory page tables according to the remapping table see step in .

The right side of i.e. to the right of the arrow labeled Remap illustrates mappings between physical memory locations and virtual memory after a remapping performed according to step in the process of . Virtual memory to the right of the arrow labeled Remap illustrates contiguous live pages resulting from a swap of pages in range with the pages in object . Virtual memory to the right of the arrow labeled Remap results from a remapping in step of in which the object is remapped to the object in the range of virtual addresses a.k.a. object which was the free range of virtual addresses prior to the remapping and the address range is remapped to the range of virtual addresses which was the range of virtual addresses for object prior to the remapping . As illustrated by the virtual memory to the right of the arrow labeled Remap the remapping in results in all live pages of the large objects in large object area being contiguous and all free pages in large object area being contiguous. That is the virtual memory resulting from the remapping of the process of includes no free pages and or uncommitted pages interspersed with the live pages of objects and . The resulting contiguous live pages and contiguous free pages in virtual memory on the right side of are attained by the process of without requiring copying data in memory.

Compaction through virtual memory remapping is prototyped in this section to explore its performance characteristics. The C code in this section shows a piece of physical memory page file backed being allocated through the WINDOWS API CreateFileMapping. The prototype in this section then maps the allocated memory into the application s virtual address space using MapViewOfFileEx. At any time the block of memory in the prototype can be unmapped from the address space using UnmapViewOfFile. The code in this section simply tries a few different virtual addresses to map the memory starting at 0x640000.

Implementing a real large object area garbage collection using the prototype in this section would be inefficient because each of the WINDOWS APIs utilized in the prototype requires a separate kernel transition thereby making the process too expensive for the remapping of many large objects after a collection.

Memory may comprise any known type of computer data storage media including bulk storage magnetic media optical media random access memory RAM read only memory ROM a data cache etc. In one embodiment cache memory elements of memory provide temporary storage of at least some program code e.g. code for program in order to reduce the number of times code must be retrieved from bulk storage during execution. Moreover similar to CPU memory may reside at a single physical location comprising one or more types of data storage or be distributed across a plurality of physical systems in various forms. Further memory can include data distributed across for example a local area network LAN or a wide area network WAN .

I O interface comprises any system for exchanging information to or from an external source. I O devices comprise any known type of external device including a display device e.g. monitor keyboard mouse printer speakers handheld device facsimile etc. Bus provides a communication link between each of the components in computer system and may comprise any type of transmission link including electrical optical wireless etc.

I O interface also allows computer system to store and retrieve information e.g. data or program instructions such as code of program from an auxiliary storage device such as computer data storage unit or another computer data storage unit not shown . Computer data storage unit may be a non volatile storage device such as a magnetic disk drive i.e. hard disk drive or an optical disc drive e.g. a CD ROM drive which receives a CD ROM disk .

Memory includes computer program code for the program for large object area garbage collection by virtual memory address remapping e.g. logic for the process of . Further memory may include other systems not shown in such as an operating system e.g. Linux that runs on CPU and provides control of various components within and or connected to computer system .

Memory storage unit and or one or more other computer data storage units not shown that are operatively coupled to computer system may store the addresses of large objects in large object area see . The process of may result in a transformation that 1 transforms a computer data storage unit from a store of addresses in a large object area that includes non contiguous large objects to a store of addresses in a large object area that includes only contiguous large objects.

As will be appreciated by one skilled in the art the present invention may be embodied as a system method or computer program product. Accordingly an embodiment of the present invention may be an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a system e.g. system in or computer system . Furthermore an embodiment of the present invention may take the form of a computer program product embodied in any tangible medium of expression e.g. memory or computer data storage unit having computer usable program code e.g. code for program embodied or stored in the medium.

Any combination of one or more computer usable or computer readable medium s e.g. memory and or computer data storage unit may be utilized. The computer usable or computer readable medium may be for example but not limited to an electronic magnetic optical or semiconductor system apparatus or device. A non exhaustive list of more specific examples of the computer readable medium includes an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device or a magnetic storage device. Note that the computer usable or computer readable medium could even be paper or another suitable medium upon which the program is printed as the program can be electronically captured via for instance optical scanning of the paper or other medium then compiled interpreted or otherwise processed in a suitable manner if necessary and then stored respectively in a computer memory . In the context of this document a computer usable or computer readable medium may be any medium that can store the program for use by or in connection with the instruction execution system apparatus or device. The computer usable program code may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable radio frequency RF etc.

Computer program code e.g. code of program for carrying out operations of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as JAVA Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on a user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. Any one of the aforementioned computers or servers may be computer system . In the latter scenario the remote computer may be connected to the user s computer through any type of network not shown including a LAN a WAN or the connection may be made to an external computer e.g. through the Internet using an Internet Service Provider .

The present invention is described herein with reference to flowchart illustrations e.g. and or block diagrams of methods apparatus systems e.g. and and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions e.g. code of program . These computer program instructions may be provided to a processor e.g. CPU of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions when executed by the processor of the computer or other programmable data processing apparatus implement the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium e.g. memory or computer data storage unit that can direct a computer e.g. computer system or other programmable data processing apparatus to function in a particular manner such that storing the instructions in the computer readable medium produces an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer e.g. computer system or other programmable data processing apparatus to cause a series of operational steps to be performed on the computer or other programmable apparatus to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

Any of the components of an embodiment of the present invention can be deployed managed serviced etc. by a service provider that offers to deploy or integrate computing infrastructure with respect to the process for batched remapping of virtual memory addresses for garbage collection in large object areas. Thus an embodiment of the present invention discloses a process for supporting computer infrastructure comprising integrating hosting maintaining and deploying computer readable code e.g. code of program into a computer system e.g. computer system wherein the code in combination with the computer system is capable of performing the process of batched remapping of virtual memory addresses for garbage collection in large object areas.

In another embodiment the process steps of the invention are provided to customers on a subscription advertising and or fee basis. That is a service provider such as a Solution Integrator can offer to create maintain support etc. processes for batched remapping of virtual memory addresses for garbage collection in large object areas. In this case the service provider can create maintain support etc. a computer infrastructure that performs the process steps of the invention for one or more customers. In return the service provider can receive payment from the customer s under a subscription and or fee agreement and or the service provider can receive payment from the sale of advertising content to one or more third parties.

The flowchart in and the block diagrams in illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code e.g. code of program which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

While embodiments of the present invention have been described herein for purposes of illustration many modifications and changes will become apparent to those skilled in the art. Accordingly the appended claims are intended to encompass all such modifications and changes as fall within the true spirit and scope of this invention.

